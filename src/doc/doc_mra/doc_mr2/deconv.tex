

\chapter{Multiscale Entropy Applied to Deconvolution}
\label{ch_deconv}
\index{deconvolution}
\section{Introduction to Deconvolution}

Consider an image characterized by its intensity
distribution (the ``data'') $I$, corresponding to the observation of a
``real image'' $O$ through an optical system. If the
imaging system is linear and shift-invariant, the relation between
the data and the image in the same coordinate frame is a
convolution:
\begin{eqnarray}
I = O * P + N
\label{eqn_3_first}
\end{eqnarray}
$P$ is the point spread function (PSF) of the imaging system, and $N$
is additive noise. In practice $O * P$ is subject to non-stationary noise
\index{stationary signal}
which one can tackle by simultaneous object estimation and restoration
\cite{rest:katsaggelos91}. 
The issue of more extensive statistical
modeling will not be further addressed here (see 
\cite{rest:llacer90,rest:lorenz93,rest:molina93}), 
beyond noting that multiresolution
frequently represents a useful framework, allowing the user to introduce
a priori knowledge of objects of interest.

In Fourier space we have:
\begin{eqnarray}
\hat I= \hat O \hat P + \hat N
\end{eqnarray}
We want to determine $O(x,y)$ knowing $I$ and $P$. This
inverse problem has led to a large amount of work, the main difficulties 
being the existence of: (i) a cut-off frequency of the 
point spread function, 
and (ii) the additive noise (see for example \cite{rest:cornwell88}).
 
Eqn.\ \ref{eqn_3_first} is usually in practice an ill-posed problem.
This means that there is not a unique solution.  

\section{Non-Regularized Deconvolution Methods}
\subsection*{Inversed filtering}
This method, sometimes called   {\em  Fourier-quotient method},
 computes
  the Fourier transform of the deconvolved object $\hat{O}$ by
  a simple division between the image $\hat{I}$ and the PSF $\hat{P}$
\begin{eqnarray}
\hat{\tilde{O}}_u=\frac{\hat{I}_u}{\hat{P}_u}=
   \hat{O}_u+\frac{\hat{N}_u}{\hat{P}_u}
\end{eqnarray}

This algorithm is very fast. We only need to do a Fourier transform
 and an inverse Fourier transform. For frequencies close the frequency
 cut-off, the noise term becomes important, and the noise is amplified.
 Then in the presence of noise, this method cannot be used.
 To reduce the artifact, it is possible to convolve the solution with a 
 smoothing function (Gaussian). Another possibility 
is to use Wiener filtering
 which is defined by:   
 \begin{eqnarray}
\hat{W}_u = \frac{\mid \hat{S}_u \mid^2 }{\mid \hat{S}_u \mid^2 + \mid \hat{N}_u\mid^2}
\end{eqnarray}
where $\mid \hat{S}_u \mid^2 $ and  $\mid \hat{N}_u\mid^2$  are
the spectral density of the signal and the noise. The filter is
\begin{eqnarray}
\hat{W_d}_u = \frac{ 
    \hat{P}^*_u} {\mid\hat{P}_u\mid^2+ \frac{\mid\hat{N}_u\mid^2}{\mid\hat{O}_u\mid^2}}
\end{eqnarray}

\bigskip
Wiener filtering has serious drawbacks (artifact creation such as ringing
effects), and  needs spectral noise estimation. Its advantage is that it
is very fast.
 
\subsection*{Jansson-Van Cittert}
 
Van Cittert \cite{rest:vancittert31}  restoration is relatively easy to write.
We start with $k=0$ and $O^{(0)} = I$ and we iterate:
\index{Van Cittert deconvolution} 
\begin{eqnarray}
O^{(n+1)}  = O^{(n)}  + \alpha(I - P * O^{(n)})
\label{vanvan}
\end{eqnarray}
where $\alpha$ is a convergence parameter generally taken as $1$.
When $k$ tends to infinity, we have $O = O + I - p * O$, so $I = P * O$. In
Fourier space, the convolution product becomes a product 
\begin{eqnarray}
\hat{O}^{(n+1)} = \hat{O}^{(n)}  + \alpha(\hat{I} - \hat{P}  \hat{O}^{(n)})
\end{eqnarray}
In this equation, the object distribution is modified by adding a term
proportional to the residual. The algorithm converges quickly after only
5 or 6 iterations. But the algorithm generally diverges in the
presence of noise. Jansson \cite{rest:jansson68} 
modified this technique in order to give it
more robustness by considering constraints on the solution. If we wish
that $ A \leq O_k \leq B$, the iteration is
\begin{eqnarray}
O^{(n+1)}_k = O^{(k)}_k + r(k)[I_k - P_k * O^{(n)}_k]
\end{eqnarray}
with:
\[r_k = C[1 - 2(B-A)^{-1}\mid O^{(n)}_k - 2^{-1}(A+B)\mid]\]
$C$ being a constant.

\subsection*{Gradient method}

The one-step gradient method is provided by the minimization of the norm 
$\parallel I  - P * O \parallel$ \cite{rest:landweber51}
and leads to:
\begin{eqnarray}
O^{(n+1)} = O^{(n)} + \alpha P^* * [I - (P * O^{(n)})]
\label{eqn_carre}
\end{eqnarray}
\noindent where $P^*(x,y)=P(-x,-y)$. $P^*$ is the transpose of the point
spread function, 
and $O^{(n)}$ is the current estimate of the desired ``real image''.  
In Fourier space we have:
\begin{eqnarray}
\hat{O}^{(n+1)} = \hat{O}^{(n)}  + \alpha \hat{P}^* (\hat{I} - \hat{P}  \hat{O}^{(n)})
\end{eqnarray}
 This method is more robust than Van Cittert's. The conjugate gradient 
method provides a faster 
way to minimize this norm with a somewhat more complex algorithm.

\subsection*{Richardson-Lucy}
The Richardson-Lucy
\index{Richardson-Lucy deconvolution}
method \cite{rest:richardson72,rest:lucy74} can be  derived from Bayes' theorem on conditional
probabilities.  Given Poisson noise, Shepp and Vardi \cite{rest:shepp82}
showed that a maximum likelihood solution was obtained, by use of an 
expectation-maximization algorithm.   Richardson-Lucy image restoration 
leads to:
\begin{eqnarray}
\begin{array}{l}
O^{(n+1)} =  O^{(n)} [ (I/I^{(n)}) \ast P^* ]    \\
 I^{(n)} = P \ast O^{(n)} 
\end{array}
\label{eqn_lucy}
\end{eqnarray}
This method is commonly used in astronomy.
Flux is preserved and the solution is always positive. The positivity 
of the solution can be obtained too with Van Cittert's and the 
one-step gradient
methods by thresholding negative values in $O^{(n)}$ at each iteration.

\subsection*{Conclusion}
All these methods have a severe drawback:  noise amplification,
which prevents the detection of weak objects, and leads to false
detections. To resolve these problems, some constraints must be added to
the solution (positivity is already one such constraint, 
but it is not enough). The addition
of such constraints is called regularization. Several regularization methods 
exist.

\section{Tikhonov Regularization}
Tikhonov regularization \cite{rest:tikhonov77} consists of minimizing the term:
\index{Tikhonov regularization}
\index{regularization, Tikhonov}
\begin{eqnarray}
 \parallel I(x,y) - (P * O)(x,y) \parallel + \lambda \parallel H * O\parallel
\end{eqnarray}
 where $H$ corresponds to a high-pass filter. 
This criterion contains two terms. 
The first, $\parallel I(x,y) - P(x,y)* O(x,y) \parallel^2$, expresses
 fidelity to the data $I(x,y)$, and the second, 
$\lambda \parallel H * O\parallel^2$,  expresses 
smoothness of the restored image. 
$\lambda$ is the
regularization parameter and represents the trade-off between
fidelity to the data and the smoothness of the restored image. Finding
the optimal value $\lambda$ necessitates use of numerical techniques such as
cross-validation \cite{rest:golub79,rest:galatsanos92}. 
This method works well, but computationally it is relatively lengthy
and produces smoothed images. This second point can be a real problem
when we seek compact structures such as is the case in astronomical imaging.

\subsection*{Tikhonov regularization and wavelet transform}
\label{direct_dec}
If $w_j^{(I)}$ are the wavelet coefficients of 
the image $I$ at the scale j, we have:
\begin{eqnarray}
 \hat{w}_j^{(I)}(u,v) & = & \hat{g}(2^{j-1}u, 2^{j-1}v) \prod_{i=j-2}^{i=0}\hat{h}(2^{i}u, 2^{i}v) \hat{I}(u,v) \nonumber \\
      & = &    {\hat{\psi}(2^{j}u, 2^{j}v) \over \hat{\phi}(u,v)} \hat{P}(u,v) \hat{O}(u,v) \\
      & = &   \hat{w}_j^{(P)} \hat{O}(u,v) \nonumber
\label{eq_cpphi}
\end{eqnarray}
where $w_{j}^{(P)}$ are the wavelet coefficients of the PSF at the scale $j$.
The wavelet coefficients of the image $I$ are the product of convolution
of object $O$ by the  wavelet coefficients of the PSF.

To deconvolve the image, we have to minimize for each scale j:
\begin{eqnarray}
\parallel {\hat \psi(2^ju, 2^jv)\over \hat\phi(u, v)} \hat P(u,v) \hat O(u,v)  - \hat w_j^{(I)}(u,v)\parallel^2 
\label{eqn_min1}
\end{eqnarray}
and for the plane at the lower resolution:
\begin{eqnarray}
\parallel {\hat \phi(2^{n-1}u, 2^{n-1}v)\over \hat\phi(u, v)} \hat P(u,v) \hat O(u,v)  - \hat  c_{n-1}^{(I)}(u,v)\parallel^2
\label{eqn_min2}
\end{eqnarray}
$n$ being the number of planes of  the wavelet transform ($(n-1)$ wavelet
coefficient planes and one plane for the image at the lower resolution).
The problem does not generally have a unique solution, and we need to do
a regularization \cite{rest:tikhonov77}. At each scale, we add the term:
\begin{eqnarray}
\gamma_j \parallel  w_j^{(O)} \parallel^2 \mbox{ min }
\label{eqn_min3}
\end{eqnarray}
This is a smoothness constraint. We want to have the minimum information 
in the restored object. From equations \ref{eqn_min1}, \ref{eqn_min2},
 \ref{eqn_min3}, we find:
\begin{eqnarray}
\hat D(u,v) \hat O(u,v) = \hat N(u,v)
\end{eqnarray}
with:
\begin{eqnarray*}
\hat D(u,v) & = & \sum_j \mid \hat\psi(2^ju, 2^jv) \mid^2  (\mid\hat P(u,v)\mid^2 + \gamma_j) \\
           &  & + \mid \hat \phi(2^{n-1}u,2^{n-1}v)\hat P(u,v) \mid^2
\end{eqnarray*} 
and:
\begin{eqnarray*}
\hat N(u,v) & = & \hat\phi(u, v) [ \sum_j \hat P^*(u,v)\hat\psi^*(2^ju, 2^jv) \hat w_j^{(I)} \\
          &  & + \hat P^*(u,v) \hat\phi^*(2^{n-1}u,2^{n-1}v) \hat c_{n-1}^{(I)}]
\end{eqnarray*} 
if the equation is well constrained, the object can be computed by a 
simple division of $\hat N$ by  $\hat D$. An iterative algorithm 
can be used to do this inversion if we want to add other constraints such as
 positivity. We have in fact a multiresolution Tikhonov regularization.
This method has the advantage to furnish a solution quickly, but 
optimal regularization parameters $\gamma_j$ cannot be found directly,
and several tests are generally necessary before finding an acceptable
solution. However, the method can be useful if we need to deconvolve
a large number of images with the same noise characteristics. In this case,
parameters have to be determined only the first time. In a more general
perspective,
we prefer to use one of the following iterative algorithms.


\section{The CLEAN Approach}
\subsection{The CLEAN algorithm}
\index{CLEAN}

This approach assumes the object is composed of point sources.
It tries to decompose the image (called the dirty map), obtained 
\index{dirty map}
by inverse Fourier transform
\index{Fourier transform}
of the calibrated $uv$ data, into a set of $\delta$-functions. 
This is done iteratively by finding the point with the largest
absolute brightness and subtracting the point spread function (dirty beam)
scaled with the product of the loop gain and the intensity at that
point. The resulting residual map is then used to repeat the
process. The process is stopped when some prespecified limit 
is reached. The convolution of the $\delta$-functions with an ideal 
point spread function 
(clean beam) plus the residual equals the restored image (clean map). 
\index{clean beam}
\index{clean map}
This solution is only possible if the image does not contain
large-scale structures.  
The algorithm is:
\begin{enumerate}
\item Compute the dirty map  $I^{(0)}(x,y)$ and the dirty beam $A(x,y)$.
\item Find the maximum value, and the coordinate $(x_{\mbox{max}},y_{\mbox{max}})$ of
the corresponding pixel in $I^{(i)}(x,y)$.
\item Compute $I^{(i+1)}(x,y) = I^{(i)}(x,y) - \gamma I_{\mbox{max}} 
A_{\mbox{m}}(x,y)$ 
      with $A_{\mbox{m}}(x,y)= A(x-x_{\mbox{max}}, y-y_{\mbox{max}})$ 
      and the loop gain $\gamma$ inside [0,1].
\item If the residual map is at the noise level, then go to step 5. \\
      Else $i \longleftarrow i+1$ and go to step 2.
\item The clean map is the convolution of the list of maxima 
with the clean beam  (which is generally a Gaussian).
\item Addition of the clean map and the residual map 
  produces the deconvolved image. 
\end{enumerate}

\subsection{Multiresolution CLEAN}
\index{CLEAN}

The CLEAN solution is only available if the image does not contain
large-scale structures.  Wakker and Schwarz (1988)
introduced the concept of Multiresolution CLEAN
(MRC) in order to alleviate the difficulties occurring
in CLEAN for extended sources.  The MRC approach
consists of building two intermediate images, the first one (called
the smooth map) by smoothing the data to a lower resolution with a
Gaussian function, and the second one (called the difference map)
by subtracting the smoothed image from the original data.  Both
these images are then processed separately.  By using a standard
CLEAN algorithm on them, the smoothed clean map and difference clean map are
obtained.  The recombination of these two maps gives the clean map
at the full resolution.

In order to describe how the clean map at the full resolution is
obtained from the smoothed and difference clean map, a number of symbols
must be defined:
\begin{itemize}
%\baselineskip=0.3truecm
\item $G = $ the normalized  ($\int G(x)dx = 1$) smoothing function; the width
of the function is chosen such that the 
full-width at half maximum of the smoothed dirty beam is $f$
times larger than the full-width at half maximum of the original dirty beam.
\item $A = $ dirty beam
\item $D = $ dirty map
\item $\delta = \delta$-functions
\item $R = $ residual after using CLEAN on the map
\item $B = $ clean beam with peak value 1
\item $C = $ clean map 
\item $s = $ the scale factor of the dirty beam needed to rescale the smooth  dirty beam back to a peak value 1
\item $r = $ the scale factor of the dirty beam needed to rescale the smooth clean beam back to a peak value 1 
\item $A_{\mbox{s}} = $ normalized smooth dirty beam  $= s A * G$
\item $A_{\mbox{d}} = $ normalized difference dirty beam 
$= 1/(1-\frac{1}{s})(A-\frac{A_{\mbox{s}}}{s})$
\item $B_{\mbox{s}} = $ normalized smooth clean beam $= r B * G$
\item $B_{\mbox{d}} = $ normalized difference clean beam  
$= 1/(1-\frac{1}{r})(B-\frac{B_{\mbox{s}}}{r})$
\end{itemize}
%\baselineskip=0.6truecm

From the $\delta$-functions found by the CLEAN algorithm, one can restore
the dirty map by convolving with the dirty beam and adding the residuals:
\begin{eqnarray}
D = D_{\mbox{s}} + D_{\mbox{d}} = \delta_{\mbox{s}}*A_{\mbox{s}}+R_{\mbox{s}} 
+ \delta_{\mbox{d}}*A_{\mbox{d}}+R_{\mbox{d}}
\end{eqnarray}
which can be written also as:
\begin{eqnarray}
D = \left[ s\delta_{\mbox{s}}*G + \frac{s}{s-1}\delta_{\mbox{d}}*(1-G) \right]*A+ 
R_{\mbox{s}}+R_{\mbox{d}}
\end{eqnarray}
If we replace the dirty beam by the clean beam, we obtain the clean map:
\begin{eqnarray}
C = \frac{s}{r}\delta_{\mbox{s}} * B_{\mbox{s}} + \frac{s(r-1)}{r(s-1)}
\delta_{\mbox{d}}
* B_{\mbox{d}}+R_{\mbox{s}}+R_{\mbox{d}}
\end{eqnarray}

The MRC algorithm  needs three parameters.
The first fixes the smoothing function  $G$, and the other two are the 
 loop gain and the  extra loop gain which are used by  CLEAN respectively
on the smooth dirty map and  difference dirty map.

This algorithm may be viewed as an artificial recipe, but we have
shown \cite{starck:sta94_1} that it is linked to 
multiresolution analysis as defined by Mallat \cite{wave:mallat89}. 
Mallat's theory provides a new representation where a
function is a sum of detail structures obtained with the same pattern, the
wavelet, with suitable translations and dilations. Wavelet analysis
leads to a generalization of MRC from a set of scales.

Our approach allows MRC algorithms to be harmonized with the
classical theory of deconvolution.
 
\subsection{CLEAN and wavelets}
\index{CLEAN}
\index{wavelet transform}
\subsubsection{The wavelet transform chosen.}
We have seen that there are many wavelet transforms. For interferometric
deconvolution, we choose the wavelet transform based on the FFT for
the following reasons:
\begin{itemize}
\item The convolution product is kept at each scale.
\item The data are already in Fourier space, so this decomposition
\index{Fourier transform}
is natural.
\item There is a pyramidal implementation available which does not take 
much memory.
\end{itemize}
Hence until the end of this chapter, we will consider the use of the
pyramidal transform based on the FFT.

\subsubsection{Deconvolution by CLEAN in wavelet space.}
\index{deconvolution}

If $w_j^{(I)}$ are the wavelet 
coefficients of  the image $I$ at the scale $j$, we
get:
\begin{eqnarray}
\hat{w}_j^{(I)}(u,v) =  \hat{w}_j^{(P)} \hat{O}(u,v) 
\end{eqnarray}
where $w_{j}^{(P)}$ are the wavelet coefficients of the point spread 
function at the scale $j$.
The wavelet coefficients of the image $I$ are the   convolution product
of the object $O$ by the  wavelet coefficients of the point spread 
function.

At each scale $j$, the wavelet plane $w_j^{(I)}$ can be decomposed by CLEAN 
($w_j^{(I)}$ represents the dirty map and $w_{j}^{(P)}$  the dirty beam)
into a set, denoted $\delta_j$, of weighted $\delta$-functions.
\begin{eqnarray}
\delta_j  = \{A_{j,1} \delta(x-x_{j,1}, y-y_{j,1}), A_{j,2} \delta(x-x_{j,2},
 y-y_{j,2}), \dots,  \\ \nonumber
A_{j,n_j} \delta(x-x_{j,n_j}, y-y_{j,n_j})\}
\end{eqnarray}
 where $n_j$ is the number of $\delta$-functions at the scale $j$  
and $A_{j,k}$ represents the height of the peak $k$ at the scale $j$.

 By repeating this operation at each scale, we get
a set ${\cal W}_\delta$ 
composed of weighted $\delta$-functions  found by CLEAN 
($ {\cal W}_\delta= \{\delta_1, \delta_2, \dots\}$).
If $B$ is the ideal point spread function (clean beam),
the estimation of the wavelet coefficients of the object at the scale $j$
is given by:
\begin{eqnarray}
w_j^{(E)}(x,y) = \delta_j * w_j^{(B)}(x,y) + w^{(R)}_j (x,y)  \\ \nonumber
\ \ \ \ \ \ \ \ \ \ \ = \sum_k A_{j,k}
 w_j^{(B)}(x-x_{j,k},y-y_{j,k}) + w^{(R)}_j(x,y)
\end{eqnarray}
where $w^{(R)}_j $ is the residual map.
The clean map at the full resolution is obtained by the reconstruction 
algorithm.
If we take a Gaussian function as the scaling function, and the difference 
between
two resolutions as the wavelet ($\frac{1}{2}\psi
(\frac{x}{2},\frac{y}{2})=\phi(x,y) - 
\frac{1}{2}\phi(\frac{x}{2},\frac{y}{2}$)), we find the algorithm 
proposed by
Wakker and Schwarz \cite{rest:wakker88}. The MRC algorithm in the wavelet space is:
\begin{enumerate}
\item We compute the wavelet transforms of the dirty map, the dirty beam 
and the clean beam.
\item For each scale $j$, we decompose by CLEAN the wavelet coefficients 
of the 
dirty map into a list of weighted $\delta$-functions $\delta_j$.
\item For each scale $j$, we convolve  $\delta_j$ by the wavelet 
coefficients of the clean beam and we add the residual map $w^{(R)}_j$ 
to the result in order to obtain the  wavelet coefficients of the clean map.
\item We compute  the clean map at the full resolution by using the 
reconstruction algorithm.
\end{enumerate}

 
\subsubsection{Improvements to multiresolution CLEAN.}

\index{CLEAN}
We apply CLEAN to each plane of the wavelet transform. This allows us to
detect at each scale the significant structure. The reconstructed image
 gives the estimation $\tilde{O}$ found by MRC of the object. But MRC does
not
assume that this estimation is compatible with the measured visibilities.
We want:
 \begin{eqnarray}
\mid \hat{\tilde{O}}(u,v) - V_{\mbox{m}}(u,v)\mid \ < \ \Delta_{\mbox{m}}(u,v)
\end{eqnarray}
 where $\Delta_{\mbox{m}}(u,v)$ is the error associated with the measure 
$V_{\mbox{m}}$.

To achieve this, we use the position of the
peaks determined by the MRC algorithm. We have seen that after
the use of CLEAN, we get a list of positions $\delta_j$ on each plane $j$, with
 approximate heights $A_j$. In fact, we get a nice description
 of the significant structures in the wavelet space. 
The height values are not sufficiently accurate, 
but CLEAN enhances these structures.
So we have to determine heights which reduce the error. 
We do so using Van Cittert's algorithm \cite{rest:vancittert31}
which converges, even in the presence of noise,
because our system is well regularized. Then, heights of the peaks
contained in ${\cal W}_{\delta}$ will be modified by the following
iterative algorithm:
\index{Van Cittert deconvolution}

\begin{enumerate}
\item Set $n = 0$ and ${\cal W}_{\delta}^{(0)} = {\cal W}_{\delta}$.
\item Compute $A_{j,l}^{(n+1)}  = A_{j,l}^{(n)} + 
{\cal Q}_{j,l}.{\cal W}_{\delta}^{(n)}$
so that we then have:
\begin{eqnarray*}
\delta_j^{(n+1)} = \{ A_{j,1}^{(n+1)} \delta(x-x_{j,1}, y-y_{j,1}),  
%A_{j,2}^{(n+1)} \delta(x-x_{j,2}, y-y_{j,2}), A_{j,n_j}^{(n+1)} 
%\delta(x-x_{j,n_j}, y-y_{j,n_j})\}
\end{eqnarray*}
and:
\begin{eqnarray*}
{\cal W}_{\delta}^{(n+1)} =  \{\delta_1^{(n+1)}, \delta_2^{(n+1)}, \dots\}
\end{eqnarray*}
\item $n = n + 1$ and go to step 1.
\end{enumerate}

${\cal Q}$ is the  operator that:
\begin{itemize}
\item computes the  wavelet coefficients of the clean map $w^{(C)}$ by
convolving at each scale $\delta_j^{(n)}$ by the clean beam wavelet $w_j^{(B)}$
\[w_j^{(C)} = \delta_j^{(n)} * w_j^{(B)}\] 
\item reconstructs  the estimated object $O^{(n)}$ at  full resolution
from $w^{(C)}$
\item thresholds  the negative values of $O^{(n)}$
\item computes  the residual $r^{(n)}$ by:
\[\hat{r}^{(n)} = p(V - \hat{O}^{(n)})\]
 where $p$ is a weight function which depends on the quality of the
measurement $V$ (error bars). A possible choice for $p$ is:
\begin{itemize}
\item $p(u,v) = 0$ if we do not have any information at this frequency (i.e.\ 
a frequency hole).
\item $p(u,v) = 1 - 2 \frac{\Delta_{\mbox{m}}(u,v)}{V_{\mbox{m}}(0,0)}$ 
if $\Delta_{\mbox{m}}(u,v)$
is the error associated with the measurement $V_{\mbox{m}}(u,v)$.
\end{itemize}
\item computes the wavelet transform $w^{(r^{(n)})}$ of $r^{(n)}$ 
\item extracts the wavelet coefficient of $w^{(r^{(n)})}$ which is at 
the position of the peak $A_{j,l} \delta(x - x_l, y - y_l)$.
\end{itemize}

\bigskip

The final deconvolution algorithm is:
\index{deconvolution}
\begin{enumerate}
\item Convolution of the dirty map and the dirty beam by the scaling function.
\item Computation of the wavelet transform of the dirty map which yields 
$w^{(I)}$.
\item Computation of the wavelet transform of the dirty beam which yields 
$w^{(D)}$.
\item Estimation of the standard deviation of the noise $N_0$ of the first 
plane
from the histogram of $w_0$. Since we process oversampled images, the
values of the
wavelet image corresponding to the first scale ($w_0^{(I)}$) are nearly 
always due to the noise. The histogram shows a Gaussian peak around
$0$. We compute the standard deviation of this Gaussian function,
with a 3-sigma clipping, rejecting pixels where the signal
could be significant.
\item Computation of the wavelet transform of the clean beam. We get $w^{(B)}$.
If the  clean beam is a Dirac delta, 
then $\hat{w}_j^{(B)}(u,v) = \frac{\psi(2^ju, 
2^jv)}{\phi(u, v)}$.
\item Set $j$ to 0. 
\item Estimation of the standard deviation of the noise $N_j$ from $N_0$. This
is done from the study of the variation of the noise between two
scales, with the hypothesis of a white Gaussian noise.
\item Detection of significant structures by CLEAN: we get $\delta_j$ from
$w_j^{(I)}$ and $w_j^{(D)}$. The CLEAN algorithm is very sensitive to the
noise. Step 1 of this algorithm offers more robustness. CLEAN
can be modified in order to optimize the detection. 
\item $j = j + 1$ and go to step 7.
\item Reconstruction of the clean map from ${\cal W}_{\delta}= \{\delta_1, \delta_2, \cdots\}$ by the 
iterative algorithm using Van Cittert's method.
\end{enumerate}
\index{Van Cittert deconvolution}

The limited support constraint is implicit because we put information
only at the position of the peaks, and the positivity constraint is 
 introduced in the iterative algorithm. 
We have made the hypothesis that MRC, 
by providing the coordinates of the peaks,
 gives the exact position of the information in the wavelet space and 
we limited the deconvolution problem by looking for the  height of the peaks 
which give the best results. It is a very strong limited support
constraint which allows our problem to be regularized. CLEAN is not used as a 
deconvolution algorithm, but only as a tool to detect the position of 
structures.




\section{Regularization from the Multiresolution Support}
\subsection{Noise suppression based on the wavelet transform}
\index{noise}
We have noted how, in using 
an iterative deconvolution algorithm such as  Van Cittert or
Richardson-Lucy, we define $R^{(n)}(x,y)$, the residual at iteration $n$:
\index{Richardson-Lucy deconvolution}
\index{Van Cittert deconvolution}
\begin{eqnarray}
R^{(n)}(x,y) = I(x,y) - (P * O^{(n)})(x,y)
\end{eqnarray}
 
 By using the \`a trous wavelet transform algorithm 
(\cite{starck:bij94_1,starck:phd,starck:midas}), $R^{(n)}$ 
\index{a trous wavelet transform}
\index{wavelet transform}
can be defined as the sum of its $p$ wavelet scales and the last smooth 
array:
\begin{eqnarray}
R^{(n)}(x,y) = c_{p}(x,y) + \sum_{j=1}^{p} w_j(x,y) 
\end{eqnarray}
where the first term on the right is the last smoothed array, 
and $w$ denotes a wavelet scale.
 
The wavelet coefficients provide a mechanism to extract only the significant 
structures from the residuals 
at each iteration. Normally, a large part of
these residuals are statistically non-significant. 
The significant residual (\cite{starck:mur94_1,starck:sta94_1}) is then:
\begin{eqnarray}
\bar{R}^{(n)}(x,y) = c_{p}(x,y) + \sum_{j=1}^{p} T(w_j(x,y)) w_j(x,y)
\label{eq_resi}
\end{eqnarray}
 
\noindent $T$ is a function which is defined by:
\begin{eqnarray}
T(w) = \left\{
  \begin{array}{ll}
  1 & \mbox{ if w is significant} \\
  0 & \mbox{ if w is non-significant} \\
  \end{array}
  \right.
\end{eqnarray}
 
Assuming that the noise follows a given law,  
 $w_j(x,y)$ is significant if the probability that the wavelet coefficient
is due to noise is small. 
\begin{eqnarray}
w_j(x,y) \mbox{ is significant if } \left\{ \begin{array}{ll}
  P(W > w_j(x,y)) < \epsilon & \mbox{ if }   w_j(x,y) \geq 0 \\
  P(W < w_j(x,y)) < \epsilon & \mbox{ if }   w_j(x,y) < 0 \\
  \end{array}
  \right.
\end{eqnarray}

\subsection{Noise suppression based on the multiresolution support}
\index{noise}
\index{multiresolution support}
\index{support, multiresolution}

\subsubsection{The multiresolution support}
The multiresolution 
support \cite{starck:sta95_1} of an image describes in a
logical or boolean way whether an image $I$ contains information at a 
given scale $j$ and at a given position $(x,y)$.
If $M^{(I)}(j,x,y) = 1$ (or {\it true}), then $I$ contains information at 
scale $j$ and at the position $(x,y)$.
$M$ depends on several parameters:
\begin{itemize}
\item The input image.
\item The algorithm used for the multiresolution decomposition.
\item The noise.
\item All constraints we want the support additionally to satisfy.
\end{itemize}
Such a support results from the data, the treatment (noise
estimation, etc.), and from knowledge on our part of the objects contained
in the data (size of objects, alignment, etc.). In the most general case, 
a priori information is not available to us.

The multiresolution support of an image is computed in several steps:
\begin{enumerate}
\item We compute the wavelet transform of the  image.
\item We estimate the noise standard deviation at each scale.  We
deduce the statistically significant level at each scale. 
\item The binarization of each scale leads to the multiresolution
support.
\item Modification using a priori knowledge (if desired).
\end{enumerate}
Step 4 is optional. A typical use of a priori knowledge is the
suppression of isolated pixels  in the multiresolution support in the 
case where the image is obtained with a point spread function (PSF) of
more than one pixel. Then we can be sure that isolated pixels are
residual noise which has been detected as significant coefficients.
 If we use a pyramidal algorithm or a nonlinear multiresolution transform, the same
method can be used.

The multiresolution support is obtained by detecting 
at each scale the significant coefficients.  The multiresolution support is 
defined by:
\begin{eqnarray}
M(j,x,y) = \left\{
  \begin{array}{ll}
  \mbox{ 1 } & \mbox{ if }   w_j(x,y) \mbox{ is significant} \\
  \mbox{ 0 } & \mbox{ if }  w_j(x,y) \mbox{ is not significant}
  \end{array}
  \right.
\end{eqnarray}

  
\subsubsection{Regularization}

In the approach presented in the preceding section, 
a wavelet coefficient is significant
if it is above a threshold.  Therefore a coefficient which is 
less than this threshold is not considered, even if a significant 
coefficient had
been found at the same scale as this coefficient, during previous 
iterations; and consequently we were justified in thinking that we had found
signal at this scale, and at this position.  Arising out of this approach,
it follows that the wavelet coefficients of the residual image could
contain signal, above the set threshold, which is ignored.  
 
In order to 
conserve such signal, we use the notion of multiresolution support.
Whenever we find signal at a scale $j$ and at a position $(x,y)$, we will 
consider that this position in the wavelet space belongs to the 
multiresolution support of the image.
 
Eqn.\ \ref{eq_resi} becomes:
\begin{eqnarray}
\bar{R}^{(n)}(x,y) = c_{p}(x,y) + \sum_{j=1}^{p} M(j,x,y) \  w_j(x,y)
\label{eq_sup_resi}
\end{eqnarray}
 
An alternative approach was outlined in \cite{starck:mur95_2} and 
\cite{starck:sta95_1}:
 the support was
initialized to zero, and built up at each iteration of the restoration 
algorithm.  Thus in eqn.\ \ref{eq_sup_resi} above, 
$M(j,x,y)$ was additionally
indexed by $n$, the iteration number.  In this case, the support was
specified in terms of significant pixels at each scale, $j$; and in addition
pixels could become significant as the iterations proceeded, but could not
be made non-significant.  In practice, we have found both of these strategies
to be equally acceptable.

\subsubsection{Regularization of Van Cittert's Algorithm}
\index{Van Cittert deconvolution}
 
Van Cittert's iteration \cite{rest:vancittert31} is:
\begin{eqnarray}
O^{(n+1)} (x,y) = O^{(n)} (x,y) + \alpha{R}^{(n)}(x,y) 
\end{eqnarray}
with ${R}^{(n)}(x,y) =  I^{(n)}(x,y) - (P * O^{(n)}) (x,y)$.
Regularization using significant structures leads to:
\begin{eqnarray}
O^{(n+1)} (x,y) = O^{(n)} (x,y) + \alpha {\bar{R}}^{(n)}(x,y) 
\end{eqnarray}
The basic idea of our method consists of detecting, at each scale,  
structures of a given size in
the residual $R^{(n)}(x,y)$ and putting them in the restored 
image $O^{(n)}(x,y)$. The
process finishes when no more structures are detected. Then, we have separated
the image $I(x,y)$ into two images $\tilde O(x,y)$ and $R(x,y)$.
 $\tilde O$ is the restored image, which ought not to contain any
noise, and  $R(x,y)$ is the final residual which ought  not to contain any 
structure. $R$ is our estimate of the noise $N(x,y)$.
 
\subsubsection{Regularization of the One-Step Gradient Method}
 
The one-step gradient iteration is:
\begin{eqnarray}
O^{(n+1)} (x,y) = O^{(n)} (x,y) + P(-x,-y) * {R}^{(n)}(x,y) 
\end{eqnarray}
with ${R}^{(n)}(x,y) = I(x,y) - (P * O^{(n)}) (x,y)$.
Regularization by significant structures leads to:
\begin{eqnarray}
O^{(n+1)} (x,y) = O^{(n)} (x,y) +  P(-x,-y) * {\bar{R}}^{(n)}(x,y)
\end{eqnarray}
 
\subsubsection{Regularization of the Richardson-Lucy Algorithm}
\index{Richardson-Lucy deconvolution} 

From eqn.\ \ref{eqn_3_first}, 
we have $I^{(n)}(x,y) =  (P * O^{(n)}) (x,y)$. Then
 $R^{(n)}(x,y) = I(x,y) - I^{(n)}(x,y) $, and 
hence $ I(x,y) = I^{(n)}(x,y) + R^{(n)}(x,y)$.\\
The Richardson-Lucy equation is:
\begin{eqnarray}
O^{(n+1)}(x,y) = O^{(n)}(x,y) [ \frac{I^{(n)}(x,y) + 
               R^{(n)}(x,y)}{I^{(n)}(x,y)} * P(-x,-y) ]
\end{eqnarray}
and regularization leads to: 
\begin{eqnarray}
O^{(n+1)}(x,y) = O^{(n)}(x,y) [ \frac{I^{(n)}(x,y) + 
               {\bar{R}}^{(n)}(x,y)}{I^{(n)}(x,y)} * P(-x,-y) ]
\end{eqnarray}
 
\subsubsection{Convergence}
 
The standard deviation of the residual decreases until no more
significant structures are found. Convergence can be estimated
from the residual. The algorithm stops when a user-specified threshold is
reached:
 
\begin{eqnarray}
(\sigma_{{R}^{(n-1)}} - \sigma_{{R}^{(n)}})/(\sigma_{{R}^{(n)}})   < \epsilon
\end{eqnarray}


\section{Regularization using a Markov Model}
\subsection{Introduction}

Let us briefly review the ingredients of the proposed regularization method.
The basic procedure uses a Markov random field as the prior model, 
the relation (\ref{eqn_3_first}) for image formation consisting typically of blur and superposition
of Gaussian noise, and Bayes' formula to obtain the posterior distribution 
$P(x/y)$. 

\subsubsection*{Random Markov field}

A random sequence $x$ is called a Markov random field if for each site $s$:
\begin{eqnarray}
P({x}) > 0 && \forall {x}\in \Omega  
\end{eqnarray}
\begin{eqnarray}
P(x_s \mid x_t;t\in S-\{s\}) = P(x_s \mid x_t;t\in{{\cal V}_s}) 
\end{eqnarray}
where $\Omega$ represents all possible configurations and $S$ is the dimension of
the field $x$.
At every site $s$ of the field $x$, the conditional probability  
depends on a neighborhood ${\cal V}_s$ which is defined by the neighbors $t$ of the 
site $s$. Note that ${\cal V}_s$ increases with the order of the model.

\subsubsection*{Examples of models}

The four-neighbor system is defined as follows:

\begin{picture}(100,120)(0,0)
\put(50,0){\circle{5}}
\multiput(0,50)(100,0){2}{\circle{5}}
\put(50,50){\circle*{5}}
\put(55,55){site s}
\put(50,100){\circle{5}}
\put(150,55){4 NEIGHBOR MODEL}
\end{picture}

Because the edges of the image are not only parallel to the axes, there seems
to be need to include diagonal neighbor pixels.
Then, the four-neighbor model can be improved as follows:

\begin{picture}(100,120)(0,0)
\multiput(0,0)(50,0){3}{\circle{5}}
\multiput(0,50)(100,0){2}{\circle{5}}
\put(50,50){\circle*{5}}
\put(55,55){site s}
\multiput(0,100)(50,0){3}{\circle{5}}
\put(150,55){8 NEIGHBOR MODEL}
\end{picture}

\subsubsection*{Gibbs distribution}

The prior distribution $P({x})$ can be interpreted as a Gibbs energy.
Then, $x$ is a Markov random field if 
$P({x})$ is a Gibbs distribution such that:
\begin{eqnarray} 
P({x}) = \frac{1}{Z}\exp(-U({x})) 
\end{eqnarray}
where $Z$ is a partition function and $U({x})$ a prior energy such that:
\begin{eqnarray} 
U({x}) = \sum_{c \in {\cal C}} V_c(x)
\end{eqnarray}
where $V_c(x)$ are potentials functions and $c$ is a clique which is 
defined as a pair of adjacent pixels. 

\subsubsection*{Potential function and line process}

In order to preserve edges, 
the use of a {\it line process} was introduced by Geman and Geman \cite{Geman84}. 
In practice, a line process is defined via a potential function $\phi$
which has particular properties (see \cite{Geman92}).

Suppose $\phi(u)$ has the following properties on $[0,+\infty[$:
\begin{itemize}
\item $\phi(0)=0$
\item $\phi(\sqrt u)$ concave
\item $\lim_{u \rightarrow +\infty} \phi(u)=1$
\end{itemize}

Then, there exists a function $\psi(l)$ defined on an interval [0,L] 
such that: 
\begin{eqnarray} 
\phi(u) = \inf_{0\leq l\leq L}(lu^2+\psi(l))
\label{eqn_vdl}
\end{eqnarray}

and such that $\psi(l)$ has the properties:
\begin{itemize}
\item $\psi(0)=1$
\item $\psi(L)=0$ 
\item $\psi(l)$ strictly decreasing.
\end{itemize}

The line process is defined as the derivative of  
$\phi(\sqrt u)$:
\begin{eqnarray} 
l = \phi'(\sqrt u) 
\end{eqnarray}

\subsubsection{Posterior modeling}
 
In the context of Bayesian estimation, the posterior distribution  
$P({x \mid y})$ can be written as:
\begin{eqnarray}
P({x \mid y}) \propto P({y \mid x})P({x}) 
\end{eqnarray}
where 
\begin{eqnarray} 
P({y \mid x}) \propto \exp(-U({y \mid x})) 
\end{eqnarray}
and
\begin{eqnarray}
P({x}) \propto \exp(-U({x}))
\end{eqnarray}
Then, the posterior $P({x \mid y})$ is also a Gibbs energy such that:
\begin{eqnarray}
U({x \mid y}) = U({y \mid x}) + U({x})
\end{eqnarray}
The traditional choice in image restoration is:
\begin{eqnarray} 
U({y \mid x}) = \frac{\|{y-Hx}\|^2}{2\sigma^2}
\end{eqnarray}
In the first order case, the prior $P({x})$ is defined such that:
\begin{eqnarray} 
U({x}) = \sum_{cliques} \phi(x_r-x_s)
\end{eqnarray} 
where $\phi$ is the potential function and $(x_s-x_r)$ is the difference 
between the values $x_r$ and $x_s$ of the two neighbors inside the 
clique $c$.
The solution is estimated by maximizing the posterior distribution
$P({x \mid y})$.
Then, the energy $U({x \mid y})$ must be minimized.
\begin{eqnarray} 
U({x \mid y}) = \frac{\|{y-Hx}\|^2}{2\sigma^2}
               + \lambda \sum_{cliques} \phi(x_r-x_s) 
\label{eqn_cr}	       
\end{eqnarray}
where $\lambda$ is the regularizing parameter.

\subsection{Application}

\subsubsection*{Minimization of the prior energy}

The difficulty is to minimize the non-quadratic energy $U(x)$.
From the work of Geman and Reynolds \cite{Geman92},
the minimization of $U(x)$ is equivalent to minimizing $U(x \mid l)$ such
that:
\begin{eqnarray}
\min_{x}(U({x})) = \min_{x,l}(U({x,l}))
\end{eqnarray}
where $l$ is the vector of the line variables $l_c$.
According to equation (\ref{eqn_vdl}), it follows that $U(x \mid l)$ can 
be written
as:
\begin{eqnarray} 
U({x,l}) = \sum_{cliques\,c} l_c (x_r-x_s)^2 + \psi(l_c)
\label{eqn_eg}
\end{eqnarray}
Note that the regularization becomes 
``half-quadratic'' (see \cite{BlancFeraud96})
by using equation (\ref{eqn_eg}):
\begin{itemize}
\item With $l$ fixed, $U({x,l})$ is quadratic in $x$. The
minimization in $x$ reduces to the resolution of a linear system.
\item With $x$ fixed, the minimum $\hat l_c$ is given by the expression
$\hat l_c=\phi'(u)/2u$ where $u=(x_r-x_s)$.
\end{itemize}
We suppose that the variables $\hat l_c$ do not interact with each other.
In fact, these {\it line variables} map the discontinuities (or the edges) of
the image $x$. $\hat l_c$ takes a value near zero at the edges and a 
value $L$
in homogeneous areas.

\subsubsection*{Line variables system}

For the first order Markov case, a line variable is labeled as an arrow 
between two horizontal or vertical and adjacent pixels $(x_r,x_s)$.
Then, each arrow is associated with a first order clique.


\begin{picture}(100,120)(0,0)
\put(50,0){\circle{5}}
\multiput(0,50)(100,0){2}{\circle{5}}
\put(50,50){\circle*{5}}
\put(55,55){(x,y)}
\put(55,105){(x,y+1)}
\put(55,5){(x,y-1)}
\put(105,55){(x+1,y)}
\put(5,55){(x-1,y)}
\put(50,100){\circle{5}}
\put(50,95){\vector(0,-1){40}}
\put(50,45){\vector(0,-1){40}}
\put(95,50){\vector(-1,0){40}}
\put(45,50){\vector(-1,0){40}}
\put(150,55){FOUR-NEIGHBOR SYSTEM}
\end{picture}


The four neighbor system can be improved by including diagonal adjacencies.

\begin{picture}(100,120)(0,0)
\multiput(0,0)(50,0){3}{\circle{5}}
\multiput(0,50)(100,0){2}{\circle{5}}
\put(50,50){\circle*{5}}
\multiput(0,100)(50,0){3}{\circle{5}}
\put(105,105){(x+1,y+1)}
\put(5,-5){(x-1,y-1)}
\put(105,-5){(x+1,y-1)}
\put(5,105){(x-1,y+1)}
\put(50,95){\vector(0,-1){40}}
\put(50,45){\vector(0,-1){40}}
\put(95,50){\vector(-1,0){40}}
\put(45,50){\vector(-1,0){40}}
\put(95,95){\vector(-1,-1){40}}
\put(45,45){\vector(-1,-1){40}}
\put(95,5){\vector(-1,1){40}}
\put(45,55){\vector(-1,1){40}}
\put(150,55){EIGHT-NEIGHBOR SYSTEM}
\end{picture}


\subsubsection*{The potential function}

Concerning the choice of $\phi$, the following convex function proposed in 
\cite{Brette96} is used:
\begin{eqnarray} 
\phi_{\delta}(u) = |u/\delta| - \ln(1+|u/\delta|) 
\label{eqn_phi}
\end{eqnarray}
where $u=(x_r-x_s)$ and $\delta$ is a scaling parameter. 
An example is given for $\delta=500$ in Figure~\ref{fig_phi}. It shows 
that $\phi$ is quadratic with $u<<\delta$ and linear with $u>>\delta$.
\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=fig_markov_phi.ps,bbllx=2.5cm,bblly=13cm,bburx=19.5cm,bbury=25.5cm,width=8cm,height=8cm,clip=}
}}
\caption{}
\label{fig_phi}
\end{figure}
The derivative is equal to
$\phi'_{\delta}(u)=u/\delta(|u|+\delta)$.
Note that updating the line variables is a simplified operation by using the following
formula:
\begin{eqnarray} 
\hat l_c = \phi'_{\delta}(u)/2u = \frac{1}{2\delta}/(\delta + |u|) 
\end{eqnarray}

 
\subsubsection*{The prior energy formula} 
 
In the case of the four nearest neighbors, the prior energy is defined as: 
\begin{eqnarray} 
U({x})& = &\sum_{vertical\, cliques} \phi_{\delta}(I_{y,x}-I_{y+1,x}) \\
       & &  + \sum_{horizontal\, cliques} \phi_{\delta}(I_{y,x}- I_{y,x+1})
\label{eqn_e}
\end{eqnarray}
where $I_{y,x}$ is the pixel intensity in image $I$ at row $y$ and column $x$.


By adding the following expressions to the terms in equation (\ref{eqn_e}), we
obtain the energy $U({x})$ of the eight neighbor system:
\begin{eqnarray} 
\sum_{diagonal\, cliques} \phi_{\delta}(I_{y,x}- I_{y+1,x+1})
\end{eqnarray}
and 
\begin{eqnarray} 
\sum_{diagonal\, cliques} \phi_{\delta}(I_{y,x}- I_{y-1,x+1})
\end{eqnarray}

Instead of using a stochastic approach, we use a single site update algorithm 
\cite{Brette96} in order
to minimize the half-quadratic criterion (\ref{eqn_cr}).
The solution is computed by visiting the entire set of pixels in a determined
fashion (checkerboard) to update each value $x_{ij}$ of the estimated solution
$x$ at row $i$ and column $j$.
We know that the energy $U(x)$ is quadratic as a function of $x_{ij}$.
Its minimum value is reached at $m_{ij}$:
\begin{eqnarray}
m_{ij} = x_{ij} + \frac{[{H^ty}]_{ij} - [{H^tHx}]_{ij} - 2\sigma^2\lambda 
\sum l_c(x_{ij}-x_c)}{[{H^tH}]_{ij,ij} + 2\sigma^2\lambda\sum l_c}
\label{eqn_corr}
\end{eqnarray} 
where the sums extend to the neighborhood of the currently visited pixel $x_{ij}$.
The algorithm is initialized with an image where all pixels are equal to zero.

\subsubsection*{Parameter estimation}

% \subsubsection{Scaling parameter $\delta$}

This parameter allows to fix the threshold under which the smoothness of the
solution is preserved and above which discontinuities or edges stay in the
estimated solution.
The value $\delta$ is estimated from the observed image $y$ by looking at the
evolution of edges between adjacent pixels. In fact, one method of selecting
$\delta$
would be to determine the global maximal difference between two adjacent pixels 
for all possible cliques of the observed image.
If $\delta$ is too high, then the estimated solution will be smooth.

% \subsubsection{Regularizing parameter $\lambda$}

This parameter balances fidelity to the prior constraints and fidelity to the
data. In every experiment, $\lambda$ is empirically tuned to obtain 
visually good results. In fact, since appropriate values for $\delta$ are more or
less estimated, the value for $\lambda$ is not an evident choice.
However, if $\lambda$ is too high, the solution is over-regularized and if
$\lambda$ is too small, the solution is not stabilized.


\clearpage
\newpage

\section{Multiscale Entropy Deconvolution}
\subsection{The principle}
The standard maximum entropy method (MEM) has been described in the preceding
chapter. The most realistic solution is that which minimizes 
the the amount of information,
but remains compatible with the data. 
By the MEM method, minimizing the information
is equivalent to maximizing the entropy and the   functional to minimize is 
\begin{eqnarray}
J(O)= 
\sum_{k=1}^N
 \frac{(I_k-(P*O)_k)^2}{2\sigma_I^2} - \alpha H(O)
\end{eqnarray}
where $H$ is either the Frieden or the Gull and Skilling entropy. 

Using the Shannon entropy or the multiscale entropy, minimizing the information
is equivalent to  minimizing 
the entropy and the functional to minimize is 
\begin{eqnarray}
J(O)= \sum_{k=1}^N \frac{(I_k-(P*O)_k)^2}{2\sigma_I^2} + \alpha H(O)
\end{eqnarray}

We have seen that in the case of Gaussian noise, $H$ is given by the 
energy of the wavelet coefficients. We have
\begin{eqnarray}
J(O)= \sum_{k=1}^N
 \frac{(I_k-(P*O)_k)^2}{2\sigma_I^2} + \alpha \sum_{j=1}^{l} \sum_{k=1}^{N_j} \frac{w_{j,k}^2}{2 \sigma_j^2}
\end{eqnarray}
where $\sigma_j$ is the noise at scale $j$, $N_j$ the number of pixels at the
scale $j$, $\sigma_I$ the noise standard deviation in the data, and $l$ the number
of scales.

Rather than minimizing the amount of information in the solution, we may
prefer to minimize the amount of information which can be due to the noise.
The function is now:
\begin{eqnarray}
J(O)= \sum_{k=1}^N
 \frac{(I_k-(P*O)_k)^2}{2\sigma_I^2} + \alpha H_n(O)
\end{eqnarray}
Using the N2-MSE approach, $H_n$ is defined by  
\begin{eqnarray}
H_n(w_{j,k}) =  \sum_{j=1}^{l} \sum_{k=1}^{N_j}  \int_{0}^{\mid w_{j,k} \mid }
 p_n(\mid w_{j,k} \mid - u) ( \frac{\partial h(x)}{\partial x} )_{x=u} du
\end{eqnarray}
which gives for Gaussian noise
\begin{eqnarray}
H_n(X) = \sum_{j=1}^{l} \sum_{k=1}^{N_j} \frac{1}{\sigma_j^2} \int_{0}^{\mid w_{j,k} \mid} u 
         \mbox{ erf}(\frac{\mid w_{j,k} \mid -u}{\sqrt{2} \sigma_j})
\end{eqnarray}

The solution is found by computing the gradient $\nabla(J(O))$ 
and performing the following iterative schema:
\begin{eqnarray}
O^{n+1} = O^{n} - \gamma \nabla(J(O^n))
\label{eq_iter1}
\end{eqnarray}

As for the multiscale entropy filtering, there are several ways to use
the parameter $\alpha$. In the same way,
 we can consider an $\alpha_j$ per scale, and introduce a 
kind of adaptive regularization, depending on the signal-to-noise ratio
 of the input data wavelet coefficients.
 
\subsection{The parameters}
\label{sect_mse_param}
In order to introduce flexibility in the way we restore the 
data, we introduce two parameters $\beta_{j,k}$ and $\alpha_{j,k}$ which
allow us to weight respectively the two terms of the equation to 
be minimized:
 
\begin{eqnarray*}
J(O) = \frac{1}{2\sigma_I^2} \sum_{k=1}^N (c_{l,k}(R)
        + \sum_{j=1}^{l} \beta_{j,k} w_{j,k}(R) )^2
        +  \sum_{j=1}^{l} \sum_{k=1}^{N_j} \alpha_{j,k} h(w_{j,k}(O))
\end{eqnarray*}
where $R = I - P * O$, and $R = c_{l,k}(R) + \sum_{j=1}^{l} w_{j,k}(R)$ 
($w_{j,k}(R)$ are the wavelet coefficients of $R$ using the \`a trous 
algorithm, and $w_{j,k}(O)$ are the wavelet coefficients of $O$).

We consider three approaches for estimating $\beta_{j,k}$
\begin{enumerate}
\item no weighting: $\beta_{j,k} = 1$ 
\item soft weighting: $\beta_{j,k} = p_s(w_{j,k}(I))$  \\
In this case, $\beta_{j,k}$ is equal to the probability that the input
data wavelet coefficient is due to signal (and not to noise).  
\item hard weighting: $\beta_{j,k} = 0$ or $1$ depending on $p_n(w_{j,k}(I))$
($p_n(w_{j,k}(I)) = 1. - p_s(w_{j,k}(I))$).
This 
corresponds to using only significant input data wavelet coefficients. If $M$
is the multiresolution support 
of the input image $I$, then $\beta_{j,k} = M(j,k)$.
\end{enumerate}

$\alpha_{j,k}$ is the product of three values: 
$\alpha_{j,k} = \alpha_u \alpha_{j} \beta^\prime_{j,k}$.
\begin{itemize}
\item{$\alpha_u$ } is a user parameter (defaulted to 1) which allows us
to control the smoothness of the solution. Increasing $\alpha_u$ produces
a smoother solution.
\item{$\alpha_j$ } is a constant which depends only on the PSF.
\item{$\beta^\prime_{j,k}$ } depends on the input data and can take the
following value:
\begin{enumerate}
\item no regularization ($\beta^\prime_{j,k} = 0$):   
only the first term of the functional is minimized.
\item no protection from regularization ($\beta^\prime_{j,k} = 1$): the regularization is applied at all positions and
at all the scales.
\item soft protection ($\beta^\prime_{j,k} = p_n(w_{j,k}(I))$): 
the regularization becomes adaptive,
depending on the probability that the input wavelet coefficient is due 
to noise.
\item hard protection ($\beta^\prime_{j,k} = 0$ or $1$ depending 
on $p_n(w_{j,k}(I))$). If $M$
is the multiresolution support 
of the input image $I$, then $\beta_{j,k} = 1 - M(j,k)$.
\item Soft + hard protection: 
($\beta^\prime_{j,k} = 0$ or $p_n(w_{j,k}(I))$ 
depending on $p_n(w_{j,k}(I))$).
\end{enumerate}

\end{itemize}
 
We easily see that choosing a hard weighting and no regularization leads 
to deconvolution from the multiresolution support.

The problem is now to find how to calculate the $\alpha_j$ values. Taking
all $\alpha_j$ equal to $1$ would mean that we try to restore all bands
in the same way. However if the PSF is very large, structures which may 
appear roughly the size of the pixel are certainly artifacts due to the noise.
At the contrary, if the PSF is very extended, there is no reason to not
consider as true a compact structure in the solution. This reason leads
us
to consider that the regularization should not be applied in the same way
at all scales, but should depend on the PSF. Since at each iteration the
solution is updated by adding a part the residual (which contains the noise)
convolved by the PSF, we estimate $\alpha_j$ by the following method:
\begin{itemize}
\item we generate a random noise $N_r$ of standard deviation equal to 1.
\item we convolve it by the PSF: $C_r = N_r * P$.
\item we take the wavelet transform of $C_r$.
\item we take the wavelet transform of $N_r$.
\item we calculate the standard deviation at each scale of $C_r$: $\sigma^r_j (w_j(C_r))$
\item we calculate the standard deviation at each scale of $N_r$: $\sigma^e_j (w_j(N_r))$
\item we calculate the value: $a_j =  {\sigma_j^e \over  \sigma^r_j}$
\item we normalize $a_j$ by $a_j = a_j / max(a_i)$ (for $i=1..l$).
\end{itemize}
By this method, the regularization will be
stronger at small scales if the PSF is large.

\subsubsection{The Intrinsic Correlation Function}
In many cases, there is no sense to try to deconvolve an image at the resolution
of the pixel (especially when the PSF is very large). The idea to limit the 
resolution is relatively old, because it is already this concept which 
is used in the CLEAN algorithm \cite{rest:hogbom74}. Indeed the Clean-Beam
fixes the resolution in the final solution. This principle was also 
developed by Lannes \cite{rest:lannes87} under a different form. 
Finally this concept have been re-invented,  first by
Gull and Skilling, who have called the Clean-Beam 
the {\em Intrinsic Correlation Function} (ICF), and more recently by
Magain \cite{rest:magain98}. 

The ICF is usually a Gaussian, but in some cases it may be useful to
take another function. For example, if we want to compare two images $I_1$ and
$I_2$ which are obtained with 
two wavelengths or with two different instruments,
their PSFs $P_1$ and $P_2$ will certainly be different. The classic way would
be convolve $I_1$ with $P_2$ and $I_2$ with $P_1$, so we are sure that
both are at the same resolution. But unfortunately, we lose some resolution.
Deconvolving both images is generally not possible because we can never be sure
that both solutions $O_1$ and $O_2$ will have the same resolution. 

A solution would be to 
deconvolve only the image which has the worse resolution
(say $I_1$), and to limit the deconvolution to the second image resolution ($I_2$).
Then, we just have to take $P_2$ for the ICF. The deconvolution problem is to
find $\tilde O$ (hidden solution) such that:
\begin{eqnarray}
I_1 = P_1 * P_2 * \tilde O
\end{eqnarray}
and our real solution $O_1$ at the same resolution as $I_2$ is just obtained
by convolving $\tilde O$ by $P_2$. $O_1$ and $I_2$ can then be compared.

Introducing an ICF $G$ in the deconvolution equation leads to
just considering a 
new PSF $P^\prime$ which is the convolution between $P$ and $G$.
The deconvolution is carried out using $P^\prime$, and the solution must be 
reconvolved by $G$ at the end. By this way, the solution has a limited 
resolution, but aliasing may occur during the iterative process, and it is
not sure that the artifacts will disappear afer the re-convolution with $G$.
Magain \cite{rest:magain98} has proposed an original alternative to this
problem, by assuming that the  PSF can be consider as the convolution
product of tho terms, the ICF $G$ and an unknow $S$, $P=G*S$. Using
$S$ instead of $P$ in the deconvolution process, and a suffisant large 
FWHM value for $G$  imply that the Shannon sampling theorem is never
violated. But the problem is now to calculate $S$, knowing $P$ and $G$,
which is again a deconvolution problem. Unfortunately, 
this delicate point was not discussed in the original paper. Propagation of
the error on $S$ estimation in the final solution has also until now never
been investigated, but this approach seems promising.

\subsubsection{ICF calculation}

This section describes how to calculate the Full Width at Half 
Maximum for a given sampling, in order to not violate the Shannon
sampling theorem. Gaussian functions are generally chosen for the ICF. 
The resolution to
achieve is fixed by its standard deviation, or its Full Width at Half 
Maximum (FWHM=2.34$\sigma$). As the Fourier transform of a Gaussian 
of standard deviation $\sigma$ is
also a Gaussian of standard deviation $\sigma_\nu = {N \over 2\pi \sigma}$,
($N$ being the number of pixels), we can estimate the smallest FWHM which 
does not violate the Shannon sampling theorem. It is impossible in theory,  
but in practice we can consider that values under a given $\epsilon$ have
no computation effect. The Shannon theorem is experimentally
respected if 
\begin{eqnarray}
\exp{ {\nu^2 \over 2 \sigma_{\nu}^2}} < \epsilon \mbox{ when } u > {N \over 2}
\end{eqnarray}
For $u = {N \over 2}$, we have:
$
\exp{ -\pi^2\sigma^2 \over 2 } < \epsilon
$ \\
Then the smallest ICF standard deviation $\sigma_{g}$ is given by
\begin{eqnarray}
\sigma_g = \sqrt{-2 \log{\epsilon} \over \pi^2}
\end{eqnarray}
Table~\ref{sigmag} gives the $\sigma_g$ values for different values
of $\epsilon$. If the resolution to achieve is smaller than $\sigma_g$,
it means that the solution sampling must be fainter than the data sampling.

\begin{table}[hbt]
\caption{ICF Standard deviation.}
\begin{center}
\begin{tabular}{ccc} \hline \hline
$\epsilon$     & $\sigma_g$  & FWHM       \\ \hline \hline
 $10^{-3}$      & 1.18    &   2.77     \\
$10^{-4} $       & 1.37    &   3.20     \\
$10^{-5} $       & 1.53    &   3.57     \\
$10^{-7} $       & 1.81    &   4.23     \\
$10^{-10}$      & 2.16    &   5.05     \\
$10^{-20}$      & 3.05    &   7.15     \\  \hline \hline
\end{tabular}
\end{center}
\label{sigmag}
\end{table}


 



