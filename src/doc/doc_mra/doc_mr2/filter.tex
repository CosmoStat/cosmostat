% Note that $H_s(X) + H_n(X)$ is always equal to $H(X)$. 
% For Gaussian noise, the functional to minimize becomes
% \begin{eqnarray}
%J(X) = \sum_{pixels} \frac{{(Y-X)}^{2}}{2 {\sigma}^{2}} + {\alpha} (H_s(X)+H_n(X))
%\end{eqnarray}
%If we want to preserve features with high signal-to-noise ratio from the
%regularization, we just omit $H_s(X)$ and we get
%\begin{eqnarray}
%J(X) = \sum_{pixels} \frac{{(Y-X)}^{2}}{2 {\sigma}^{2}} + {\alpha} H_n(X)
%\end{eqnarray}
%We seek a solution which minimizes the amount of information which could
%be due to the noise.

\chapter{Multiscale Entropy Applied to Filtering}
\index{filtering}
\section{Introduction}
\label{ch_filter}

 The wavelet transform (WT) has been widely used in recent times and
furnishes a new approach for describing and modeling  data. Using wavelets,
a signal can be decomposed into components of different scales.  
There are many 2D WT algorithms \cite{starck:book98}. The most well-known are 
perhaps the orthogonal
wavelet transform proposed by Mallat \cite{wave:mallat89}, and its biorthogonal
version \cite{wave:cohen92}. These methods are based on the principle of
reducing 
the redundancy of the information in the transformed data. Other WT algorithms
exist, such as the Feauveau algorithm \cite{wave:feauveau} (which is an 
orthogonal
transform using an isotropic wavelet), or the \`a trous algorithm which 
is non-orthogonal and
furnishes a very redundant dataset \cite{wave:hol89}. All these methods have 
advantages and
drawbacks. Following the content of the data, and the nature of the noise,
each can be considered as optimal. 

Once the vision model is
chosen, the second fundamental point is to estimate the noise behavior in
the transformed data. Linear transforms have in this case the advantage of
allowing robust estimation of noise variance. But again, different strategies
can be employed, which include soft or hard thresholding 
\cite{rest:donoho93_1,rest:donoho93_2}, 
and in these latter cases threshold level estimation
\cite{starck:sta94_4,rest:moulin99,rest:donoho93_1,rest:krim92,wave:chipman97,wave:amato97,wave:nason94,wave:nason96,wave:nason96}.

We review in the second section the algorithms which can be used for 
a multiresolution decomposition (we call these vision models in the 
sequel), and which strategies can be used for treating the noise, once
the data have been transformed. Then we introduce in section 3 the 
Multiscale Entropy Filtering method (MEF), and present a large number
of examples. Results of a set of simulations are presented and discussed
in section 4 in order to compare the MEF method to other standard wavelet-based
methods. Finally, we discuss why a single vision model is often not 
sufficient 
to describe the data, and how the combination of several vision models
can improve the result. This leads to the concept of a multiple vision model. 
 
\section{Multiresolution and Filtering}
This section reviews different strategies available for wavelet 
coefficient filtering.  A range of important and widely-used transform
and filtering approaches are used.  

\subsection{The choice of the multiresolution transform}
\begin{itemize}

\item The (bi-) orthogonal wavelet transform.

This wavelet transform \cite{wave:mallat89}, often referred to 
as the Fast Wavelet Transform (FWT),
is certainly the most widely used among available 
discrete wavelet transform algorithms. 
It is a non-redundant representation of the information. 
An introduction to this type of transform can be found in \cite{wave:strang96,wave:daube92}.

An example is the Haar wavelet transform which consists of using a 
wavelet defined by
\[\begin{array}{ll}
\psi(x)  = 1               & \mbox{ if } 0 \leq x < \frac{1}{2} \\
\psi(x) = -1               & \mbox{ if } \frac{1}{2} \leq x < 1 \\
\psi(x) = 0                & \mbox{ otherwise}
\end{array}\]
A large class of orthogonal wavelet functions are available.

\item The Feauveau wavelet transform.

Feauveau \cite{wave:feauveau} introduced quincunx analysis based on
 Adelson's work \cite{wave:adelson87}.
 This analysis is not dyadic and 
allows an image decomposition with a resolution factor equal to $\sqrt 2$. 
By this method, we have only one wavelet image at each scale, and not three
as in the previous method.

\item The \`a trous algorithm \cite{wave:hol89}.
 
The wavelet transform of an image by this algorithm
produces, at each scale $j$, a set $\{w_j\}$.  This has 
the same number of pixels as the image. Furthermore, using
a wavelet defined as the difference between the scaling functions
of two successive scales 
(${1 \over 2} \psi({x \over 2}) = \phi(x) - \phi({x \over 2})$),
the original image
$c_0$ can be expressed as the sum of all the wavelet scales and the
 smoothed array $c_{l}$:
\begin{eqnarray}
c_0 = c_{l} + \sum_{j=1}^{l} w_j
\end{eqnarray}
and a pixel at position $x,y$ can be expressed also as the sum of all the 
wavelet coefficients at this position, plus the smoothed array:
\begin{eqnarray}
c_{0,k} = c_{l,k} + \sum_{j=1}^{l} w_{j,k}
\end{eqnarray}

\item The multiresolution median transform.
The median transform is nonlinear, and offers advantages for robust 
smoothing (i.e.\ the effects of outlier pixel values are mitigated).
The multiresolution median transform \cite{starck:sta96_2} (which is not 
a wavelet transform) consists of a series ($c_1$, ..., $c_p$) of smoothings of
the input image, with successively broader kernels. Each resolution scale $w_j$
is constructed from differencing two successive smoothed images 
($w_j = c_{j-1} - c_j$).
For integer input image values, this transform can be carried out in 
integer arithmetic only which may lead to computational savings.
As in the case of the \`a trous algorithm, the original image can be 
expressed as a sum of the scales and the smoothed array.
\end{itemize}


\subsection{Filtering in wavelet space}
We review in this section some important strategies for treating the 
noise, once the data have been transformed.

\subsubsection*{Non-Gaussian noise}
If the noise in the data $I$ is Poisson, the transformation 
\cite{rest:anscombe48}
\begin{eqnarray}
t(I) = 2\sqrt{I + \frac{3}{8}}
\end{eqnarray}
acts as if the data arose from a
Gaussian white noise model, with $\sigma = 1$, under the
assumption that the mean value of $I$ is sufficiently large.
The arrival of photons, and their expression by electron counts, on CCD
detectors may be modeled by a Poisson distribution.  In addition, there is 
additive Gaussian read-out noise. The Anscombe 
transformation has been extended to take this combined noise into 
account.  The  generalization of the variance stabilizing
Anscombe formula is derived as \cite{starck:mur95_2}:
\begin{eqnarray}
t(I) = \frac{2}{g} \sqrt{g I + \frac{3}{8} g^2 + \sigma^2 - g m}
\label{eqn_bijaoui}
\end{eqnarray}
where $g$ is the electronic gain of the detector, $\sigma$ and $m$ the standard deviation 
and the mean of the read-out noise. 
 
This implies that for the filtering of an image with Poisson noise or
a mixture of Poisson and Gaussian noise, we will first pre-transform 
the image $I$ into another one $t(I)$ with Gaussian noise. Then $t(I)$ 
will be filtered, and the filtered image will be inverse-transformed.

For other kinds of noise, modeling must be performed in order to 
define the noise probability distribution of the wavelet coefficients 
\cite{starck:book98}.   
In the following, we will consider only stationary Gaussian noise.


\subsubsection*{Hard thresholding}
\label{hardsect}
This consists of setting to 0 all wavelet coefficients which have an absolute
value lower than a threshold $T_j$ ($T_j = K \sigma_j$, where $j$ is the
scale of the wavelet coefficient, $\sigma_j$ is the noise standard 
deviation at the scale $j$, and $K$ is a constant generally chosen equal to 3).
For an energy-normalized wavelet transform algorithm, we have $\sigma_j = \sigma$
for all $j$. 

The appropriate value of $\sigma_j$ 
in the succession of wavelet scales is assessed 
from the standard deviation of the noise $\sigma$ in the original signal
and from study of the noise in the wavelet space.  This study consists of 
simulating a signal containing Gaussian noise with a standard deviation 
equal to 1, and taking the wavelet transform of this signal.  Then we
compute the standard deviation $\sigma^e_j$ at each scale.  We get a curve 
$\sigma^e_j$ as a function of $j$, giving the behavior of the noise in the 
wavelet space. Due to the properties of the wavelet transform, we have 
$ \sigma_j = \sigma \sigma^e_j $ (see \cite{starck:sta98_3} for a description
of how $\sigma$ can be automatically calculated directly from the data).


\subsubsection*{Soft thresholding}
Soft thresholding consists of replacing each wavelet coefficient $w_{j,k}$
($j$ being the scale index, and $k$ the position index)
by the value $\tilde w_{j,k}$ where
\begin{eqnarray}
\tilde w_{j,k}  & = & sgn(w_{j,k}) ( \mid w_{j,k} \mid - T_j) \mbox{ if } \mid w_{j,k} \mid 
\geq  T_j  \\
         & = & 0  \mbox{ otherwise} 
\end{eqnarray}

\subsubsection*{Donoho universal approach}
Donoho \cite{rest:donoho93_1,rest:donoho93_2} has suggested to take 
$T_j =  \sqrt{2\log(n)}\sigma_j$ (where $n$ 
is the number of pixels) instead of the standard $K \sigma$ value. This 
leads to a new soft and hard thresholding approach.

Other threshold-based approaches are available. SURE, 
Stein unbiased risk estimator (\cite{rest:donoho95}) 
is adaptive in that it is resolution-dependent. The SURE estimator can 
break down when the wavelet coefficients are mostly around zero.
In contrast, the Donoho {\em universal} hard and soft thresholding approach 
may overly smooth the data, which is potentially rectified by the minimax
criterion proposed in \cite{rest:donoho93_1}. Note also that 
Chipman et al.\ \cite{wave:chipman97}
found that SURE create high frequency artifacts.

\subsubsection*{Multiresolution Wiener filtering}
Multiresolution Wiener filtering \cite{starck:sta94_4} consists of 
multiplying all
coefficients $w_{j,k}$ of a given scale $j$ by 
\begin{eqnarray}
\alpha_j = \frac{S_j}{S_j + N_j}
\end{eqnarray}
where $S_j$ and $N_j$ are respectively the variance of the signal 
and of the noise at the scale $j$ ($N_j = \sigma_j^2$). In the absence
of any information about the signal, we take $S_j$ equal to 
the difference between the variance of the data $w_j$ and the variance 
of the noise $N_j$.

\subsubsection*{Hierarchical Wiener filtering}
Hierarchical Wiener filtering \cite{starck:sta94_4} tries to 
introduce a prediction $w_{j,k}^h$ into the estimation of $\tilde w_{j,k}$. 
\begin{eqnarray}
\tilde w_{j,k} = \frac{H_j}{N_j+H_j+Q_j} w_{j,k} + \frac{N_j}{N_j+H_j+Q_j} w_{j,k}^h
\end{eqnarray}
with:
\begin{eqnarray}
Q_j = \frac{H_jN_j}{S_j}
\end{eqnarray}
where $H_j$ is the variance of the image $D$ obtained by taking the difference
of the scale $j$ and the following one $j+1$ ($D = w_j - w_{j+1}$, and
$H_j = {1 \over N} \sum_k (D_k - m_D)^2$, where $N$ is the number of pixels and
$m_D$ the mean of $D$). If a pyramidal transform is used, the scale
$w_{j+1}$ must be first interpolated to the size of the scale of $w_j$.

This prediction $w_{j,k}^h$ is obtained from 
the coefficient at the same position but at the following scale.
In the case of the \`a trous algorithm $w_{j,k}^h = w_{j+1,k}$, while for
a pyramidal transform, $w_{j,k}^h = w_{j+1,{k \over 2}}$. 


\subsubsection*{Hierarchical hard thresholding}

The threshold used here, $T_h$ \cite{starck:sta94_4}, is equal 
to $T_j=K \sigma_j$ if $\mid w_{j,k} \mid \ \geq T_j$,
and $T_h = T_j f(\mid\frac{w_{j,k}^h}{\sigma_{j+1}}\mid)$ otherwise. 
The function $f(a)$
must return a value between 0 and 1. A possible function for $f$ is:
\begin{itemize}
\item $f(a) = 0$ if $a \geq k$  
\item $f(a) = 1 - \frac{1}{K} a$ if $a < K$  
\end{itemize}
If the predicted wavelet coefficient has a high signal to noise ratio (SNR)
(this means that there is certainly some information at this position),
the threshold level becomes null, and the wavelet coefficient will not
be thresholded, even if its value is small. The threshold level becomes
adaptive.

\subsubsection*{Conclusion}
In a soft thresholding, we consider that all coefficients must be
corrected because there are all noisy. Hard thresholding principle is that
wavelet coefficient with high signal-to-noise ratio should not be 
corrected because we may lose some significative information. Depending
on the quality criterion on the solution, we may prefer one or the other
thresholding approach. If the visual aspect quality is the main criterion,  
the soft thresholding is generally better, because there is less 
visual artifact. For astronomical images, a soft thresholding should never
be used because it leads to a photometry lose of all objects, which 
can easily be verified by looking to the residual map 
(i.e. data - filtered data).
Concerning the threshold level, Donoho one corresponds to a minimum risk. 
Larger is the number of pixels, larger is the risk, and it is normal that the
threshold depends on the number of pixels. The $k\sigma$ threshold 
corresponds to a false detection probability, the probability to detect 
a coefficient as significant when it is due to the noise. The $3\sigma$ value
corresponds to 0.27 \% of false detection. The Multiresolution Wiener 
filter is derived from the hypothesis that the signal and the noise follow
a Gaussian distribution. This hypothesis is in general not true for the 
signal. The Hierarchical Wiener filtering introduces the concept of 
interscale dependence between the wavelet coefficients. Indeed,  
if we find a wavelet coefficient with a high signal-to-noise ratio
at a given scale, we will certainly also find one at the following scale.
This interscale dependence is actually used by the best image compression
methods \cite{compress:shapiro93,compress:said96}. The hierarchical threshold
level is varying with this interscale dependence. In the following, these
methods will be evaluated using two different images.
 
\section{Multiscale Entropy Filtering}
\subsection{Filtering}

The problem of filtering or restoring data $D$ can be expressed by the 
following: 
We search for a solution $\tilde D$ such that the difference between
$D$ and $\tilde D$ minimizes the information due to the signal, and 
such that  $\tilde D$ minimizes the information due to the noise. 
\begin{eqnarray}
J(\tilde D) = H_s(D-\tilde D) + H_n(\tilde D)
\label{eqn_func1}
\end{eqnarray}
Furthermore, the smoothness of the solution can be controlled by adding
a parameter:
\begin{eqnarray}
J(\tilde D) = H_s(D-\tilde D) + \alpha H_n(\tilde D)
\label{eqn_func2}
\end{eqnarray}

In practice \cite{rest:chambolle98}, we minimize for each wavelet coefficient $w_{j,k}$:
\begin{eqnarray}
j(\tilde w_{j,k}) = h_s(w_{j,k}-\tilde w_{j,k}) + \alpha h_n(\tilde w_{j,k})
\label{eqn_func_coef}
\end{eqnarray}
$j(\tilde w_{j,k})$ can be obtained be any minimization routine. In our examples,
we have used a simple dichotomy. 

Figure~\ref{fig_tab1} shows the result when minimizing the functional $j$ with
different $\alpha$ values, and a noise standard deviation equal to 1. 
The corrected wavelet coefficient is plotted versus the 
wavelet coefficient. From the top curve to the bottom one, 
$\alpha$ is respectively equal to 0, 0.1, 0.5, 1, 2, 5, 10. 
The higher the value of $\alpha$, the 
more the corrected wavelet coefficient is reduced. When $\alpha$ is equal 
to 0, there is no regularization and the data are unchanged.

\begin{figure}[htb]
\centerline{
\vbox{
\psfig{figure=fig_tab1.ps,bbllx=3.5cm,bblly=13cm,bburx=19.5cm,bbury=25.5cm,width=12cm,height=9cm}
}}
\caption{Corrected wavelet coefficient versus the wavelet coefficient with
different $\alpha$ values (from the top curve to the bottom one, 
$\alpha$ is respectively equal to 0,0.1,0.5, 1, 2, 5,10).}
\label{fig_tab1}
\end{figure}

\subsection{The regularization parameter}

\begin{figure}[htb]
\centerline{
\vbox{
\psfig{figure=fig_tab2.ps,bbllx=3.5cm,bblly=13cm,bburx=19.5cm,bbury=25.5cm,width=12cm,height=9cm}
}}
\caption{Corrected wavelet coefficient versus the wavelet coefficient with
different $\alpha$ values.}
\label{fig_tab2}
\end{figure}

The $\alpha$ parameter can be used in different ways: 
\begin{itemize}
\item It can be fixed to a given value (user parameter): $\alpha = \alpha_u$.
This method leads to very fast filtering using the optimization proposed
in the following.
\item It can be calculated
under the constraint that the residual should have some specific 
characteristic. For instance, in the case of Gaussian noise, we expect 
a residual
with a standard deviation equal to the noise standard deviation. In this case,
$\alpha = \alpha_c \alpha_u$. The parameter finally used is taken as the
product of a user parameter (defaulted to 1) and the calculated
value $\alpha_c$. This allows the user to keep open the possibility of 
introducing an
under-smoothing, or an over-smoothing. It is clear that such an algorithm 
is iterative, and will
always take more time than a simple hard thresholding approach.
\item We can permit more constraints on  $\alpha$ by using the fact that 
we expect a residual with a given standard deviation at each scale $j$ 
equal to the noise standard deviation $\sigma_j$ at the same scale. Then
rather than  a single $\alpha$ we have an $\alpha_j$ per scale.
\end{itemize}

A more sophisticated way to fix the $\alpha$ value is to introduce a 
distribution  
(or a priori knowledge) of how the regularization should work. 
For instance, in astronomical
image restoration, the analyst generally prefers that the flux 
(total intensity)
contained in a star or in a galaxy is not modified by the restoration process.
This means that the residual at positions of astronomical objects will 
approximately be equal to zero. All zero areas in the residual map 
obviously do not relate to realistic noise behavior, but from 
the user's point of view they are equally important. For the user, all 
visible objects in the filtered map 
contain the same flux as in the raw data. In order to obtain this kind
of regularization, the $\alpha$ parameter is no longer a constant value, but
depends on the raw data. Hence we have one $\alpha$ per wavelet coefficient,
which will be denoted $\alpha_s(w_{j,k})$, and it can be derived by
\begin{eqnarray}
\alpha_s(w_{j,k}) = \alpha_j \frac{1 - L(w_{j,k})}{L(w_{j,k})}
\label{eqn_alpha}
\end{eqnarray}
with $L(w_{j,k}) = MIN(1, \frac{\mid w_{j,k} \mid }{k_s \sigma_j})$, 
where $k_s$ is a user parameter (typically defaulted to 3).

When $L(w_{j,k})$ is close to $1$, $\alpha_s(w_{j,k})$ becomes equal to zero, and there
is no regularization anymore, and the obvious solution is $\tilde w_{j,k} = w_{j,k}$.
Hence, the wavelet coefficient is preserved from any regularization.
If $L(w_{j,k})$ is close to $0$, $\alpha_s(w_{j,k})$  tends toward infinity, then the
first term in equation~(\ref{eqn_func_coef}) is negligible, and the solution
will be $\tilde w_{j,k} = 0$. In practice, this means that all coefficients higher
than $k_s \sigma_j$ are untouched as in the hard thresholding approach.
We also notice that by considering a distribution $L(w_{j,k})$ equal to 
0 or 1 (1 when 
$\mid w \mid > K\sigma$ for instance), the solution is then the same as a
hard thresholding solution. 

\subsection{The use of a model}
 
Using a model in wavelet space has been successfully applied for 
denoising (see for example \cite{wave:chipman97,wave:crouse98,wave:jansen98}).
If we have a model $D_m$ for the data, this can also naturally be inserted 
into the filtering equation:
\begin{eqnarray}
J_m(\tilde D) = H_s(D-\tilde D) + \alpha H_n(\tilde D - D_m)
\end{eqnarray}
or, for each wavelet coefficient $w_{j,k}$:
\begin{eqnarray}
j_m(\tilde w_{j,k}) = h_s(w_{j,k}-\tilde w_{j,k}) + \alpha h_n(\tilde w_{j,k} - w_{j,k}^m)
\label{eqn_func_coef_jm}
\end{eqnarray}
where $w_{j,k}^m$ is the corresponding wavelet coefficient of $D_m$.

The model can be of quite different types. 
It can be an image, and in this case,
the coefficients $w_{j,k}^m$ are obtained by a simple wavelet transform of the 
model image.  It can also be expressed by a distribution or a 
given function which
furnishes a model wavelet coefficient $w^m$ from the data. For instance, the 
case where we want to keep intact high wavelet coefficients 
(see equation~\ref{eqn_alpha}) can also be treated by the use of a model, just
by calculating $w_{j,k}^m$ by
\begin{eqnarray}
w_{j,k}^m = P_s(w_{j,k}) w_{j,k}
\label{eqn_wm}
\end{eqnarray}
when $w_{j,k}$ has a high signal to noise ratio, $P_s(w_{j,k})$ is close to $1$, and 
$w_{j,k}^m$ is equal to $w_{j,k}$. Then $\alpha h_n(\tilde w_{j,k} - w_{j,k}^m)$ is equal to zero
and $\tilde w_{j,k} = w_{j,k}$, i.e.\ no regularization is 
carried out on $w_{j,k}$. 

Other models may also be considered. When the image contains 
contours, it may be interesting to derive the model from the detected edge.
Zero-crossing wavelet coefficients indicate where the edges are \cite{wave:mallat91}.
By averaging three wavelet coefficients in the direction of the detected edge,
we get a value $w_a$, from which we derive the SNR $S_e$ of the edge  
($S_e = 0$ if there is no detected edge). The model value $w^m$ is  
set to $w_a$ if a contour is detected, and $0$ otherwise. 
This approach has the advantage to filter the
wavelet coefficient, and even if an edge is clearly detected the smoothing
operates in the direction of the edge.

There is naturally no restriction on the model. 
When we have a priori information
of the content of an image, we should use it in order to improve the quality
of the filtering. It is clear that the way we use the knowledge of the presence
of edges in an image is not a closed question. The model in the entropy 
function is an interesting direction to investigate in the future. 


\subsection{The multiscale entropy filtering algorithm}

The Multiscale Entropy Filtering algorithm (MEF) consists of minimizing
for each wavelet coefficient $w_{j,k}$ at scale $j$
\begin{eqnarray}
j_m(\tilde w_{j,k}) = h_s(w_{j,k}-\tilde w_{j,k}) + \alpha_j h_n(\tilde w_{j,k} - w_{j,k}^m)
\end{eqnarray}
or 
\begin{eqnarray}
j_{ms}(\tilde w_{j,k}) = h_s(w_{j,k}-\tilde w_{j,k}) + \alpha_j \alpha_s(w_{j,k})  h_n(\tilde w_{j,k} - w_{j,k}^m)
\end{eqnarray}
if the SNR is used. By default the model $w_{j,k}^m$ is set to 0. There is no user
parameter because the $\alpha_j$ are calculated automatically in order to
verify the noise properties. If an over-smoothing (or an under-smoothing) 
is desired, a user parameter must be introduced. We propose in this case to
calculate the $\alpha_j$ in the standard way, and then to multiply the 
calculated values by a user value $\alpha_u$ defaulted to 1. 
Increasing $\alpha_u$
will lead to an over-smoothing, while 
decreasing $\alpha_u$ implies an under-smoothing.
 
Using a simple dichotomy, the algorithm becomes:
\begin{enumerate}
\item Estimate the noise in the data $\sigma$ (see \cite{ima:olsen93,starck:sta98_3}).
\item Wavelet transform of the data.
\item Calculate from $\sigma$ the noise standard deviation $\sigma_j$ at each scale $j$.
\item Set $\alpha^{min}_j = 0$, $\alpha^{max}_j = 200$.
\item For each scale $j$ do
\begin{enumerate}
 \item Set $\alpha_j = \frac{\alpha^{min}_j + \alpha^{max}_j}{2}$
 \item For each wavelet coefficient $w_{j,k}$ of scale $j$, 
       find $\tilde w_{j,k}$ by minimizing $j_m(\tilde w_{j,k})$ or $j_{ms}(\tilde w_{j,k})$
  \item Calculate the standard deviation of the residual: \\
 $ \sigma_j^r = \sqrt{ \frac{1}{N_j} \sum_{k=1}^{N_j} (w_{j,k}-\tilde w_{j,k})^2}$
 \item If $\sigma_j^r > \sigma_j$ then the regularization is too strong, and
 we set $\alpha^{max}_j$ to $\alpha_j$, otherwise we 
 set $\alpha^{min}_j$ to $\alpha_j$ ($\sigma_j$ is derived from the
 method described in section~\ref{hardsect}).
\end {enumerate}
\item If $\alpha^{max}_j - \alpha^{min}_j > \epsilon $ then go to 5.
\item Multiply all $\alpha_j$ by the constant $\alpha_u$.
\item For each scale $j$ and for each wavelet coefficient $w$
find $\tilde w_{j,k}$ by minimizing $j_m(\tilde w_{j,k})$ or $j_{ms}(\tilde w_{j,k})$.
\item Reconstruct the filtered image from $\tilde w_{j,k}$ by the inverse wavelet
transform.
\end{enumerate}

The minimization of $j_m$ or $j_{ms}$ (step 5b) can be done by any method. 
For instance,
a simple dichotomy can be used in order to find $\tilde w$ such that
\begin{eqnarray}
\nabla(j_m(\tilde w_{j,k})) & = &
 \frac{\partial h_s(w_{j,k}-\tilde w_{j,k})}{\partial \tilde w_{j,k}} 
 + \alpha_j \frac{\partial h_n(\tilde w_{j,k})}{\partial \tilde w_{j,k}} = 0
\end{eqnarray}

In the case of Gaussian noise, and by using N2-MSE approach, 
we derive from equations~\ref{eqn_n2_hn} and~\ref{eqn_n2_hs} described 
in the next section that
 $\nabla(j_m(\tilde w_{j,k}))$ 
is defined by:
\begin{eqnarray}
\nabla(j(\tilde w_{j,k})) & = &  
- \frac{w_{j,k} - \tilde w_{j,k}}{\sigma_j^2} 
\mbox{erf}\left(\frac{w_{j,k} - \tilde w_{j,k}}{\sqrt{2}\sigma_j}\right) + 
\sqrt{\frac
{2}{\pi}}\frac{1}{\sigma_j}
\left[1 - e^{-\frac{(w_{j,k} - \tilde w_{j,k})^{2}}{2\sigma_j^{2}}}\right]
+   \nonumber \\
& & 
 \alpha_j \left( \frac{\tilde w_{j,k}}{\sigma_j^{2}}
\mbox{erfc}\left(\frac{\tilde w_{j,k}}{\sqrt{2}\sigma_j}\right)
    + \frac{1}{\sigma_j} \sqrt{\frac{2}{\pi} } \:
      \left[1 - e^{-\frac{\tilde w_{j,k}^{2}}{2\sigma_j^{2}}}\right]\right)
\end{eqnarray}

The idea to treat the wavelet coefficients
such that the residual respects some constraint has also been used in
\cite{wave:nason94,wave:nason96,wave:amato97b} using cross-validation. 
However, 
cross validation appears to overfit the data \cite{wave:strang96}.


\subsection{Derivative calculation of $h_s$ and $h_n$ for N2-MSE}
\subsubsection*{The erf function}
 The erf and erc functions are defined by  
\begin{eqnarray}
  \mbox{erf(x)} & = & \frac{2}{\sqrt{\pi}}\int_{0}^{x} e^{-t^{2}} dt \nonumber \\ 
   \mbox{erfc}(x) & = & 1-\mbox{erf}(x) = \frac{2}{\sqrt{\pi}}\int_{x}^{\infty} e^{-t^{2}} dt 
\end{eqnarray}
These functions have the following symmetries
 \begin{eqnarray}
   \begin{tabular}{c|c} 
   \hline
    \mbox{erf}(0) = 0         & $ \mbox{erf}(\infty) = 1 $  \\
   \mbox{erfc}(0) = 1        & $  \mbox{erfc}(\infty) = 0 $ \\
   \mbox{erf}(-x) = \mbox{erf}(x)   &   \mbox{erfc}(-x) = 2-\mbox{erfc}(x) \\
   \hline
   \end{tabular}
\end{eqnarray}

\subsubsection{Gaussian case}
We compute the contribution of the wavelet coefficient $x$ to the noise information: 
\begin{eqnarray}
h_{n}(x) = 
\frac{1}{\sigma^{2}}\int_{0}^{x} t \: \mbox{erfc}
\left( \frac{x-t}{\sqrt{2}\sigma}\right) dt 
\end{eqnarray}

\begin{eqnarray}
\frac{d h_{n}(x)}{dx} &  = &  h_{n}(x+dx) - h_{n}(x)  \nonumber \\
   &  = & \frac{1}{\sigma^{2}} \int_{0}^{x+dx} 
            t \mbox{ erfc}\left(\frac{x+dx-t}{\sqrt{2}\sigma}\right) dt -
\frac{1}{\sigma^{2}}\int_{0}^{x} t \mbox{ erfc} \left(\frac{x-t}{\sqrt{2}\sigma}\right) dt \nonumber \\
   &  = & \frac{1}{\sigma^{2}} \int_{0}^{x} \left[ t 
              \mbox{ erfc}\left(\frac{x+dx-t}{\sqrt{2}\sigma}\right) 
	      - t \mbox{ erfc} \left(\frac{x-t}{\sqrt{2}\sigma}\right) \right] dt +
	   \frac{1}{\sigma^{2}} \int_{x}^{x+dx}   t 
              \mbox{ erfc}\left(\frac{x+dx-t}{\sqrt{2}\sigma}\right) dt \nonumber \\
   &  = & \frac{1}{\sigma^{2}} \int_{0}^{x} t \frac{\partial \mbox{ erfc}\left(\frac{x-t}{\sqrt{2}\sigma}\right)}{\partial x} 
          + \frac{1}{\sigma^{2}} \int_{x}^{x+dx}   t 
              \mbox{ erfc}\left(\frac{x+dx-t}{\sqrt{2}\sigma}\right) dt \nonumber \\
   &  = & \frac{1}{\sigma^{2}}\int_{0}^{x} 
          t \frac{ \partial \:  \, \mbox{ erfc} (\frac{x-t}{\sqrt{2}\sigma})}{ \partial x} dt +
	  \frac{x}{\sigma^{2}}  \, \mbox{ erfc}(0)
\end{eqnarray}

% \begin{eqnarray}
% \frac{d h_{n}(x)}{dx} = 
% \frac{x}{\sigma^{2}}  \, \mbox{erfc}\left(\frac{x-x}{\sqrt{2}\sigma}\right)  +
% \frac{1}{\sigma^{2}}\int_{0}^{x} 
%           \frac{ \partial \: t \, \mbox{erfc} (\frac{x-t}{\sqrt{2}\sigma})}{ \partial x} dt 
% \end{eqnarray}

Now, because erfc(0) = 1  we have:
\begin{eqnarray}
\frac{d h_{n}(x)}{dx} = 
\frac{x}{\sigma^{2}}   +
\frac{1}{\sigma^{2}}\int_{0}^{x} 
          t \frac{ \partial \:  \, \mbox{erfc} (\frac{x-t}{\sqrt{2}\sigma})}{ \partial x} dt 
\end{eqnarray}

We derive the function erfc:
\begin{eqnarray}
\frac{\partial \: \mbox{erfc}(x)}{\partial x} = - \frac{2}{\sqrt{\pi}}   e^{-x^{2}} 
\end{eqnarray}

\begin{eqnarray}
\frac{ \partial\:  \mbox{erfc}( \frac{(x-t)}{\sqrt{2}\sigma} )}{\partial x} = 
-\frac{2}{\sqrt{\pi}} \frac{1}{\sqrt{2}\sigma}  
  e^{-\frac{(x-t)^{2}}{2\sigma^{2}}} =
 -\sqrt{\frac{2}{\pi}} \frac{1}{\sigma} e^{-\frac{(x-t)^{2}}{2\sigma^{2}}}
\end{eqnarray}

Now we deduce for the derivative of $h_n$:

\begin{eqnarray}
\frac{d h_{n}(x)}{dx} = 
\frac{x}{\sigma^{2}}   +
\frac{1}{\sigma^{2}}\int_{0}^{x} 
 -\sqrt{\frac{2}{\pi}}\frac{1}{\sigma}t \, e^{-\frac{(x-t)^{2}}{2\sigma^{2}}}dt 
\end{eqnarray}

\begin{eqnarray}
\frac{d h_{n}(x)}{dx} = 
\frac{x}{\sigma^{2}}   +
\frac{1}{\sigma^{3}}\sqrt{\frac{2}{\pi}} \int_{0}^{x} t \, e^{-\frac{(x-t)^{2}}{2\sigma^{2}}}dt 
\end{eqnarray}

We create the variable $J$
\begin{eqnarray}
J = \int_{0}^{x} t \, e^{-\frac{(x-t)^{2}}{2\sigma^{2}}}dt 
\end{eqnarray}

We create the variable $u$
\begin{eqnarray}
\begin{array}{cc} 
  u = \frac{t-x}{\sqrt{2}\sigma}  &  t = x+u \, \sqrt{2}\sigma         \\
   & dt = \sqrt{2}\sigma du         \\
  t=0 \Rightarrow u = \frac{-x}{\sqrt{2}\sigma}  &
  t=x \Rightarrow u = 0                     \\
   \end{array}
\end{eqnarray}


The variable $J$ can be written with $u$
\begin{eqnarray}
 J = \int_{\frac{-x}{\sqrt{2}\sigma} }^{0} (x+u \,\sqrt{2}\sigma) e^{-u^{2}}\sqrt{2}\sigma du
\end{eqnarray}
\begin{eqnarray}
 J = \sqrt{2}\sigma x \int_{\frac{-x}{\sqrt{2}\sigma} }^{0} 
 e^{-u^{2}} du  +
 2 \sigma^{2} \int_{\frac{-x}{\sqrt{2}\sigma} }^{0} u \,
 e^{-u^{2}} du
\end{eqnarray}

The first part of $J$ can be rewritten as:
\begin{eqnarray}
 J_{0} = \sqrt{2}\sigma x \int_{0}^{\frac{x}{\sqrt{2}\sigma} } 
 e^{-u^{2}} du  
\end{eqnarray}
$ J_{0} $ can be expressed with the error function.
\begin{eqnarray}
 J_{0} = \sqrt{2}\sigma \frac{\sqrt{\pi}}{2} x  \mbox{erf}\left(\frac{x}{\sqrt{2}\sigma}\right) 
       = \sigma \sqrt{\frac{\pi}{2}} \: x \:  \mbox{erf}\left(\frac{x}{\sqrt{2}\sigma}\right) 
\end{eqnarray}
Now the second part of $J$ is obvious
\begin{eqnarray}
 J_{1} = 2 \sigma^{2} \int_{\frac{-x}{\sqrt{2}\sigma} }^{0} u \,
 e^{-u^{2}} du  
\end{eqnarray}
 or
\begin{eqnarray}
\frac{d e^{-u^{2}}} {du} = -2 u e^{-u^{2}} 
\end{eqnarray}

We replace
\begin{eqnarray}
 J_{1} = -\sigma^{2}  \int_{\frac{-x}{\sqrt{2}\sigma} }^{0} d(e^{-u^{2}})  
\end{eqnarray}
\begin{eqnarray}
 J_{1} = \sigma^{2}  [e^{-\frac{x^{2}}{2\sigma^{2}}} - 1]  
\end{eqnarray}

Now we can write $J$
\begin{eqnarray}
 J = J_{0} + J_{1}
  = \sigma \sqrt{\frac{\pi}{2}} \: x \:  \mbox{erf}\left(\frac{x}{\sqrt{2}\sigma}\right) 
    + \sigma^{2}  \left[e^{-\frac{x^{2}}{2\sigma^{2}}} - 1 \right]  
\end{eqnarray}

We can write the derivative of $h_n$
\begin{eqnarray}
\frac{d h_{n}(x)}{dx} & = & 
\frac{x}{\sigma^{2}}   -
\frac{1}{\sigma^{3}} \sqrt{\frac{2}{\pi} } \: J \nonumber \\
                   & = &   \frac{x}{\sigma^{2}} -
  \frac{x}{\sigma^{2}}\: x \:  \mbox{erf}\left(\frac{x}{\sqrt{2}\sigma}\right)
  + \frac{1}{\sigma} \sqrt{\frac{2}{\pi} } \:
      \left[1 - e^{-\frac{x{2}}{2\sigma{2}}}\right]  \nonumber \\
                    & = &  \frac{x}{\sigma^{2}}\mbox{erfc}\left(\frac{x}{\sqrt{2}\sigma}\right)
    + \frac{1}{\sigma} \sqrt{\frac{2}{\pi} } \:
      \left[1 - e^{-\frac{x^{2}}{2\sigma^{2}}}\right] 
\label{eqn_n2_hn}
\end{eqnarray}

In order to minimize the functional~(\ref{eqn_func1}), we may want to calculate
the derivative of $h_s(y-x)$, where $h_s(y-x)$ measures the amount 
of information
contained in the residual ($y$ being the data).
\begin{eqnarray}
h_s(y-x) = \frac{1}{\sigma^{2}} \int_{0}^{y-x} t \mbox{ erf}\left(\frac{y-x-t}{\sqrt{2}\sigma}\right) dt
\end{eqnarray}
Denoting $z = y - x$, we have
\begin{eqnarray}
h_s(z) &  =  & \frac{1}{\sigma^{2}} \int_{0}^{z} t \mbox{ erf}\left(\frac{z-t}{\sqrt{2}\sigma}\right) dt \nonumber \\
       &  =  & \frac{1}{\sigma^{2}} \int_{0}^{z} t dt - \frac{1}{\sigma^{2}} \int_{0}^{z} t \mbox{ erfc}\left(\frac{z-t}{\sqrt{2}\sigma}\right) dt
\end{eqnarray} 
and
\begin{eqnarray}
\frac{d h_s(x)}{dx} = \frac{d h_s(z)}{dz} \frac{dz}{dx}
\end{eqnarray}
\begin{eqnarray}
\frac{d h_s(z)}{dz} = \frac{z}{\sigma^2} - \frac{d h_n(z)}{dz}
 \end{eqnarray}
then
\begin{eqnarray}
\frac{d h_s(y-x)}{dx} & = & - \frac{y-x}{\sigma^2} + \frac{y-x}{\sigma^2}\mbox{erfc}\left(\frac{y-x}{\sqrt{2}\sigma}\right) + \sqrt{\frac{2}{\pi}}\frac{1}{\sigma}\left[1 - e^{-\frac{(y-x)^{2}}{2\sigma^{2}}}\right] \nonumber \\
                    & = & - \frac{y-x}{\sigma^2} \mbox{erf}\left(\frac{y-x}{\sqrt{2}\sigma}\right) + \sqrt{\frac{2}{\pi}}\frac{1}{\sigma}\left[1 - e^{-\frac{(y-x)^{2}}{2\sigma^{2}}}\right]
\label{eqn_n2_hs}
\end{eqnarray}


\subsection{General Case}
  
The contribution of the wavelet coefficient $x$ to the noise and signal
information in the general case is
\begin{eqnarray}
h_n(x) & = & \int_{0}^{\mid x \mid } P_n(x-u) \left(\frac{\partial h(x)}{\partial 
x}\right)_{x=u} du \\ \nonumber 
h_s(x) & = & \int_{0}^{\mid x \mid } P_s(x-u) \left(\frac{\partial h(x)}{\partial 
x}\right)_{x=u} du
\end{eqnarray}

Assuming $h(x) = \frac{1}{2}x^2$, we have
\begin{eqnarray}
h_n(x) & = & \int_{0}^{\mid x \mid } P_n(x-u) u du \\ \nonumber 
h_s(x) & = & \int_{0}^{\mid x \mid } P_s(x-u) u du
\end{eqnarray}


\begin{eqnarray}
\frac{ d h_{s}(x)}{dx} = \int_0^x \left( 
\frac{\partial P_s(x-u)}{\partial x}\right)_{x=u} u du +
         \frac{1}{dx}  \int_x^{x+dx} P_s(x-u) u  du
\end{eqnarray}

Since $P_s(0) = 0$, the second term tends to zero.

Denoting  $\frac{\partial P_s(x-u)}{\partial x} = - \frac{\partial P_s(x-u)}{\partial u}$, we have  
\begin{eqnarray}
\frac{ d h_{s}(x)}{dx} & = & - \int_0^x \frac{\partial P_s(x-u)}{\partial u} u du \nonumber \\
& = &  - ( [u P_s(x-u) ]_0^x - \int_0^x P_s(x-u) du) \nonumber \\
& = & \int_0^x P_s(x-u) du \nonumber \\
& = & \int_0^x P_s(u) du
\end{eqnarray}
and from $h_n = h - h_s$ we get
\begin{eqnarray}
\frac{ d h_{n}(x)}{dx} & = &  x -  \int_0^x P_s(u) du
\end{eqnarray}
and 
\begin{eqnarray}
\frac{ d h_{s}(y-x)}{dx} = - \int_0^{y-x} P_s(u) du
\end{eqnarray}

It is easy to verify that replacing $P_s(x) = \mbox{erf}(x)$, 
and $P_n(x) = \mbox{erfc}(x)$
(case of Gaussian noise) we find the same equation as in the Gaussian case.



% See appendix~\ref{annexB} and \ref{annexC} for the calculation of the 
% derivative of $h_s$ and $h_n$.

\subsection{Optimization}

In the case of Gaussian noise, the 
calculation of {\em erf} and {\em erfc} functions could lead to a 
considerable
time computation, when compared to a simple filtering method. This can
be easily avoided by precomputing tables, which is possible due to 
the specific properties of 
$\frac{\partial h_s}{\partial \tilde  w}$ and $\frac{\partial h_n}{\partial \tilde  w}$.
$h_s$ and $h_n$ are functions of the standard deviation of the noise, and
we denote the reduced functions by $h^r_s$ and $h^r_n$, 
i.e.\ $h_s$ and $h_n$ for
noise standard deviation equal to 1. It is easy to verify that
\begin{eqnarray}
\frac{\partial h_s(w_{j,k})}{\partial \tilde  w} & = & \sigma_j \frac{\partial h^r_s(\frac{w_{j,k}}{\sigma_j})}{\partial \tilde  w} \\
\frac{\partial h_n(w_{j,k})}{\partial  \tilde w} & = & \sigma_j \frac{\partial h^r_n(\frac{w_{j,k}}{\sigma_j})}{\partial  \tilde w} 
\end{eqnarray}
Furthermore,  $\frac{\partial h^r_n}{\partial \tilde w}$ and  $\frac{\partial h^r_s}{\partial \tilde w}$   
are symmetric functions, $\frac{\partial h^r_n}{\partial \tilde w}$
converges to a constant value $C$ (C=0.798), and $\frac{\partial h^r_s}{\partial \tilde  w}$
tends to $C-w$ when $w$ is large enough ($>5$).
In our implementation, we precomputed the tables using a step-size of $0.01$
from 0 to 5. If no model is introduced and if the SNR is not used, the filtered
wavelet of coefficients is a function of $\alpha$ and $\frac{w_j}{\sigma_j}$,
and a second level of optimization can be performed by precomputed tables
of solutions for different values of $\alpha$.
 

\section{Examples}
\subsection{1D data filtering}
\begin{figure}[htb]
\centerline{
\vbox{ 
\psfig{figure=fig_block_orig.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_block.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_block.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_over_block.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
}}
\caption{From top to bottom, simulated block data, noise blocks, filtered blocks,
and both noisy and filtered blocks overplotted.}
\label{fig_1d_block}
\end{figure}

\begin{figure}[htb]
\centerline{
\vbox{ 
\psfig{figure=fig_ndopler_orig.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_ndopler.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_ndopler.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_over_ndopler.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
}}
\caption{From top to bottom, simulated data, noisy data, filtered data,
and both noisy and filtered data overplotted.}
\label{fig_1d_ndoppler}
\end{figure}

\begin{figure}[htb]
\centerline{
\vbox{ 
\psfig{figure=fig_bump_orig.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_bump.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_bump.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_over_bump.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
}}
\caption{From top to bottom, simulated data, noisy data, filtered data,
and both noisy and filtered data overplotted.}
\label{fig_1d_bump}
\end{figure}

\begin{figure}[htb]
\centerline{
\vbox{ 
\psfig{figure=fig_lit6n.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_lit6n.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_over_lit6n.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
\psfig{figure=fig_fm_diff_lit6n.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=14cm,height=5.5cm}
}}
\caption{From top to bottom, real spectrum, filtered spectrum,  
 both noisy and filtered spectrum overplotted, and difference between the spectrum
 and the filtered data. As we can see, the residual contains only noise.}
\label{fig_1d_lit6n}
\end{figure}

 
Figures~\ref{fig_1d_block}, \ref{fig_1d_ndoppler} and 
\ref{fig_1d_bump} show the
results of the multiscale entropy method on 
simulated data (2048 pixels).  From 
top to bottom, each figure shows simulated data, the noisy data, 
the filtered data, and both noisy and filtered data overplotted. 
For the two first filterings, all default parameters were taken (noise 
standard deviation and $\alpha_j$ automatically calculated, $\alpha_u=1$,
and the chosen wavelet transform algorithm is the \`a trous one). For
the block signal (Fig.~\ref{fig_1d_block}), default parameters were
also used, but the multiresolution transform we used is the multiresolution
median transform.
 
Figure~\ref{fig_1d_lit6n}
shows the result after applying the MEF method to a real spectrum (512 pixels). The last
plot shows the difference between the original and the filtered spectrum.
As we can see, the residual contains only noise. In this case, we used 
also default parameters, but we introduce the SNR in the calculation
of $\alpha$.


\subsection{Image filtering}
\begin{figure}[h]
\centerline{
\hbox{
\psfig{figure=fig_simu4_bw.ps,bbllx=1.8cm,bblly=12.8cm,bburx=14.5cm,bbury=25.5cm,width=16cm,height=16cm,clip=}
}}
\caption{(a) Simulated image, (b) simulated image and 
Gaussian noise, (c) filtered image, and (d)
residual image.}
\label{fig_filter_gauss_noise}
\end{figure}

A simulated $256 \times 256$ 
image containing stars and galaxies is shown in Fig.\ 
\ref{fig_filter_gauss_noise} (top left). The simulated noisy
image, the filtered image and the residual image are respectively shown in
Fig.\ \ref{fig_filter_gauss_noise} top right, bottom left, and
bottom right. We can see that there is no structure in the residual 
image.  

\clearpage
\newpage

\section{Comparison with Other Methods from Simulations}

\subsection{Simulation descriptions}

 A set of simulations were carried out based on two images: the classical
Lena 512$\times$512 image, and a 512$\times$512 landscape image. From each 
image, three
images were created  by adding Gaussian noise with standard deviations
of 5,10,30. These six images were filtered using different 
multiresolution methods and different noise treatment methods.
The multiresolution methods were:
\begin{enumerate}
\item Haar wavelet transform (FWT-Haar).
\item Mallat-Daubechies biorthogonal wavelet transforms using the 
Dauchechies-Antonini 7/9 filters \cite{wave:antonini92} (FWT-7/9).
\item Feauveau wavelet transform.
\item \`A trous algorithm using a B-spline scaling function (see
 \cite{starck:sta95_1,starck:book98} for more details).
\item Multiresolution median transform (MMT) \cite{starck:sta96_2}.
\end{enumerate}
The first two belong to the class of fast wavelet transforms.
The third is also a non-redundant transform, but compared to the FWT,
the wavelet function is isotropic. The \`a trous algorithm is redundant and
symmetric, and finally the MMT is not a wavelet transform, but does allow 
a multiresolution representation.

Using these five transforms, we used eight different strategies 
for correcting the multiresolution coefficients from the noise:
\begin{itemize}
\item k-sigma hard and soft  thresholding
\item Donoho hard and soft thresholding
\item Multiscale entropy method
\item Hierarchical hard thresholding
\item Multiresolution Wiener filtering
\item Hierarchical Wiener filtering
\end{itemize}
The last three strategies have up to now only been used  with 
redundant transforms (\`a trous algorithm and MMT in our case).

Finally, close to two hundred filtered images were created. 
Four resolution scales were used for the filtering, and the constant $k$ for
the hard thresholding was always taken as equal to 4 for the first scale,
and 3 for the others. For the multiscale entropy method, the parameter 
$\alpha$ was determined by the program in order to get a standard deviation
of the residual (i.e.\ image minus filtered image) of the same order as the
noise standard deviation.

For 
each filtered image, the PSNR (peak signal-to-noise)
ratio between the original image $I$ and the 
filtered image $F$ was calculated as:
\begin{eqnarray}
PSNR_{dB} = 10 \log_{10} \frac{255}{NRMSE^2}
\end{eqnarray}
where NRMSE is the normalized root mean square error:
\begin{eqnarray}
NRMSE^2  = \frac {\sum_{pix} (I - F)^2}{\sum_{pix} I^2}
\end{eqnarray}

We  also calculated the correlation factor, but we found that this
does not furnish more information than the PSNR. If the PSNR is an objective
measure, it is however not sufficient, because it does not allow us to 
control whether artifacts are present or not. Images were therefore also
visually assessed,  in order to decide if artifacts are visible.

Results of the simulations are presented in 
Tables~\ref{comptab1},\ref{comptab}.

$ $

\begin{table}[hbt]
\begin{center}
\begin{tabular}{lccccc} \hline \hline
Method               & FWT-Haar  & FWT-7/9    & Feauveau & \`a trous & MMT \\ \hline \hline
Hard thresh.         & 34.63 & 35.95 &  33.27   &   35.20  & 34.82  \\
Soft thresh.         & 32.35 & 33.83 &  30.67   &   32.30  & 32.43  \\
Donoho hard thresh.  & 33.19 & 34.62 &  31.05   &   33.98  & 33.68  \\
Donoho soft thresh.  & 30.69 & 32.09 &  28.73   &   30.76  & 31.19  \\
Hierarchical thresh. &     - &  -    &   -      &   35.26  & 34.89  \\
Hierarchical Wiener  &     - &  -    &   -      &   33.35  & 31.91  \\
Multiresol. Wiener   &     - &  -    &   -      &   33.42  & 31.93  \\
Multiscale Entropy   & 35.86 & 36.76 &   -      &   35.82  & 35.56  \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image (Lena + Gaussian 
noise (sigma=5)).}
\vspace{0.5cm}


\begin{tabular}{lccccc} \hline \hline
Method               & FWT-Haar  & FWT-7/9    & Feauveau & \`a trous & MMT \\ \hline \hline
Hard thresh.         & 31.31 & 32.97 &  29.87   &  32.63   & 31.80 \\
Soft thresh.         & 29.72 & 31.29 &  28.05   &  30.03   & 30.15 \\
Donoho hard thresh.  & 29.94 & 31.55 &  27.68   &  31.33   & 30.88  \\
Donoho soft thresh.  & 28.18 & 29.66 &  26.77   &  28.49   & 29.09  \\
Hierarchical thresh. &     - &  -    &   -      &  32.75   & 31.93  \\
Hierarchical Wiener  &     - &  -    &   -      &  31.71   & 30.33  \\
Multiresol. Wiener   &     - &  -    &   -      &  31.68   & 30.24  \\
Multiscale Entropy   & 32.12 & 33.39 &   -      &  32.41   & 31.95 \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image (Lena + Gaussian
noise (sigma=10)).}
\vspace{0.5cm}


\begin{tabular}{lccccc} \hline \hline
Method               & FWT-Haar  & FWT-7/9    & Feauveau & \`a trous & MMT \\ \hline \hline
Hard thresh.         & 26.82 & 27.97 &  26.00   &  28.58   & 28.19  \\
Soft thresh.         & 26.27 & 27.67 &  25.85   &  26.85   & 27.27  \\
Donoho hard thresh.  & 25.99 & 27.46 &  25.80   &  27.03   & 27.42   \\
Donoho soft thresh.  & 25.29 & 26.78 &  25.80   &  25.85   & 26.58   \\
Hierarchical thresh. &     - &  -    &   -      &  28.97   & 28.42   \\
Hierarchical Wiener  &     - &  -    &   -      &  28.08   & 27.96 \\
Multiresol. Wiener   &     - &  -    &   -      &  27.25   & 26.81  \\
Multiscale Entropy   &  27.45 & 28.75  &   -      &  28.37    & 27.96 \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image (Lena + Gaussian noise 
(sigma=30)).}
\vspace{0.5cm}
\end{center}
\label{comptab1}
\end{table}


\begin{table}[hbt]
\begin{center}
\begin{tabular}{lccccc} \hline \hline
Method               & FWT-Haar  & FWT-7/9    & Feauveau & \`a trous & MMT \\ \hline \hline
Hard thresh.         & 32.50 & 33.02 &  30.48   &   32.49  & 31.79 \\
Soft thresh.         & 30.35 & 30.97 &  28.27   &   29.87  & 29.59  \\
Donoho hard thresh.  & 31.04 & 31.53 &  28.38   &   31.23  & 30.67  \\
Donoho soft thresh.  & 28.80 & 29.40 &  26.70   &   28.46  &  28.45  \\
Hierarchical thresh. &     - &  -    &   -      &   32.51  &  31.82  \\
Hierarchical Wiener  &     - &  -    &   -      &   30.59  &  30.32  \\
Multiresol. Wiener   &     - &  -    &   -      &   30.65  &  30.35  \\
Multiscale Entropy   & 34.63 & 34.94 &   -      &   34.30  &  33.97  \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image (Landscape + Gaussian noise (sigma=5)).}
\vspace{0.5cm}


\begin{tabular}{lccccc} \hline \hline
Method               & FWT-Haar  & FWT-7/9    & Feauveau & \`a trous & MMT \\ \hline \hline
Hard thresh.         & 29.32 & 30.00 &  27.38   &  29.88   &  28.91 \\
Soft thresh.         & 27.89 & 28.66 &  26.18   &  27.78   &  27.45 \\
Donoho hard thresh.  & 28.05 & 28.74 &  25.86   &  28.58   &  27.98  \\
Donoho soft thresh.  & 26.53 & 27.32 &  25.32   &  26.50   &  26.52  \\
Hierarchical thresh. &     - &  -    &   -      &  29.99   &  28.99  \\
Hierarchical Wiener  &     - &  -    &   -      &  29.59   &  28.04  \\
Multiresol. Wiener   &     - &  -    &   -      &  29.64   &  28.04  \\
Multiscale Entropy   & 30.80 &  31.35 &   -     &  30.70   &  30.16 \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image (Landscape + Gaussian noise (sigma=10)).}
\vspace{0.5cm}


\begin{tabular}{lccccc} \hline \hline
Method               & FWT-Haar  & FWT-7/9    & Feauveau & \`a trous & MMT \\ \hline \hline
Hard thresh.         & 25.44 & 26.01 &  24.80   &   26.55  &  25.90  \\
Soft thresh.         & 25.03 & 25.88 &  24.75   &   25.33  &  25.10  \\
Donoho hard thresh.  & 24.77 & 25.60 &  24.72   &   25.36  &  25.19   \\
Donoho soft thresh.  & 24.26 & 25.29 &  24.725  &   24.61  &  24.51   \\
Hierarchical thresh. &     - &  -    &   -      &   27.07  &  26.21   \\
Hierarchical Wiener  &     - &  -    &   -      &   26.52  &  25.83 \\
Multiresol. Wiener   &     - &  -    &   -      &   25.89  &  25.24  \\
Multiscale Entropy   & 26.33 & 27.11 &   -      &   26.88  &  26.16 \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image (Landscape + Gaussian noise (sigma=30)).}
\vspace{0.5cm}

\end{center}
\label{comptab}

\end{table}



\section{Simulation Analysis}
\subsubsection*{Multiresolution algorithm} 
 
Filtering using the Haar transform always produces artifacts, even at low 
noise levels.  When using other filters, artifacts appear only beyond a
given noise level. Improving the filter set improves the 
filtered image quality,
which is a well-known result. When the noise increases, artifacts appear,
even with a good filter set such as the Antonini 7/9 one.

\begin{itemize}
\item {\bf Feauveau WT.}
 The standard orthogonal WT is always better than
the Feauveau method for filtering.

\item {\bf \`A trous algorithm.} 
This does not create artifacts when thresholding,
and results are significantly better (from the visual point of view) at 
high noise levels, compared to 
orthogonal WT approaches. As opposed to the standard WT method,
this transform is symmetric and performs better on 
isotropic structures compared to faint contours. This is the reason
for its success on astronomical images where objects are diffuse and 
more or less isotropic (stars, galaxies, etc.). 

\item{\bf Multiresolution median transform.} 
This transform is non-linear, and noise estimation at the 
different scales cannot be carried out in
the same rigorous way as with linear transforms. For pure Gaussian noise,
there is clearly no interest in using this transform, even if it respects well
the morphology of the objects contained in the image. For some other kinds
of noise,
the non-linearity can be an advantage, and it can then be considered.
\end{itemize}
 
\subsubsection*{Conclusion}
The Feauveau WT and the MMT are not competitive for filtering in the 
case of Gaussian noise. FWT-7/9 allows better restoration of the edges than
the \`a trous algorithm, but the \`a trous algorithm is more robust from
the visual point of view.
The important point to be made is clearly that the way the information
is represented is fundamental. At high noise levels, whatever the chosen filter set,
we will always have more artifacts using the FWT than with 
the \`a trous algorithm.

\subsubsection{Noise treatment strategies} 

\begin{itemize}
\item {\bf The optimal method depends on the noise level.} \\
At low noise levels, simple thresholding using an orthogonal wavelet
transform leads to very good results. When the noise increases, artifacts
appear.  Non-orthogonal transforms produce better results, and soft
thresholding strategies lead to more acceptable image quality.

\item {\bf Donoho soft and hard thresholding versus the k-sigma approach.} \\
Whatever the multiresolution transform and the noise level, 
the k-sigma hard (respectively soft)
 thresholding is always 
better than the Donoho hard (respectively soft) thresholding. Both PSNR ratio
and visual aspect are better using the k-sigma approach. This outcome is
not too surprising. Indeed the threshold, in the Donoho approach,
 is increasing with the number of 
pixels (justified in order to have a fixed number of ``artifacts'').
For our 512$\times$512 image, this approach is equivalent to thresholding 
at $5 \sigma$. But then the
thresholding level is too high, because the main coefficients between
$3\sigma$ and $5\sigma$ are significant. The larger the image size, 
the stronger will be the over-smoothing.

\item {\bf Hierarchical thresholding.} \\
The modification of the thresholding level at a given scale
 using the information at the following scale improves the result. 
The PSNR is better, and the visual aspect is similar to the hard thresholding.
This procedure could certainly be also introduced into orthogonal transforms.   
 
\item {\bf Quality of the multiscale entropy method.} \\
The multiscale entropy method proposes a visually good solution 
whatever the noise 
level. It is in fact a method which preserves high wavelet coefficients, and
corrects other wavelet coefficients in an adaptive, soft, manner.
\end{itemize}

\section{Conclusion: Toward Combined Filtering}

If a hard or a soft thresholding approach is used, the k-sigma value should be
preferred to the universal $\sqrt{(2 \log(n))}$ value. 
Multiresolution Wiener filtering and hierarchical Wiener filtering are
not at all competitive.

 The multiscale entropy method is an adaptive soft approach 
which is certainly the best when considering both visual quality and the
PSNR criterion. At low noise levels, a FWT can be used, 
which allows better restoration of edges (assuming the image does 
contain edges!),
and at high noise levels, the \`a trous algorithm must be chosen since 
otherwise
artifacts related to decimation appear. However, these artifacts are less
severe than those produced by poor thresholding. 

\begin{figure}[htb]
\centerline{
\vbox{ 
\psfig{figure=fig_cmp_filter.ps,bbllx=3.5cm,bblly=14cm,bburx=19.5cm,bbury=25.cm,width=12cm,height=6.5cm}
}}
\caption{Filtered wavelet coefficients versus wavelet coefficients (for a
noise standard deviation equal to 1) by four methods: hard thresholding, soft
thresholding, multiscale entropy filtering, and multiscale entropy filtering
with a non-constant $\alpha$ (SNR-dependent) value.}
\label{fig_cmp_filter}
\end{figure}

Figure~\ref{fig_cmp_filter} shows how a wavelet coefficient is modified using
a hard thresholding, a soft thresholding, MEF method, and MEF method with
$\alpha$ as a function of the SNR. As we can see, MEF methods are intermediate
between hard and soft thresholding, but do not present any discontinuity
as the hard thresholding. This is the reason why good SNR is obtained with
the MEF method, while retaining also good visual quality. 

 
As the previous section demonstrates, it is not easy to find an optimal
method for all noise amplitudes. At low noise levels, hard thresholding
methods produce perfect results, and when the noise increases, the 
situation changes. Orthogonal transforms produce artifacts related to the 
decimation, hard thresholding produces visual artifacts  which
are less severe with soft methods, such  as soft thresholding and multiscale
entropy. The isotropic wavelet transform allows better extraction of
 isotropic structures, whereas the biorthogonal transform describes  
 the contours in a better way. The MMT permits also a relatively good 
object shape description. The conclusion is that there is no perfect method.
 Each method has its advantages and its drawbacks, and can  be
in some situations  better than others. Parameters for choosing
one method rather than another include  the noise level, the nature of
the noise, and the shape of the significant information.

Having a default optimal method seems impossible when using any of the
strategies described above. This can also be interpreted in another 
way: the complexity of an image is so high, that all vision models 
are too simplistic to fully describe the information, and subsequently to 
separate
the signal from the noise. 

We have therefore developed the idea to combine 
the results obtained from different filtering strategies. Seven filtered
images have been simply averaged. These seven images were obtained from
the soft thresholding, the hard thresholding, and the multiscale entropy method
using both the \`a trous algorithm and the biorthogonal transform,
 and the hierarchical thresholding with the \`a trous algorithm.
PSNR is represented in Table~\ref{comptab3}. Comparing Table~\ref{comptab3}
with previous results, we see that PSNR of the combined method
is clearly always above that of all other methods. The visual aspect is 
also always
improved. This means that the results obtained from different vision models
do not present the same artifacts, which tend to disappear when  
averaging. The significant information is perhaps lost in some of the 
combined images,
but not in all, and the combined filtered image is always better.

\begin{table}[hbt]
\begin{center}
\begin{tabular}{lc} \hline \hline
Images              &  PSNR    \\ \hline \hline
 Lena+$5\sigma$    &   37.09  \\
 Lena+$10\sigma$   &   33.90  \\
 Lena+$30\sigma$   &   29.44  \\
                    &          \\
  Landscape+$5\sigma$   &  34.70          \\
  Landscape+$10\sigma$   & 31.39          \\
  Landscape+$30\sigma$   &   27.42        \\ \hline \hline
\end{tabular}
\caption{PSNR after averaging of seven filtered images.}
\vspace{0.5cm}
\label{comptab3}
\end{center}
\end{table}




