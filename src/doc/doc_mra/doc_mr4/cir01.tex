%\documentclass[twocolumn]{IEEEtran} %!PN
%\documentclass[11pt]{IEEEtran} %!PN
\documentclass[11pt,draft]{IEEEtran} %!PN
\usepackage{graphicx}
\usepackage{amssymb,amsmath,latexsym}
\usepackage{psfig}
\psfigurepath{./PS}


%%% version
%%% 01 Jun 14, 2000, X. Huo


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%\newcommand{\deq}{\overset{d}{=}}
\newcommand{\deq}{\stackrel{d}{=}}
\newcommand{\ra}{\rightarrow}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\dapprox}{\stackrel{d}{\approx}}
\newcommand{\eps}{\varepsilon}

\newtheorem{theorem}{Theorem}%[]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}
\newtheorem{remarks}[theorem]{Remarks}
\setcounter{page}{1}

\begin{document}

\title{Some Exploratory Experiments on Combined Image Representation} %!PN

\author{Xiaoming Huo, David Donoho and Jean-Luc Starck
\thanks{Xiaoming Huo is an assistant professor in the school of
  Industrial and System Engineering at Georgia Institute of Technology.
  his email is xiaoming@isye.gatech.edu.}
\thanks{David Donoho is ...}
\thanks{Jean-Luc Starck is ...}}
\date{}
% \markboth{IEEE Transactions On Image Processing, Vol. XX, No. Y,
 % Month 2000}
\markboth{}{Huo, Donoho and Starck: combining} %!PN
\maketitle
%\thispagestyle{plain}\pagestyle{plain}

\begin{abstract}

\end{abstract}

\begin{keywords}
Combined Image Transform, Sparsity, Image Representation...
\end{keywords}

\section{Introduction}
\PARstart{T}{he} fundamental problem in image compression is about how 
to use the least amount of bits to represent the objective image. Some 
recent advances in applied math, especially in computational harmonic
analysis, together with recent development in digital signal
processing provides convenient tools to attack this problem. One of
the key idea \cite{MallatFalzon} is that to find an efficient image
compression method, to the most part, what we need to do is to find a
sparse representation of an objective image in a given dictionary. The 
sparsity is measured by the rate of decay of the amplitudes of the
coefficients in the linear decomposition. The result in
\cite{MallatFalzon} is celebrating because it is particularly developed 
for low bit rate image compression, which is what we usually
encounter. Although \cite{MallatFalzon} mainly talks about its
application in wavelet image compression, the same idea can be easily
extended to any given dictionary. Note wavelet basis is a special
dictionary. It is orthonormal. We refer to \cite{DonohoIT50} for a
more detailed and comprehensive description of the interplay between
data compression and harmonic analysis.

In the present paper, we consider how to find a new efficient method
in image representation. We present some numerical experiments to show that an 
approach with combined transforms is more optimal than an approach
based on a single transform. It is optimal in the
sense that the linear representation is sparser in some sense than some 
existing well-known approaches.
Based on the result in
\cite{MallatFalzon,DonohoIT50}, to find an efficient image
representation scheme, we can simply consider how to find a
{\it sparse} linear representation in a dictionary. 
Apparently if both the dictionary
and the measure of sparsity is given, then we can find the sparsest
linear decomposition through computation. Unfortunately, for each of
these three atoms---dictionary, measure of sparsity and computation---we
can ask ourselves some questions: 
\begin{itemize}
\item[{\bf P1}] What is a ``good'' dictionary for image compression?
\item[{\bf P2}] Once we have a dictionary, what are the criteria we
  should choose to determine a good measure of sparsity? 
\item[{\bf P3}] Given a dictionary and a measure of sparsity, how to
  efficiently find the sparsest linear decomposition? 
\end{itemize}

In order to show our evidences, we
need to explain our answers to the three questions above. Note
searching for the ideal solutions to these questions can deserve a long 
term effort. 

From now on, we limit our discussion in image representation scenario.

Our answer to {\bf P1} is three folded. First of all, a dictionary is
good if and only if its elements resemble the features that we intend
to represent in the objective. This is self-evident because if the
final linear decomposition is sparse, then there should be only
a few significant components in the decomposition, hence each
component should somehow be close to the objective. 

Many efforts have been invested in finding schemes that can
extract important features in certain class of signals. For example,
Fourier analysis, wavelet analysis and Gabor analysis are good at
representing some types of signals. In image representation, some of
them are complementary \cite{HuoThesis}, in the sense that each basis
contains some of these important features appearing in images, but not 
all of them. If we consider a dictionary made by any single basis, it
will not give a sparse decomposition. But if we consider a dictionary
made by combining several bases, then we can have a much sparser
decomposition. A interesting theoretical perspective is provided in
\cite{DonohoHuoUP}, which explains why in a case with two
complementary bases, a combined dictionary is unavoidable in order to
find a sparse decomposition for certain types of signals. Because of
all the above, in the present paper, we explore the possibility of
combined image transforms. 

There have been tremendous efforts in finding efficient image
transform. Many fast algorithms have been invented. Two of the best
known is the fast Fourier transform and fast discrete wavelet
transform. We intend to take advantages of these as much as
possible. At the same time, we may mention some new developments in
image transforms as needed. 

Before we move on to the {\bf P2}, let us clarify what we mean by
combining several transforms. Suppose $y$ is our objective
image. Suppose $\Phi=\{\phi_i, i\in \mathbb{I}\}$ is a dictionary, where
each $\phi_i$ was either a basis function of the basis that is
combined, or an element of a smaller dictionary that is absorbed. The
dictionary $\Phi$ is our dictionary for the combined transform. A
linear decomposition of objective $y$ in the combined transform is
simply $y = \sum_{i \in {\mathbb{I}}} c_i \phi_i$, where $C_i$'s are
coefficients.

In general, after combining several transform, we have an overcomplete 
system, or a singular system. In a singular system, for any given
objective, there are infinite many ways for the decomposition. Among
them which is the sparsest? To answer this, we need to determine the
measure of sparsity. We mentioned the works in \cite{MallatFalzon},
from there, the sparsity should be defined as the decay of the
amplitudes of coefficients. But this definition itself is too hard to
be useful. Another intuitive and simple measure of sparsity is the
$\ell^0$ norm. But unfortunately, it is not convex. To find the
minimum $\ell^0$ norm is equivalent to solve a combinatorial
optimization problem, which in general is NP hard. So for {\bf P2}, we 
want to find a measure which is convex and at the same time, when the
function value associated with this measure is small, the coefficient
is reasonably sparse. 

About {\bf P3}, we can provide a comprehensive literature survey. Some 
highly profiled methods include Match Pursuit, Basis Pursuit and Best
Basis algorithm. Each of them has advantages and disadvantages. Each
has its domain of application. Actually in a particular setting, the
answers to above questions are interwoven. The answers to {\bf P1}
and {\bf P2} determine the answer to {\bf P3}.

The rest of the paper is organized as follows...

\section{Minimum $\ell^1$ Norm Decomposition}

\section{Alternate Thresholding}

\subsection{$l^1$ optimization by soft thresholding}
\label{sect_l1}

Noting ${\cal T}_1, ..., {\cal T}_{N_t}$ the $N_t$ transform operators, 
a solution $S$  is obtained by minimizing a functional of the form:
\begin{eqnarray}
J(S) = \parallel I - \sum_{k=0}^{N_t} {\cal T}_k^{-1} c_k  \parallel_2^2 + \lambda \sum_k \parallel c_k \parallel_1
\label{eqn_min_l1}
\end{eqnarray}
where $I$ is the original image, and $c_k$ are the coefficient 
obtained with the transform ${\cal T}_k$.

An simple algorithm to achieve such an solution 
is (Donoho, private communication):
\begin{enumerate}
\item set $\lambda = L_{\max}$
\item while $\lambda >= 0$ do
\item for k = 1, .., $N_{t}$ do
\begin{itemize}
\item calculate the residual $E = I - \sum_k {\cal T}_k^{-1} r_k$
\item calculate the  transform ${\cal T}_k$ of the residual:
$e_k = {\cal T}_k E$.
\item add the residual to to $r_k$:  $r_k = r_k + e_k$
\item soft threshold the coefficient $r_k$ with the $\lambda$ threshold.
\end{itemize}
\item $\lambda = \lambda - \delta$, and goto 2.
\end{enumerate}
In our experiment, we have initialized with $L_{\max} = 20$, and 
$\delta = 2$ (10 iterations).

Figure~\ref{fig_cb1_synt} illustrates the result in the case where the
input image contains only lines and Gaussians. Two transform operators
were used, the \`a trous wavelet transform and the ridgelet transform. The 
first is well adapted to the detection of Gaussian due to the isotropy of
the wavelet function~\cite{starckbook98}, while the second is optimal
to represent lines \cite{cur_candes99_1}. Figure~\ref{fig_cb1_synt} top,
bottom left, and bottom right represents respectively the 
original image, the reconstructed image from the \`a trous wavelet coefficient, 
and the reconstructed image from the ridgelet coefficient. The addition 
of both reconstructed images reproduces the original one.

\begin{figure}[htb]
\vbox{
\centerline{
\hbox{
\psfig{figure=fig_cb2_line_g.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}}
}
\centerline{
\hbox{
\psfig{figure=fig_cb2_line_g_atrou.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
\psfig{figure=fig_cb2_line_g_rid.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
}}}
\caption{Top, original image containing lines and gaussian. Botton left,
reconstructed image for the \`a trous wavelet coefficient, bottom right,
reconstructed image from the ridgelet coefficients.}
\label{fig_cb1_synt}
\end{figure}

In some specific cases where the data are sparse in all bases, 
it has been shown \cite{HuoThesis}  
that the solution is identical to the solution when using a 
$\parallel . \parallel_0$ penalty term. This is however generally not the 
case. The problem we met when minimizing equation~\ref{eqn_min_l1} is 
that both the signal and noise are splitted into the bases. The way the noise
is distributed in the coefficients $c_k$ is not known, and leads to the problem
that we do not know at which level we should threshold the coefficients. Using
the threshold we would have used with a single transform 
makes a strong over-filtering of the data. Using the $l^1$ optimization 
for data restoration implies that we study first how the noise is 
distributed in the coefficients.

\subsection{$l^0$ optimization by hard thresholding ?}
\label{sect_l0}
The following algorithm consists in hard thresholding the residual 
successively on the different bases. 
\begin{enumerate}
\item initialize $ L_{\min}, L_{\max}$ and the number of iterations $Ni$.
\item set $\Delta = \frac{L_{\max} - L_{\min}}{Ni}$
\item set $\lambda = L_{\max}$
\item set all coefficients $c_k$ to 0.
\item while $\lambda >= L_{\min}$ do
\item for k = 1, .., $N_{rid}$ do
\begin{itemize}
\item calculate the residual $E = I - \sum_k {\cal R}_k^{-1} c_k$
\item calculate the transform ${\cal T}_k$ of the residual:
$e_k = {\cal T}_k E$.
\item for all coefficients $c_k$ of the transform by $T_k$ do
\begin{itemize}
\item hard (or soft) threshold the coefficient $e_k$ with the $\lambda$ threshold.
We get $\tilde e_k$.
\item if $c_k \ne 0$ or $\mid r_k \mid > k \sigma$ then $c_k = c_k + r_k$
\end{itemize}
\end{itemize}
\item $\lambda = \lambda - \delta$, and goto 5.
\end{enumerate}
For an exact representation of an image, $k$ must be set to 0.
Chosing $k > 0$ introduces a filtering.

It would be natural that starting with a high enough $L_{\max}$  and a high
number of iterations would lead to the $l^0$ optimization solution,
but this remains to be proved.  
In our simulations, we have set $L_{\max}$ and $Ni$ to 40. For an exact
representation of the input data (i.e. $S=I$), we have set 
  $ L_{\min} $ to 0. A filtered version of $I$ is obtained by increasing
$ L_{\min} $. We used $L_{\min} = 4$ in our simulations. 
This method does not present the drawback of the previous relative to the
distribution of the noise in the different bases. As a hard thresholding
is used, when a feature is detected in the residual by a given base, it
is extracted. Hence, it cannot be diluted in several bases. This important
for a restoration purpose. Indeed, it means that the detection level in
a given base is unchanged by the fact that we use a set of bases.

\section{Applications}
\subsection{Elongated - point like object sepatation in astronomical images}
% \subsubsection{NGC2997}
% \subsubsection{A370}

\begin{figure}[htb]
\centerline{
\vbox{
\hbox{
\psfig{figure=fig_cb2_ngc2997.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
\psfig{figure=fig_cb2_ngcatrou.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
}
\hbox{
\psfig{figure=fig_cb2_ngcrid.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
\psfig{figure=fig_cb2_ngc_cb.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
}}}
\caption{Top left, galaxy NGC2997, top right reconstructed image from
the \`a trous wavelet coefficients, bottom left, reconstruction from
the ridgelet coefficients, and bottom right addition of both reconstructed
images.}
\label{fig_cb2_ngc}
\end{figure}
Figure~\ref{fig_cb2_ngc} shows the result of a decomposition 
of a spirale galaxy (NGC2997).
This image (figure~\ref{fig_cb2_ngc} top left) contains
many compact structures (stars amd HII region), more
or less isotropic, and large scale elongated features (NGC2997 spirale part).
Compact objects are well represented by isotropic wavelets, and the  
elongated features are better represented by a ridgelet basis. 
In order to benefit of the optimal data representation of both transforms,
 the image has been decomposed on both the \`a trous wavelet transform and on 
the ridgelet transform by using the same method as described in
section~\ref{sect_l0}. When the functional is minimized, we get two 
images, and their coaddition is the filtered version of the original image.
The reconstructions from the \`a trous coefficient, and from the rigelet
the ridgelet coefficient can be seen in figure~\ref{fig_cb2_ngc} top right
and bottom left. The addition of both images is presented 
in figure~\ref{fig_cb2_ngc} bottom right.


\subsection{Filtering}
A simulation has been done with the classical
Lena 512$\times$512 image. A white Gaussian noise 
with a standard deviation equal to 20 has been added to the
original data. The noisy image has been filtered by the 
undecimated wavelet transform, the curvelet transform, and
a combination of three methods (ridgelet, curvelet, and undecimated wavelet).
Results are given in table~\ref{comptab1}

\voffset -1truecm
\begin{table}[htb]
\begin{center}
\begin{tabular}{lccccc} \hline \hline
Method                          & PSNR   &  Comments   \\ \hline \hline
Noisy image                     & 22.13  &     \\
UWT7-9 + ksigma  Hard thresh.   & 31.94  &    very few artifact \\
Curvelet (B=16)                 & 31.95  &    no artifact  \\ 
Combined filtering              & 32.17  &    no artifact  \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image (Lena + Gaussian noise (sigma=20)).
In the combined filtering, a ridgelet, a curvelet, and a undecimated wavelet
transform have been used.}
\vspace{0.5cm}
\label{comptab1}
\end{center}
\end{table}

\begin{figure}[htb]
\centerline{
\vbox{
\hbox{
\psfig{figure=fig_lena_g20.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
\psfig{figure=fig_lena_f24.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
}
\hbox{
\psfig{figure=fig_lena_cur.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
\psfig{figure=fig_lena_mbase.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
}}}
\caption{Noisy image, and filtered images by the undecimated wavelet
transform, the curvelet transform, and the combined method.}
\label{fig_cb2_lenna}
\end{figure}


\begin{figure}[htb]

\vbox{
\centerline{
\hbox{
\psfig{figure=fig_resi_lena_f24.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
\psfig{figure=fig_resi_lena_cur.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
}}
\centerline{
\hbox{
\psfig{figure=fig_resi_lena_mbase.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=8cm,height=8cm,clip=}
}}}
\caption{Top, residual for the undecimated wavelet transform, and 
the curvelet transform, bottom, residual for the combined method.}
\label{fig_cb2_lenna_resi}
\end{figure}

Figure~\ref{fig_cb2_lenna} shows the noisy image (top left), the 
UWT filtering (top right), the curvelet filtering (bottom left), and
the combined filtering (bottom right). The residuals of the three 
methods are shown in figure~\ref{fig_cb2_lenna_resi}.

% \subsection{Compression ???}

\section{Conclusion}
From these simulations, we can conclude that the combined filtering 
leads to a real improvement for both the PSNR and the visual aspect, and
only a combination of methods allows us to clean properly the residual.

\section{Discussion}


\begin{appendix}

\end{appendix}

\nocite{*}
\bibliographystyle{IEEEbib}
\bibliography{HuoDonohoStarck}  % commented if *.bbl file included, as

\end{document}
