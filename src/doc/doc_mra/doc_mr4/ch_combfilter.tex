\chapter{The Combined Filtering Method}
% \section{The Combined Filtering Method}
\section{Introduction}
\label{sect_comb}

\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=fig_resi_lena_f24.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.5cm,height=7.5cm,clip=}
\psfig{figure=fig_resi_lena_cur.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.5cm,height=7.5cm,clip=}
}}
\caption{Residual for thresholding of the undecimated
wavelet transform and thresholding of 
the curvelet transform.}
\label{fig_lenna_resi}
\end{figure}

Although the results obtained by simply thresholding the curvelet expansion
are encouraging, there is of course ample room for further
improvement. A quick inspection of the residual images for both the
wavelet and curvelet transforms shown in Figure~\ref{fig_lenna_resi}
reveals the existence of very different features.  For instance,
wavelets do not restore long edges with high fidelity while curvelets
are seriously challenged by small features such as {\tt Lena}'s eyes. Loosely
speaking, each transform has its own area of expertise and this
complementarity may be of great potential. This section will develop a
denoising strategy based on the idea of combining both transforms.

In general, suppose that we are given $K$ linear transforms $T_1,
\ldots, T_K$ and let $\alpha_k$ be the coefficient sequence of an
object $x$ after applying the transform $T_k$, i.e. $\alpha_k = T_k
x$. We will suppose that for each transform $T_k$ we have available a
reconstruction rule that we will denote by $T^{-1}_k$ although this is
clearly an abuse of notation.  Finally, $T$ will denote the block
diagonal matrix with the $T_k$'s as building blocks and $\alpha$ the
amalgamation of the $\alpha_k$'s.

A hard thresholding rule associated with the transform $T_k$ synthesizes 
an estimate $\tilde{s}_k$ via the formula 
\begin{equation}
\label{eq:ht}
\tilde{s}_k = T_k^{-1} \delta(\alpha_k)
\end{equation}
where $\delta$ is a rule that sets to zero all the coordinates of
$\alpha_k$ whose absolute value falls below a given sequence of
thresholds (such coordinates are said to be non-significant).

In practice, a widely used approach is to compute the average of the
$\tilde{s}_k$'s giving a reconstruction of the form
 \begin{equation}
\tilde{s} = \sum_k \tilde{s}_k/K. 
\end{equation}
For instance, in the literature of image processing it is common to
average reconstructions obtained after thresholding the wavelet
coefficients of translated versions of the original dataset
(cycle-spinning), i.e. the $T_k$'s are obtained by composing
translations and the wavelet transform.  In our setup, we do not find
this solution very appealing since this creates the opportunity to
average high-quality and low-quality reconstructions.

\section{The Combined Filtering Principle}

Given data $y$ of the form $y = s + \sigma z$, where $s$ is the image
we wish to recover and $z$ is standard white noise, we propose solving
the following optimization problem \cite{starck:spie01a}:
\begin{equation}
  \label{eq:l1-min}
  \min \|T\tilde{s}\|_{\ell_1}, \quad \mbox{subject to} \quad s \in C,  
\end{equation}
where $C$ is the set of vectors $\tilde{s}$ 
which obey the linear constraints
\begin{equation}
\label{eq:constraints}
\left\{  \begin{array}{ll}
  \tilde{s} \ge 0, \\
  |T\tilde{s} - Ty| \le e; 
  \end{array}
  \right. 
\end{equation}
here, the second inequality constraint 
only concerns the set of significant coefficients, 
i.e. those indices $\mu$ such that $\alpha_\mu =
(Ty)_\mu$ exceeds (in absolute value) a threshold $t_\mu$. Given a
vector of tolerance $(e_\mu)$, we seek a solution whose coefficients
  $(T\tilde{s})_\mu$ are within $e_\mu$ of the noisy
empirical $\alpha_\mu$'s.  Think of $\alpha_\mu$ as being given by
\[
y = \langle y, \varphi_\mu \rangle, 
\]
so that $\alpha_\mu$ is normally distributed with mean $\langle f,
\varphi_\mu \rangle$ and variance $\sigma^2_\mu = \sigma^2
\|\varphi_\mu\|^2_2$. In practice, the threshold values range
typically between three and four times the noise level $\sigma_\mu$
and in our experiments we will put $e_\mu = \sigma_\mu/2$. In short,
our constraints guarantee that the reconstruction will take into
account any pattern which is detected as significant by  any of the
$K$ transforms.
   
We use an $\ell_1$ penalty on the coefficient sequence because we are
interested in {\em low complexity} reconstructions. There are other
possible choices of complexity penalties; for instance, an alternative
to (\ref{eq:l1-min}) would be
\[
\label{eq:tv-min}
  \min \|\tilde{s}\|_{TV}, \quad \mbox{subject to} \quad s \in C. 
\]
where $\|\cdot\|_{TV}$ is the Total Variation norm, i.e.\ the discrete
equivalent of the integral of the Euclidean norm of the gradient.

\section{The Minimization Method}

We propose solving (\ref{eq:l1-min}) using the method of hybrid
steepest descent (HSD) \cite{wave:yamada01}. HSD consists of building
the sequence
\begin{eqnarray}
 s^{n+1} = P(s^{n}) - \lambda_{n+1} \nabla_J(P(s^{n})); 
\end{eqnarray}
Here, $P$ is the $\ell_2$ projection operator onto the feasible set
$C$, $\nabla_J$ is the gradient of equation~\ref{eq:l1-min}, and
$(\lambda_{n})_{n \ge 1}$ is a sequence obeying $(\lambda_{n})_{n\ge
  1} \in [0,1] $ and $\lim_{ n \rightarrow + \infty } \lambda_{n} = 0$.

Unfortunately, the projection operator $P$ is not easily determined
and in practice we will use the following proxy; compute $T \tilde{s}$
and replace those coefficients which do not obey the constraints $|T
\tilde{s} - Ty| \le e$ (those which fall outside of the prescribed
interval) by those of $y$; apply the inverse transform.  

% {\tt Needs work.} Then apply thresholding. This approximation gives
The combined filtering algorithm is:
\begin{enumerate}
\baselineskip=0.4truecm
\itemsep=0.1truecm
\item Initialize $L_{\max} = 1$, the number of iterations $N_i$, and
  $\delta_{\lambda} = \frac{L_{\max}}{N_i}$.
\item Estimate the noise standard deviation $\sigma$, and set $e_k =
  {\sigma \over 2}$.
\item For k = 1, .., $K$ calculate the transform: $\alpha^{(s)}_k
  = T_k s$.
\item Set $\lambda = L_{\max}$, $n = 0$, and $\tilde s^{n}$ to 0.
\item While $\lambda >= 0$ do
\begin{itemize}
\item $u = \tilde s^{n}$.
\item For k = 1, .., $K$ do
  \begin{itemize}
  \item Calculate the transform $\alpha_{k} = T_k u$.
  \item For all coefficients $\alpha_{k,l}$ do
     \begin{itemize}
     \item Calculate the residual $r_{k,l} = \alpha^{(s)}_{k,l} -
       \alpha_{k,l}$
       
     \item if $\alpha^{(s)}_{k,l}$ is significant and $ \mid r_{k,l}
       \mid > e_{k,l}$ then $\alpha_{k,l} = \alpha^{(s)}_{k,l}$
     \item $\alpha_{k,l} = sgn(\alpha_{k,l}) ( \mid \alpha_{k,l} \mid - \lambda)_{+}$.
     \end{itemize}
   \item $u = T_k^{-1} \alpha_{k}$
  \end{itemize}
\item Threshold negative values in $u$ and $\tilde s^{n+1} = u$.
\item $n = n + 1$, $\lambda = \lambda - \delta_{\lambda} $, and goto 5.
\end{itemize}
\end{enumerate}

\section{Experiments}

\voffset -1truecm
\begin{table}[htb]
\begin{center}
\begin{tabular}{lccccc} \hline \hline
Method                          & PSNR   &  Comments   \\ \hline \hline
Noisy image                     & 22.13  &     \\
OWT7-9 + k-sigma  Hard thresh.   & 28.35  &   many artifacts \\
UWT7-9 + k-sigma  Hard thresh.   & 31.94  &   very few artifacts \\
Curvelet (B=16)                 & 31.95  &   no artifact  \\ 
Combined filtering              & 32.72  &   no artifact  \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image (Lena + Gaussian 
noise, sigma=20).
In the combined filtering, a curvelet and an undecimated wavelet
transform were used.}
\vspace{0.5cm}
\label{comptab2}
\end{center}
\end{table}

The noisy {\tt Lena} image (the noise standard deviation being equal 20)
was filtered by the undecimated
wavelet transform, the curvelet transform, and by our combined
transform approach (curvelet and undecimated wavelet transforms). The
results are reported in Table~\ref{comptab2}.
Figure~\ref{fig_cb2_lenna} displays the noisy image (top left), and
the restored image after denoising by the combined transforms (bottom right). 
Details are
displayed in Figure~\ref{fig_cb2_lenna} bottom left.  
Figure~\ref{fig_cb2_lenna}  bottom  right shows the full residual image, and 
can be compared  to the residual images shown in Figure~\ref{fig_lenna_resi}.
The residual is much better when the combined filtering is applied, and no
feature can be detected any more by eye. This was not the case for either the
wavelet and the curvelet filtering.

\begin{figure}[htb]
\centerline{ 
\vbox{ 
\hbox{
 \psfig{figure=fig_lena_g20.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.5cm,height=7.5cm,clip=}
 \psfig{figure=fig_lenna_cfil_wt_cur.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.5cm,height=7.5cm,clip=}
 }
\hbox{
\psfig{figure=fig_lena_cfil_rid_cur_x185_y342_sub.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.5cm,height=7.5cm,clip=}
\psfig{figure=fig_resi_cfil_wt_cur.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.5cm,height=7.5cm,clip=}
}	
}}
\caption{Noisy image (top left), and filtered image based on the
  combined transform (top right). Bottom left panel shows a detail 
  of the filtered image. The full residual image is displayed on the bottom right.}
\label{fig_cb2_lenna}
\end{figure}

\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=fig_ctm_iter.ps,bbllx=2.5cm,bblly=13.cm,bburx=19.5cm,bbury=25cm,width=10cm,height=7cm,clip=}
}}
\caption{PSNR versus the number of iterations.}
\label{fig_iter_cvg}
\end{figure}

Figure~\ref{fig_iter_cvg} displays the PSNR of the solution versus the
number of iterations. In this example, the algorithm is shown to
converge rapidly. From a practical viewpoint only four or five
iterations are truly needed.  Note that the result obtained after a
single iteration is already superior to those available using
methods based on the thresholding of wavelet or curvelet coefficients
alone.

\begin{table*}[htb]
\begin{center}
\begin{tabular}{lcc} \hline \hline
Method                         & PSNR   & PSNR  \\ 
                               & (coeff. $l_1$ norm minim.) & (TV minim.) \\ \hline \hline
 Undecimated wavelet only      & 32.00   &  32.43 \\
 Curvelet only                 & 32.03   &  32.40 \\ 
 Wavelet + curvelet            & 32.72   &  32.77 \\ 
 (Combined filtering)          &         &   \\ \hline \hline
\end{tabular}
\caption{PSNR after filtering the simulated image 
(Lena + Gaussian noise, sigma=20).
In the combined filtering, a curvelet and an undecimated wavelet
transform have been used.}
\vspace{0.5cm}
\label{cur_comptab3}
\end{center}
\end{table*}

Several papers have been recently published, based on the concept
of minimizing the total variation under constraints in the 
wavelet domain \cite{rest:froment01,rest:froment02a,rest:malgouyres02} or in 
the curvelet domain \cite{rest:candes02}. Our combined approach
can be seen as a generalization of these methods.
We carried out a set of experiments in order to estimate (i) if the
total variation is better than the $l_1$ norm of the multiscale
coefficients, and (ii) if the combined approach improves the 
results compared to a single transform based method.

In our example, Gaussian noise with a standard deviation equal
to 20 was added to the classical {\tt Lena} image (512 by 512).
Several methods were used to filter the noisy image:
\begin{enumerate}
\item TV + constraint in the wavelet domain.
\item TV + constraint in the curvelet domain.
\item Wavelet $l_1$ norm minimization + wavelet constraints.
\item Curvelet $l_1$ norm minimization + curvelet constraints.
\item Combined filtering method using multiscale coefficient $l_1$ 
norm minimization.
\item Combined filtering method using TV minimization.
\end{enumerate}
We use the PSNR as an ``objective'' measure of performance.  
The noisy image PSNR is $22.13$. 
PSNR results from the different tested methods 
are reported in Table~\ref{cur_comptab3}.

We observe that combined filtering leads to a significant improvement
when compared to a single transform based method. 
The TV penalization gives better results when a single transform is used,
while it 
seems not to have too much importance for the combined filtering approach.
We will see in the following that the latter
is not true for the deconvolution problem.

% \clearpage
\section{Discussion}
We believe that the denoising experiments presented in this paper are
of very high quality: 
\begin{enumerate}
\item Combined filtering leads to a real
improvement both in terms of PSNR and visual appearance. 
\item The combined approach arguably challenges the eye to distinguish
  structure/features from residual images of real image data (at least
  for the range of noise levels that was considered here). Single
  transforms cannot manage such a feat.  
\end{enumerate}
We also note that the combined reconstruction may tend to be free of
major artifacts which is very much unlike typical thresholding rules.
Although the ease of implementation is clear we did not address the
computational issues associated with our method. In a nutshell, the
algorithms we described require calculating each transform and its
inverse only a limited  number of times. 

In our examples, we constructed a combined transform from linear
transforms (wavelets, ridgelets and curvelets) but our paradigm
extends to any kind of nonlinear transform such as the Pyramidal
Median Transform \cite{starck:book98} or morphological multiscale
transforms \cite{wave:goutsias99b}.


\clearpage
\newpage


