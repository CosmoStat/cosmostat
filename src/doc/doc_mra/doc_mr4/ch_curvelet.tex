\chapter{The Curvelet Transform}
\section{Introduction}
 Wavelets and related multiscale representations pervade  all
areas of signal processing. The recent inclusion of wavelet algorithms
in JPEG 2000, the new still-picture compression standard, testifies
to this lasting and significant impact.  
The most used
wavelet transform algorithm is the decimated bi-orthogonal
wavelet transform (OWT). Using the OWT, a signal $s$ can be decomposed
by:
\begin{eqnarray}
  s(l) = \sum_{k} c_{J,k} \phi_{J,l}(k) 
        +  \sum_{k} \sum_{j=1}^J \psi_{j,l}(k) w_{j,k}
 \end{eqnarray}
 with $\phi_{j,l}(x) = 2^{-j} \phi(2^{-j}x-l)$ and $\psi_{j,l}(x) =
 2^{-j} \psi(2^{-j}x-l)$, where $\phi$ and $\psi$ are respectively the
 scaling function and the wavelet function.  $J$ is the number of
 resolutions used in the decomposition, $w_{j}$ the wavelet (or
 detail) coefficients at scale $j$, and $c_{J}$ is a coarse or smooth
 version of the original signal $s$.  Thus, the algorithm outputs $J+1$
 subband arrays.  The indexing is such that, here, $j = 1$ corresponds
 to the finest scale (high frequencies).

The application of the OWT to image compression, using the 7-9 filters
 \cite{wave:antonini92} and the zerotree coding
\cite{compress:shapiro93,compress:said96} has lead to impressive
results, compared to previous methods like JPEG.   

A series of recent papers
\cite{Roysoc,Curvelets-StMalo}, however, argued that wavelets and related
classical multiresolution ideas are playing with a limited dictionary
made up of roughly isotropic elements occurring at all scales and
locations. We view as a limitation the facts that those dictionaries
do not exhibit highly anisotropic elements and that there is only a
fixed number of directional elements, independent of scale.  
Despite the success of the classical wavelet viewpoint, there are objects, 
e.g.\  images, that do
not exhibit isotropic scaling and thus call for other kinds of
multiscale representation. In short, the theme of this line of
research is to show that classical multiresolution ideas only address
a portion of the whole range of interesting multiscale phenomena and
that there is an opportunity to develop a whole new range of
multiscale transforms.

Following on this theme, Cand\`es and Donoho in\-tro\-du\-ced new mul\-ti\-scale
systems like curvelets \cite{Curvelets-StMalo} and ridgelets \cite{Harmnet}
which are very different from wavelet-like systems. Curvelets and
ridgelets take the form of basis elements which exhibit very high
directional sensitivity and are highly anisotropic.  In
two-dimensions, for instance, curvelets are localized along curves, in
three dimensions along sheets, etc.  Continuing at this informal level
of discussion we will rely on an example to illustrate the fundamental
difference between the wavelet and ridgelet approaches, postponing
the mathematical description of these new systems.

We investigate in this document the best way to implement 
the ridgelet and the curvelet transform for the purpose of image restoration.
The second and third sections describe respectively
the ridgelet transform and the curvelet transform.
Section four shows how the ridgelet and the wavelet coefficients can be
thresholded in order to filter an image. Comparisons with other methods
are presented. Instructions for using the programs are given in the last 
section.

\begin{figure}[htb]
\centerline{
\vbox{
\hbox{
\psfig{figure=fig_bar_noise.ps,bbllx=1.7cm,bblly=12.5cm,bburx=14.7cm,bbury=25.5cm,width=6.5cm,height=6.5cm,clip=}
\psfig{figure=fig_bar_coupe.ps,bbllx=2.5cm,bblly=13.5cm,bburx=19.5cm,bbury=25.5cm,width=6.5cm,height=6.5cm,clip=}
}
\hbox{
\psfig{figure=fig_bar_wave.ps,bbllx=1.7cm,bblly=12.5cm,bburx=14.7cm,bbury=25.5cm,width=6.5cm,height=6.5cm,clip=}
\psfig{figure=fig_bar_rid.ps,bbllx=1.7cm,bblly=12.5cm,bburx=14.7cm,bbury=25.5cm,width=6.5cm,height=6.5cm,clip=}
}}}
\caption{Top left, original image containing a vertical band embedded in 
white noise with relatively large amplitude.  Top right, row sums 
illustrating the hardly perceptable band.  Bottom left,
reconstructed image using undecimated wavelet coefficients. Bottom right,
reconstructed image using ridgelet coefficients.}
\label{fig_bar}
\end{figure}

Consider an image which contains a vertical band embedded in white
noise with relatively large amplitude.  Figure~\ref{fig_bar} (top
left) represents such an image.  The parameters are as follows: the
pixel width of the band is 20 and the SNR (signal-to-noise ratio)
is set to be $0.1$. Note
that it is not possible to distinguish the band by eye. The wavelet
transform (undecimated wavelet transform) is also incapable of
detecting the presence of this object; roughly speaking, wavelet
coefficients correspond to averages over approximately isotropic
neighborhoods (at different scales) and those wavelets clearly do not
correlate very well with the very elongated structure (pattern) of
the object to be detected.

We now turn our attention towards procedures of a very different
nature which are based on line measurements. To be more specific,
consider an {\em ideal} procedure which consists of integrating the
image intensity over columns; that is, along the orientation of our
object.  We use the adjective ``ideal'' to emphasize the important
fact that this method of integration requires a priori knowledge about
the structure of our object. This method of analysis gives of course
an improved signal-to-noise ratio for our linear functional better
which is better correlated with the object in question: 
see the top right panel of
Figure~\ref{fig_bar}.

This example will make our point. Unlike wa\-velet trans\-forms, the
rid\-gelet trans\-form pro\-cesses data by first computing integrals over
lines with all kinds of orientations and locations. We will explain in
the next section how the ridgelet transform further processes those
line integrals. For now, we apply naive thresholding of the ridgelet
coefficients and ``invert'' the ridgelet transform; the bottom right
panel of Figure~\ref{fig_bar} shows the reconstructed image. The
qualitative difference with the wavelet approach is striking. We
observe that this method allows the detection of our object even in
situations where the noise level (standard deviation of the white
noise) is five times superior to the object intensity. 

\section{Continuous Ridgelet Transform}

The two-dimensional continuous ridgelet transform in $\bR^2$ can be
defined as follows \cite{Harmnet}. We pick a smooth univariate
function $\psi:\bR \goto \bR$ with sufficient decay and satisfying the
admissibility condition
\begin{equation}
\label{eq:admissibility}
\int |\hat{\psi}(\xi)|^2/|\xi|^2 \, d\xi < \infty,
\end{equation}
which holds if, say, $\psi$ has a vanishing mean $\int
\psi(t) dt = 0$.  We will suppose that $\psi$ is normalized so that
$\int |\hat{\psi}(\xi)|^2 \xi^{-2} d\xi = 1$.

For each $a > 0$, each $b \in \bR$ and each $\theta \in [0,2\pi)$, we
define the bivariate {\em ridgelet} $\psi_{a,b,\theta}: \bR^2 \goto
\bR^2$
by
\begin{equation}
\label{eq:ridgelet}
       \psi_{a,b,\theta} (x) = a^{-1/2} \cdot
     \psi( (x_1 \cos\theta + x_2 \sin\theta  - b)/a);
\end{equation}
this function is constant along lines $x_1 \cos\theta + x_2 \sin\theta
= const$. Transverse to these ridges it is a wavelet.  

\begin{figure}[htb]
\centerline{
\vbox{
\hbox{
\psfig{figure=ridgelet.eps,bbllx=0.5cm,bblly=6cm,bburx=20.5cm,bbury=21cm,width=5.5cm,height=5.5cm,clip=}
\psfig{figure=ridgerotate.eps,bbllx=0.5cm,bblly=6cm,bburx=20.5cm,bbury=21cm,width=5.5cm,height=5.5cm,clip=}
}
\hbox{
\psfig{figure=ridgescale.eps,bbllx=0.5cm,bblly=6cm,bburx=20.5cm,bbury=21cm,width=5.5cm,height=5.5cm,clip=}
\psfig{figure=ridgeshift.eps,bbllx=0.5cm,bblly=6cm,bburx=20.5cm,bbury=21cm,width=5.5cm,height=5.5cm,clip=}
}
}}
\caption{A few ridgelets.}
\label{fig_rid_function}
\end{figure}

Figure~\ref{fig_rid_function} graphs a few ridgelets with different
parameter values. The top right, bottom left and right panels
are obtained after simple geometric manipulations of the upper left
ridgelet, namely rotation, rescaling, and shifting.  

Given an
integrable bivariate function $f(x)$, we define its ridgelet
coefficients by
\[
\cR_f(a,b,\theta) = \int \psi_{a,b,\theta}(x) f(x) dx.
\]
We have the exact reconstruction formula
\begin{equation}
\label{eq:CRT}
f(x) = \int_0^{2\pi} \int_{-\infty}^\infty \int_0^\infty
\cR_f(a,b,\theta) {\psi}_{a,b,\theta}(x) \frac{da}{a^3} db
\frac{d\theta}{4\pi}
\end{equation}
valid a.e.\ (almost everywhere) 
for functions which are both integrable and square
integrable. Furthermore, this formula is stable since we have a Parseval
relation
\begin{equation}
\label{eq:Parseval}
       \int |f(x)|^2 dx = \int_0^{2\pi} \int_{-\infty}^\infty
\int_0^\infty
|\cR_f(a,b,\theta)|^2 \frac{da}{a^3} db \frac{d\theta}{4\pi}.
\end{equation}
Hence, much like the wavelet or Fourier transforms, the identity
(\ref{eq:CRT}) expresses the fact that one can represent any arbitrary
function as a continuous superposition of ridgelets.  Discrete
analogs of (\ref{eq:CRT})-(\ref{eq:Parseval}) exist, see
\cite{Harmnet}, or \cite{Ortholinear} for a slightly different
approach.

\subsection{The Radon Transform}

A basic tool for calculating ridgelet coefficients is to view ridgelet
analysis as a form of wavelet analysis in the Radon domain. We recall
that the Radon transform of an object $f$ is the collection of line
integrals indexed by $(\theta,t) \in [0,2\pi) \times \bR$ given by
\begin{equation}
      \label{eq:Radon}
      Rf(\theta,t) = \int f(x_1,x_2)
\delta(x_1 \cos\theta + x_2 \sin\theta - t)\, dx_1 dx_2,
\end{equation}
where $\delta$ is the Dirac distribution. The ridgelet coefficients
$\cR_f(a,b,\theta)$ of an object $f$ are given by analysis of the Radon
transform via
\[
\cR_f(a,b,\theta) = \int Rf(\theta,t) a^{-1/2} \psi((t - b)/a) \, dt.
\]
Hence the ridgelet transform is precisely the application of a
1-dimensional wavelet transform to the slices of the Radon transform
where the angular variable $\theta$ is constant and $t$ is varying.

\subsection{Ridgelet Pyramids}
\label{sec:pyramid}

Let $Q$ denote a dyadic square $Q = [k_1/2^s,(k_1+1)/2^s) \times
[k_2/2^s, (k_2+1)/2^s)$ and let ${\cal Q}$ be the collection of all
such dyadic squares. We write ${\cal Q}_s$ for the collection of all
dyadic squares of scale $s$. Associated with the squares
$Q \in \cQ_s$ we construct a partition of energy
as follows. With $w$ a nice smooth window obeying
$ \sum_{k_1,k_2} w^2(x_1-k_1 , x_2 -k_2 ) = 1$,
we dilate and transport $w$ to all squares $Q$ at scale $s$,
producing a collection of windows $(w_Q)$ such that the
$w_Q^2$'s, $Q \in {\cal Q}_s$, make up a partition of unity.
We also let $T_Q$
denote the transport operator acting on
functions $g$ via
\[
(T_Q g)(x_1,x_2) = 2^s g(2^s x_1 - k_1,2^s x_2 - k_2).
\]
With this notation, it is not hard to see that
\[
f w_Q = \int \<f, w_Q T_Q {\psi}_{a,b,\theta} \>
     T_Q {\psi}_{a,b,\theta} \frac{da}{a^3} db
\frac{d\theta}{4\pi}
\]
and, therefore,
summing the above equality across squares at a given scale gives
\begin{equation}
      \label{eq:MRT}
f = \sum_{Q \in {\cal Q}_s} f w_Q^2 = \sum_Q \int \<f, w_Q T_Q
{\psi}_{a,b,\theta} \> w_Q T_Q {\psi}_{a,b,\theta} \frac{da}{a^3} db
\frac{d\theta}{4\pi}.
\end{equation}
The identity (\ref{eq:MRT}) expresses the fact that one can represent
any function as a superposition of elements of the form $w_Q T_Q
{\psi}_{a,b,\theta}$; that is, of ridgelet elements localized near the
squares $Q$. Associated with the 
function $T_Q {\psi}_{a,b,\theta}$ is the ridgelet
$\psi_{a_Q,\theta_Q,b_Q}$ (\ref{eq:ridgelet}) with parameters obeying
\[
a_Q = 2^{-s} a, \quad \quad \theta_Q = \theta, \quad \quad b_Q = b +
k_1 2^{-s} \cos\theta + k_2 2^{-s}\sin\theta
\]
and thus $w_Q T_Q {\psi}_{a,b,\theta}$ is a windowed ridgelet,
supported near the square $Q$, hence the name {\em local ridgelet
      transform}.

The previous paragraph discussed the construction of local ridgelets
of fixed length, roughly $2^{-s}$ ($s$ fixed). Letting the scale $s$
vary defines the multiscale ridgelet dictionary
$\{\psi^Q_{a,b,\theta}: s \ge s_0, Q \in {\cal Q}_s, a > 0, b \in \bR,
\theta \in [0,2\pi)\}$ by
\[
\psi^Q_{a,b,\theta} = w_Q \, T_Q \psi_{a,b,\theta};
\]
that is, a whole pyramid of local ridgelets at various lengths and
locations. This is, of course, a massively overcomplete representation
system and no formula like (\ref{eq:MRT}) is available for this
multiscale ridgelet pyramid, because it is highly overcomplete.
 
\section{Digital Ridgelet Transform}
So the basic strategy for calculating the
continuous ridgelet transform is first to compute the Radon transform
$Rf(t,\theta)$ and second, to apply a one-dimensional wavelet
transform to the slices $Rf(\cdot,\theta)$.  

Several digital ridgelet transforms have been proposed, and we will described
three of them in this section, based on different implementations of the
Radon transform.

\subsection{The RectoPolar Ridgelet transform}
In this section 
we develop a digital procedure which is inspired by this viewpoint,
and is realizable on $n$ by $n$ numerical arrays.

 A fundamental fact about the Radon transform is the
projection-slice formula \cite{Deans}:
\[
\hat{f}(\lambda \cos\theta, \lambda \sin\theta) = \int Rf(t,\theta)
e^{-i\lambda t} dt.
\]
This says that the Radon transform can be obtained by applying the
one-dimensional inverse Fourier transform to the two-dimensional
Fourier transform restricted to radial lines going through the origin.

This of course suggests that approximate Radon transforms
for digital data can be based on discrete fast Fourier
transforms. This is a widely used approach,
in the literature of medical imaging and
synthetic aperture radar imaging, for which the
key approximation errors and artifacts have been widely discussed.
In outline, one
simply does the following, for
gridded data $(f(i_1,i_2))$, $0 \le i_1, i_2 < n-1$.
\begin{enumerate}
\item {\em 2D-FFT}. Compute the two-dimensional FFT of $f$ giving the
      array $(\hat{f}(k_1,k_2))$, $ -n/2 \le k_1, k_2 \le n/2 - 1$.
\item {\em Cartesian to Polar Conversion}. Using an interpolation
      scheme, substitute the sampled values of the Fourier transform
      obtained on the square lattice with sampled values of $\hat{f}$ on a
polar
      lattice: that is, on a lattice where the points fall on lines going
      through the origin.
\item {\em 1D-IFFT}. Compute the one-dimensional IFFT (inverse FFT)
     on each line,
      i.e.\ for each value of the angular parameter.
\end{enumerate}

The use of this strategy in connection with ridgelet transforms has
been discussed in the articles \cite{DRT,FRT,starck:sta01_3}.

\subsubsection{A Polar Sampling Scheme for Digital Data}

For our implementation of the Cartesian-to-polar
conversion, we have used a pseudo-polar
grid, in which the pseudo-radial variable has level sets which are squares
rather than circles. Starting with Oppenheim and Mersereau
\cite{MERSEREAU} this grid has often been called the {\it concentric
squares} grid in the signal processing literature; in the medical
tomography literature it is associated with the {\it linogram}
\cite{cur:edholm87,cur:edholm88}, while
in \cite{cur:averbuch01} it is called the rectopolar grid; see this  last
reference for a complete bibliographic treatment.  The geometry of the
rectopolar  grid is illustrated in Figure \ref{fig_radon}. We select $2
n$ radial lines in the frequency plane obtained by connecting the
origin to the vertices
$(k_1,k_2)$ lying on the boundary of the array $(k_1, k_2)$ , i.e. such
that $k_1$ or $k_2 \in \{-n/2, n/2\}$. The polar grid
$\xi_{\ell,m}$ ($\ell$ serves to index a given radial line while the
position of the point on that line is indexed by $m$) that we shall use
is the intersection between the set of radial lines and that of
Cartesian lines parallel to the axes.  To be more specific, the sample
points along a radial line ${\cal L}$ whose angle with the vertical
axis is less than or equal to $\pi/4$ are obtained by intersecting ${\cal
      L}$ with the set of horizontal lines $\{x_2 = k_2, \, k_2 = -n/2,
-n/2 + 1, \ldots, n/2\}$.  Similarly, the intersection with the
vertical lines $\{x_1 = k_1, \, k_1 = -n/2, -n/2 + 1, \ldots, n/2\}$
defines our sample points whenever the angle between ${\cal L}$ and the
horizontal axis is less than or equal to $\pi/4$.  The cardinality of the
rectopolar grid is equal to $2 n^2$ as there are $2 n$ radial lines and
$n$ sampled values on each of these lines. As a result,  data
structures associated with this grid will have a rectangular format. We
observe that this choice corresponds to irregularly spaced values of
the angular variable $\theta$.

\begin{figure}[htb]
\centerline{
\hbox{\psfig{figure=polar.eps,height=8cm,width=10cm,clip=}}
}
\caption{Illustration of the digital polar grid in the frequency domain for
          an $n$ by $n$ image $(n=8)$. The figure displays the set of
          radial lines joining pairs of symmetric points from the boundary
          of the square. The rectopolar grid is the set of points -- marked with
          circles -- at the intersection between those radial lines and
          those which are parallel to the axes.}
\label{fig_radon}
\end{figure}


\subsubsection{Interpolation to Rectopolar Grid}

To obtain samples on the rectopolar grid,
we should, in general, interpolate from
nearby samples at the Cartesian grid.
In principle, cf.\
\cite{cur:averbuch01,cur:donoho_02}, 
the interpolation of Fourier transforms is a
very delicate matter because of the well-known fact that
the Fourier transform of an image is highly oscillatory,
and the phase contains crucial information about the image.
In our approach, however, we use a crude interpolation method:
we simply impute for
$\hat{f}(\xi_{\ell,m})$ the value of the Fourier transform taken at
the point on the Cartesian grid nearest to
$\xi_{\ell,m}$.

There are, of course, more sophisticated ways to realize the
Cartesian-to-polar conversion; even simple bilinear interpolation
would offer better theoretical accuracy. A very high accuracy
approach used in \cite{FRT} consists of viewing the data
$(\hat{f}(k_1,k_2))$ as
samples of the trigonometric polynomial $F$ defined by

\begin{equation}
\label{eq:2d-poly}
F(\omega_1,\omega_2) = \sum_{i_1 = 0}^{n-1}  \sum_{i_2 =0}^{n-1}
    f(i_1,i_2) \exp\{-i(\omega_1 i_1 + \omega_2 i_2)\}
\end{equation}
on a square lattice; that is, with $\hat{f}(k_1,k_2) = F(\frac{2\pi
      k_1}{n},\frac{2\pi k_2}{n})$ with $ -n/2 \le k_1, k_2 < n/2$.
There turns out \cite{FRT,cur:averbuch01} to be an exact algorithm for
rapidly
finding the values of $F$ on the polar grid. The high-accuracy
approach can be used in reverse, allowing for exact reconstruction
of the original trigonometric polynomial from its rectopolar samples.

Our nearest-neighbor interpolation, although admittedly simple-minded,
happens to give  good results in our applications.
In fact numerical experiments show that in overall system
performance, it rivals the exact interpolation scheme.
This is explainable as follows.  Roughly speaking, the high-frequency
terms in the
trigonometric polynomial $F$ are associated with pixels at the boundary of
the underlying $n$ by $n$ grid.  Our crude interpolation evidently will
fail at reconstructing high-frequency terms. However, in the curvelet
application -- see below -- we use a window function to downweight
the contributions of our reconstruction near the boundary of the image
array.
So, inaccuracies in
reconstruction caused by our crude interpolation can be expected to
be located mostly in regions which make little visual
impact on the reconstruction.

A final point about our implementation. Since we are
interested in noise removal, avoiding 
artifacts is very important.  At the  signal-to-noise ratios we
consider, high-order-accuracy interpolation formulas which  generate
substantial artifacts  (as many high-order formulas do) can be less
useful than  low-order-accuracy schemes which are relatively
artifact-free. A known artifact of exact interpolation of trigonometric
polynomials is as follows: substantial long-range disturbances can be
generated by local perturbations such as discontinuities. In this
sense, our crude interpolation may actually turn out to be preferable
for some purposes.

\subsubsection{Exact Reconstruction and Stability}

The Cartesian-to-rectopolar conversion we have suggested here
is reversible. That is to say, given the rectopolar values output from
this method, one can recover the original Cartesian values exactly.
To see this, take as given the following: {\it {\bf Claim:} the assignment
of Cartesian points as nearest neighbors of rectopolar points happens
in such a way that   each Cartesian point is assigned as the nearest
neighbor of at least one rectopolar point.}  It follows from this claim
that each value in the original Cartesian input array is copied into at
least one place in the output rectopolar array. Hence, perfect
reconstruction is obviously possible in principle -- just by keeping track
of where the entries are, have been copied to, and undoing the process.

Our reconstruction rule obtains, for each point on the Cartesian grid,
the {\it arithmetic mean of all the values in the rectopolar grid
  which have that Cartesian point as their nearest point}. This
provides a numerically stable left inverse.  Indeed, if applied to a
perturbed set of rectopolar values, this rule gives an approximate
reconstruction of the original unperturbed Cartesian values in which
the approximation errors are smaller than the size of the
perturbations suffered by the rectopolar values. (This final comment
is reassuring in the present de-noising context, where our
reconstructions will always be made by perturbing the empirical
rectopolar FT of the noisy data.) Phrased in mathematical terms
this gives
\[
x_C = 1/\# R(C) \sum_{R \in R(C)} y_R, 
\]
where $C$ is a given point on the Cartesian grid and $R(C)$ is the set
of rectopolar points that are closest to $C$. Cardinality is denoted
$\#$. Stability in $\ell_2$,
for instance, follows from the observation
\[
|x_C|^2 \le 1/\# R(C) \sum_{R \in R(C)} |y_R|^2 
\le \sum_{R \in R(C)} |y_R|^2; 
\]
Since we have a partition of the set of rectopolar points,
summing this last inequality across the Cartesian grid gives $\|x\|^2
\le \|y\|^2$.

It remains to explain the italicized claim, because, as we have seen,
from it flows the exact reconstruction property and stability of the
inverse. Consider the rectopolar points in the hourglass region made of
`basically vertical lines', i.e. lines which make an angle
less than $\pi/4$ with vertical, and more specifically those
points on a single horizontal scan line. Assuming the scan line
is not at the extreme top or bottom of the array, these points are spaced {\it
strictly less than one unit apart}, where our unit is the spacing of 
the Cartesian
grid. Therefore, when we consider a Cartesian grid point $C$ belonging to this
scan line and ask about the rectopolar points $R_L$ and $R_R$ which 
are closest to
it on the left and right respectively, these two points cannot be as much as 1
unit apart:
$|| R_L - R_R || < 1$. Therefore at least one of the two points must be
strictly less than 1/2 unit away from the Cartesian point: i.e. either
$|| R_L - C || < 1/2$ or $|| R_R - C || < 1/2$. Without loss of
generality suppose that $|| R_L - C || < 1/2$. Then clearly $R_L$ has
$C$ as its closest Cartesian point. In short, every Cartesian point in
the strict interior of the `hourglass' associated with the `basically
vertical' lines arises as the strict closest Cartesian point of at
least one rectopolar point. Similar statements can be made about points
on the boundary of the hourglass, although the arguments supporting
those statements are much simpler, essentially mere inspection. Similar
statements can be made about the points in the transposed hourglass.
The italicized claim is established.


\subsubsection{One-dimensional Wavelet Transform}

To complete the ridgelet transform, we must take
a one-dimensional wavelet transform along the
radial variable in Radon space. We now discuss the choice of
digital one-dimensional wavelet transform.

Experience has shown that compactly-supported wavelets can lead to many
visual artifacts when  used in conjunction with nonlinear processing --
such as hard-thresholding of individual wavelet coefficients --
particularly for decimated wavelet schemes used at critical sampling.
Also, because of the lack of localization of such compactly-supported
wavelets in the frequency domain, fluctuations in coarse-scale wavelet
coefficients can introduce fine-scale fluctuations; this is
undesirable in our setting. Here we take a frequency-domain approach,
where the discrete Fourier transform is reconstructed from the inverse
Radon transform. These considerations lead us to use a band-limited
wavelet, whose support is compact in the Fourier domain rather than
the time domain. Other implementations have made a choice of compact
support in the frequency domain as well \cite{DRT,FRT}. However, we
have chosen a specific overcomplete system, based on work of Starck et
al. \cite{starck:sta94_3,starck:book98}, who constructed such  a
wavelet transform and applied it to interferometric image
reconstruction. The wavelet transform algorithm is based on a scaling
function $\phi$ such that $\hat{\phi}$ vanishes outside of the interval
$[-\nu_c, \nu_c]$.  We defined the scaling function
$\hat{\phi}$ as a renormalized $B_3$-spline
\[
\hat{\phi}(\nu)= {3\over 2} B_3(4\nu),
\]
and $\hat{\psi}$ as the difference between two consecutive resolutions
\[
\hat \psi(2\nu) = \hat \phi(\nu) - \hat \phi(2\nu).
\]
Because $\hat{\psi}$ is compactly supported, the sampling theorem
shows than one can easily build a pyramid of $n + n/2 + \ldots + 1 =
2n$ elements: see \cite{starck:book98} for details.

This transform enjoys the following features:
\begin{itemize}
\item The wavelet coefficients are directly calculated in the Fourier
      space. In the context of the ridgelet transform, this allows
      avoiding the computation of the one-dimensional inverse Fourier
      transform along each radial line.
\item Each subband is sampled above the Nyquist rate, hence
      avoiding aliasing -- a phenomenon typically encountered by critically
      sampled orthogonal wavelet transforms \cite{Steerable}.
\item The reconstruction is trivial. The wavelet coefficients simply
      need to be co-added to reconstruct the input signal at any given
      point. In our application, this implies that the ridgelet
coefficients
      simply need to be co-added to reconstruct Fourier coefficients.
\end{itemize}

This wavelet transform introduces an extra redundancy factor, which
might be viewed as an objection by advocates of orthogonality
and critical sampling. However,
we note that our goal in this implementation is not data
compression/efficient
coding -- for which critical sampling might be relevant -- but
instead
noise removal, for which it is well-known that overcompleteness
can provide substantial advantages
\cite{rest:donoho95}.

\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=fig_rid.ps,bbllx=4.5cm,bblly=5cm,bburx=21cm,bbury=22cm,width=10cm,height=10cm,clip=}
}}
\caption{Ridgelet transform flowgraph. Each of the $2n$  radial lines
      in the Fourier domain is processed separately. The 1D inverse FFT
      is calculated along each radial line followed by a 1D nonorthogonal
      wavelet transform.  In practice, the one-dimensional wavelet
      coefficients are directly calculated in the Fourier space. }
\label{fig_ridgelet}
\end{figure}

\subsubsection{Combining the Pieces}

Figure~\ref{fig_ridgelet} shows the flowgraph of the ridgelet
transform.  The ridgelet transform of an image of size $n \times n$ is
an image of size $2n \times 2n$, introducing a redundancy factor
equal to 4.

We note that, because our transform is made up of a chain
of steps, each one of which is invertible, the whole
transform is invertible, and so has the
exact reconstruction property. For the same
reason, the reconstruction
is stable under perturbations of the coefficients.

Last but not least, our discrete transform is computationally
attractive. Indeed, the algorithm we presented here has low complexity
since it runs in $O(n^2\log(n))$ flops for an $n \times n$ image.

\subsection{The Orthonormal Finite Ridgelet Transform}
The orthonormal finite ridgelet transform (OFRT)  has been 
recently proposed  
\cite{cur:do00,cur:do00b} for image compression and filtering. 
The transform, based on the finite Radon transform \cite{cur:matus93} and
a 1D orthogonal wavelet transform, is not redundant, and reversible.
It would be a great alternative to the previously described ridgelet transform
if the OFRT were not based on a strange definition 
of a line. In fact, a line in the OFRT is defined as 
a set of periodic equidistant points \cite{cur:matus93}. 
Figure~\ref{fig_cmp_backproj} shows the backprojection of a ridgelet 
coefficient by the FFT-based ridgelet transform (left) and by the 
 OFRT (right). It is clear that the backprojection
of the  OFRT is nothing like a ridge function.

\begin{figure}[htb]
\centerline{
\vbox{
\hbox{
\psfig{figure=fig_backproj_ridfft.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.cm,height=7.cm,clip=}
\psfig{figure=fig_backproj_fird.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.cm,height=7.cm,clip=}
}}}
\caption{Left, backprojection of a ridgelet coefficient by the 
FFT-based ridgelet transform,
and right, backprojection of a finite ridgelet coefficient.}
\label{fig_cmp_backproj}
\end{figure}

\begin{figure}[htb]
\centerline{
\vbox{
\hbox{
\psfig{figure=fig_l257.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.cm,height=7.cm,clip=}
\psfig{figure=fig_ridl257.ps,bbllx=2cm,bblly=13.5cm,bburx=13cm,bbury=24.5cm,width=7.cm,height=7.cm,clip=}
}}}
\caption{Left, part of Lena image,
and right, reconstruction after finite ridgelet coefficient thresholding.}
\label{fig_cmp_recl257}
\end{figure}

Because of this specific definition of a line, the thresholding of the OFRT
coefficients produces strong artifacts. 
Figure~\ref{fig_cmp_recl257} left shows a part 
of the original standard Lena image, and 
Figure~\ref{fig_cmp_recl257} right shows the reconstruction after the 
hard thresholding of the OFRT. A kind of noise has been added to the 
noise-free image!
Finally, the OFRT presents another limitation: the image size  
must be a prime number. This last point is however not too restrictive, 
because we generally use a partitioning when denoising the data, and a
prime number block size can be used. 
The OFTR is interesting from the conceptual point of view, but will
certainly be of no help for real applications.  

\subsection{The Slant Stack Ridgelet Transform}

\begin{figure}[htb]

\centerline{
\vbox{
\hbox{
\psfig{figure=fig_back_ssrad.ps,bbllx=8.8cm,bblly=13.7cm,bburx=12.1cm,bbury=16.cm,width=3cm,height=3cm,clip=}
\psfig{figure=fig_back_ssrad1.ps,bbllx=8.8cm,bblly=13.7cm,bburx=12.1cm,bbury=16.cm,width=3cm,height=3cm,clip=}
}
\hbox{
\psfig{figure=fig_back_ssrad2.ps,bbllx=8.8cm,bblly=13.7cm,bburx=12.1cm,bbury=16.cm,width=3cm,height=3cm,clip=}
\psfig{figure=fig_back_ssrad3.ps,bbllx=8.8cm,bblly=13.7cm,bburx=12.1cm,bbury=16.cm,width=3cm,height=3cm,clip=}
}}}
\caption{Backproject of a point at four different locations in the 
Radon space.}
\label{fig_back_stack_radon}
\end{figure}

The Fast Slant Stack \cite{cur:averbuch01}
 is geometrically more accurate than the 
previously decribed methods. The backprojection of a point 
in Radon space is exactly a ridge function in the spatial domain
(see Figure~\ref{fig_back_stack_radon}).
The transformation of an $n \times n$ image is a $2n \times 2n$ image.
$n$ line integrals with angle between $[-\frac{\pi}{4}, \frac{\pi}{4}]$
are calculated from the zero padded image on the y-axis, 
and $n$ line integrals with angle between $[\frac{\pi}{4}, \frac{3\pi}{4}]$
are computed by zero padding the image on the x-axis. 
For a given angle inside $[-\frac{\pi}{4}, \frac{\pi}{4}]$,
$2n$ line integrals are calculated by first shearing the zero-padded image, 
and then integrating the pixel values 
along all horizontal lines (resp.\ vertical lines
for angles in $[\frac{\pi}{4}, \frac{3\pi}{4}]$). The shearing is 
performed column per column (resp.\ line per line) by using the 1D FFT.
Figure~\ref{fig_stack_radon} shows an example of the image shearing step
with two different angles ($5\frac{\pi}{4}$  and $-\frac{\pi}{4}$).
A ridgelet transform based on the Fast Slant Stack transform has been
proposed in \cite{cur:donoho_02}. The connection between the Fast Slant Stack
and the linogram has been investigated in \cite{cur:averbuch01}, and
a Fast Slant Stack is proposed, based on the 2D Fourier transform.

\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=fig_slant_radon.ps,bbllx=3cm,bblly=9cm,bburx=18cm,bbury=21.cm,width=15cm,height=12cm,clip=}
}}
\caption{Slant Stack Transform of an image.}
\label{fig_stack_radon}
\end{figure}

\section{Local Ridgelet Transforms}

A digital version of the ideas presented in section \ref{sec:pyramid}
decomposes the original $n$ by $n$ image into smoothly overlapping
blocks of sidelength $b$ pixels in such a way that the overlap between
two vertically adjacent blocks is a rectangular array of size $b$ by
$b/2$; we use overlap to avoid blocking artifacts. For an $n$ by $n$
image, we count $2n/b$ such blocks in each direction.

The partitioning introduces redundancy, as a pixel belongs to 4
neighboring blocks. We present two competing strategies to perform the
analysis and synthesis:
\begin{enumerate}
\item The block values are weighted (analysis) in such a way that the
      co-addition of all blocks reproduce exactly the original pixel value
      (synthesis).
\item The block values are those of the image pixel values (analysis)
      but are weighted when the image is reconstructed (synthesis).
\end{enumerate}
Of course, there are intermediate strategies and one could apply
smooth windowing at both the analysis and synthesis stages as discussed
in Section \ref{sec:pyramid}, for example. In the first approach, the
data are smoothly windowed and this presents the advantage to limit
the analysis artifacts traditionally associated with boundaries.  The
drawback, however, is a loss of sensitivity. Indeed, suppose for the
sake of simplicity that a vertical line with intensity level $L$
intersects a given block of size $b$. Without loss of generality
assume that the noise standard deviation is equal to 1. When the
angular parameter of the Radon transform coincides with that of the
line,
we obtain a measurement with a signal intensity equal to $b L$ while
the noise standard deviation is equal to $\sqrt{b}$ (in this case, the
value of the signal-to-noise ratio (SNR) is $\sqrt{b} L$). If weights
are applied at the analysis stage, the SNR is roughly equal to $L \,
\sum_{i=1}^b w_i/\sqrt{\sum_{i=1}^b w_i^2} < \sqrt{b} L$. Experiments
have shown that this sensitivity loss may have substantial effects
in filtering applications and, therefore, the second approach
seems more appropriate since our goal is image restoration.

We calculate a pixel value $f(i,j)$ from its four corresponding block
values of half-size $\ell = b/2$, namely, $B_1(i_1,j_1)$,
$B_2(i_2,j_1)$, $B_3(i_1,j_2)$ and $B_4(i_2,j_2)$ with $i_1, j_1 >
b/2$ and $i_2 = i_1 - \ell, j_2 = j_1- \ell$, in the following way:
\begin{eqnarray}
      f_1 &  = &  w(i_2/\ell) B_1(i_1,j_1) + w(1-i_2/\ell)
B_2(i_2,j_1)\nonumber \\
      f_2 &  = &  w(i_2/\ell) B_3(i_1,j_2) + w(1-i_2/\ell)
B_4(i_2,j_2)\nonumber \\
      f(i,j) &  = &  w(j_2/\ell) f_1 +  w(1-j_2/\ell) f_2
\end{eqnarray}
with $w(x) = \cos^2(\pi x/2)$.  Of course, one might select any other
smooth, non-increasing function satisfying $w(0) = 1$, $w(1) = 0$,
$w'(0) = 0$ and obeying the symmetry property $w(x) + w(1-x) = 1$.

It is worth mentioning that the spatial partitioning introduces a
redundancy factor equal to 4.

Finally, we note that in order to be in better agreement with the
theory one should of course introduce a normalizing factor depending
on the block-size. However, since we are concerned about de-noising
and the thresholding of individual coefficients, the normalization is
a non-issue.  Renormalizing coefficients automatically renormalizes
corresponding thresholds in the exact same way: see section 
\ref{sec:filtering}.


\section{Digital Curvelet Transform}
\label{sec:curvelet}

\subsection{Discrete Curvelet Transform of Continuum Functions}

We now briefly return to the continuum viewpoint of section
\ref{sec:pyramid}.
Suppose we set an initial goal to produce a decomposition using the
multiscale ridgelet pyramid. The hope is that this
would allow us to use thin `brushstrokes' to reconstruct
the image, with all lengths and widths available to us.
In particular, this would seem allow us to trace sharp edges precisely
using a few elongated elements with very narrow widths.

As mentioned in section \ref{sec:pyramid},
the full multiscale ridgelet pyramid is highly overcomplete.
As a consequence,  convenient algorithms like
simple thresholding will not find sparse
decompositions when such good decompositions exist.
An important ingredient of the curvelet
transform is to restore sparsity by reducing redundancy across scales.
In
detail, one introduces interscale orthogonality by means of
subband filtering. Roughly speaking, different levels of the
multiscale ridgelet pyramid are used to represent different
subbands of a filter bank output.  At the same time, this subband
decomposition imposes a relationship between the width and length
of the important frame elements so that they are anisotropic and obey
$width = length^2$.

The discrete curvelet transform of a continuum
function $f(x_1,x_2)$ makes use of a dyadic sequence of scales,
and a bank of filters $(P_0 f, \Delta_1 f ,
\Delta_2 f , \dots )$ with the property that the passband filter
$\Delta_s$ is concentrated near the frequencies $[2^{2s}, 2^{2s+2}]$,
e.g.
\[
\Delta_s = \Psi_{2s} * f, \quad \widehat{\Psi_{2s}}(\xi) =
\widehat{\Psi}(2^{-2s}\xi).
\]
In wavelet theory, one uses a decomposition into dyadic subbands
$[2^s, 2^{s+1}]$. In contrast, the subbands used
in the discrete curvelet transform of continuum functions have
the non-standard form
$[2^{2s}, 2^{2s+2}]$. This is a non-standard feature of the
discrete curvelet transform well worth remembering.

With the notation of section \ref{sec:pyramid}, the curvelet
decomposition is the sequence of the following steps:
\begin{itemize}
     \item {\it Subband Decomposition.}  The object $f$ is
     decomposed into subbands:
     \[
       f \mapsto (P_0 f, \Delta_1 f , \Delta_2 f , \dots ) .
     \]
\item {\it Smooth Partitioning.} Each subband is smoo\-thly win\-do\-wed
      into ``squares'' of an appropriate scale (of sidelength $\sim
      2^{-s}$):
     \[
        \Delta_s f \mapsto ( w_Q    \Delta_s f )_{Q \in {\cal Q}_s} .
     \]
     \item {\it Renormalization.} Each resulting square is renormalized to
unit scale
     \begin{equation}
      \label{eq:gQ}
        g_Q =  (T_Q)^{-1}(w_Q \Delta_s f ),  \qquad {Q \in {\cal Q}_s} .
     \end{equation}
\item {\it Ridgelet Analysis.} Each square is analyzed via the
      discrete ridgelet transform.
\end{itemize}

In this definition, the two dyadic subbands $[2^{2s}, 2^{2s+1}]$ and
$[2^{2s+1}, 2^{2s+2}]$ are merged before applying the ridgelet
transform.
\subsection{Digital Realization}

In developing a transform for digital $n$ by $n$ data
which is analogous to the discrete curvelet transform of a
continuous function $f(x_1,x_2)$,
we replace each of the continuum concepts
with the appropriate digital concept mentioned in the sections above.
In general, the translation is rather obvious and direct. However,
experience shows that one modification is essential;
we found that, rather than merging the two
dyadic subbands $[2^{2s}, 2^{2s+1}]$ and
$[2^{2s+1}, 2^{2s+2}]$ as in the theoretical work,
in the digital application, leaving these subbands separate,
applying spatial partitioning to each subband
and applying the ridgelet transform on
each subband separately led to improved visual and numerical results.

We believe that the ``\`a trous'' subband filtering algorithm is
especially
well-adapted to the needs of the digital curvelet transform.
The algorithm decomposes an $n$ by $n$ image $I$ as a superposition of
the form
\[
I(x,y) = c_{J}(x,y) + \sum_{j=1}^{J} w_j(x,y),
\]
where $c_{J}$ is a coarse or smooth version of the original image $I$
and $w_j$ represents ``the details of $I$'' at scale $2^{-j}$: see
\cite{starck:book98} for more information. Thus, the algorithm outputs
$J+1$ subband arrays of size $n \times n$. (The indexing is such that,
here, $j = 1$ corresponds to the finest scale, or high frequencies.)

\begin{figure}[htb]
\centerline{
\hbox{\psfig{figure=fig_cur.ps,width=8cm,height=10cm,clip=}}
}
\caption{Curvelet transform flowgraph. The figure illustrates
the decomposition of the original image  into subbands followed by
the spatial partitioning of each subband. The ridgelet transform
is then applied to each block.}
\label{fig_curvelet}
\end{figure}

\subsection{Algorithm}
We now present a sketch of the discrete curvelet transform algorithm:
\begin{enumerate}
\item Apply the \`a trous algorithm with $J$ scales,
\item set $B_1 = B_{min}$,
\item for $j = 1, \ldots, J$ do,
\begin{enumerate}
\item partition the subband $w_j$ with a block size $B_j$ and apply the
digital ridgelet transform to each block,
\item if $j \mbox{ modulo } 2 = 1$ then $B_{j+1} = 2B_{j}$,
\item else $B_{j+1} = B_{j}$.
\end{enumerate}
\end{enumerate}
The sidelength of the localizing windows is doubled {\em at every
      other} dyadic subband, hence maintaining the fundamental property of
the curvelet transform which says that elements of length about
$2^{-j/2}$ serve for the analysis and synthesis of the $j$-th subband
$[2^j, 2^{j+1}]$.  Note also that the coarse description of the image
$c_J$ is not processed. Figure~\ref{fig_curvelet}
gives an overview of the organization of the algorithm.


This implementation of the curvelet transform is also redundant. The
redundancy factor is equal to $16J+1$ whenever $J$ scales are employed.
Finally, the method enjoys exact reconstruction and stability,
because this invertibility holds for each element of the
processing chain.

\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=fig_sparse_s1.ps,bbllx=4cm,bblly=7cm,bburx=17cm,bbury=21cm,width=6.5cm,height=7cm,clip=}
\psfig{figure=fig_sparse_s2.ps,bbllx=4cm,bblly=7cm,bburx=17cm,bbury=21cm,width=6.5cm,height=7cm,clip=}
}}
\caption{A few curvelets.}
\label{fig_ex_curve}
\end{figure}
Figure~\ref{fig_ex_curve} shows a few curvelets at different scales,
orientations and locations.  
 



