\chapter{ISOCAM dedicated software}
\label{ch_iso}
% \chapterhead{ISOCAM dedicated software}
\markright{ISOCAM dedicated software}

The ISOCAM infrared camera is one of the four instruments on board the ISO 
(Infrared Space Observatory) spacecraft which was launched successfully
on 1995 November 17. It operates in the 2.5-17 micron range, and was 
developed by the ISOCAM consortium lead by the French Service d'Astrophysique of 
CEA Saclay.  
Some software have been developed using the \proj package.

For one observation, the ISOCAM instrument delivers a set of frame pairs (start of 
integration {\em Reset} and end of integration (EOI)). For the 
long wavelength detector (LW), the signal corresponds  to a simple difference 
between EOI and Reset. For the short wavelength detector (SW), it is more complex, 
and several operations such as  ``cross
talk correction'' must be done. We assume that these corrections have been
applied for the data we are considering here. Then we have a set of data  noted 
$D(x,y,t,c)$: we
have one measurement per pixel position $(x,y)$ in the detector, which is repeated 
$t$ times,
and we have $c$ configurations (there is a new configuration each time the 
pointing position,
the filter, the integration time, ..., were changed).

Then, in the ideal case, calibration will consist of \cite{starck:sta98_4}
\begin{itemize}
\item normalizing the data to ADU/g.s by 
\[ D_1(x,y,t,c) = \frac{D_0(x,y,t,c)}{gain*tint*Naccu} \]
where $gain$ is the electronic gain, $tint$ is the integration time, $Naccu$ is 
the number of
frames already added  by the on-board processing ($Naccu$ is greater than one only 
in the accumulation mode, normally confined to the $0.28$ seconds readouts 
($Naccu=4$), 
or the CAM parallel mode $Naccu=12$)). 
\item subtract the DARK current  
\[ D_2(x,y,t,c) = D_1(x,y,t,c) - dark(x,y) \]
The corresponding dark is extracted from the calibration library.
\item divide by the optical and the detector flats
\[ D_3(x,y,t,c) = \frac{D_2(x,y,t,c)}{oflat(x,y)dflat(x,y)} \]
The corresponding optical and detector flats are extracted from the calibration 
library.
\item average the values corresponding to the same sky position and the same 
configuration
\[ Image(x,y,c) = mean(D_3(x,y,1..t,c)) \]
\[ RMS(x,y,c) =  sigma(D_3(x,y,1..t,c)) \]
\item in case of a raster observation, reconstruct the final raster map 
$Raster(x,y)$ from all images $Image(x,y,c)$.
\end{itemize}

But in practice, we have to take into account several problems:
\begin{itemize}
\item since the dark exhibits variation from one orbit to another, library 
darks which are done on specific orbits do not always be applicable to 
the data, specifically at low flux. 
\item calibration flat field are done with an internal source, which
creates flats different from those coming through the telescope.
\item cosmic rays hit the detector.
\item the detector exhibits a transient behavior. Every time a detector pixel is 
illuminated successively by a source and 
the background, as the detector is scanning the sky, the transition between the 
two flux levels is not instantaneous.  
\item spacecraft jitter.
\item field of view distortion: the resolution of each pixel depends on its 
position in the detector.
\item no signal is read from column 24.
\end{itemize}
Studies have been done in order to resolve all these problems, and 
some solutions have been proposed. 

\section{Cosmic ray impact suppression}
As the glitch structures can have different sizes, we need a multiresolution
tool in order to make an efficient automatic detection. The idea developed here is the following: as we observe 
the same position in the sky during $n$ exposures, we cannot have any structure in our signal 
which has a temporal size lower than $n*tint$ ($tint$ being the exposure time 
of a single frame). It means that all the 
significant structures (i.e. not due to the noise) at small scales
are due to the glitches.
The method consists in doing for each pixel $(x,y)$ the following steps
\begin{enumerate}
\item set $v(t) = C(x,y,t)$
\item estimate the temporal noise $\sigma_t$ in $v(t)$
\item calculate the multiresolution median transform  $T$ of $v(t)$: we get $T(j, t)$ where $j$ is the 
temporal scale. The number of scales in the transform is fixed by the
number of frames per satellite position.
\item derive from $\sigma_t$ the standard deviation $\sigma_j$ at each scale $j$.
\item at all scales, set to zero all structure higher a given level.
\begin{eqnarray}
\mbox{ if } abs(T(j, t)) > k \sigma_j \mbox{ then } T(j, t) = 0
\end{eqnarray}
$k$ is generally taken equal to 3.
\end{enumerate}
The method is robust and works for non stabilized data. The only real limitation is that we 
cannot detect glitches which are longer than or equal to $n*tint$. That
means that more we have frames per camera configuration, better will be the deglitch. 

\begin{center}
 USAGE: mr1d\_deglitch option cube\_in cube\_out
\end{center}
where options are:
\begin{itemize}
\item {\bf [-n number\_of\_scales]} \\
number of scales used in the multiresolution transform. Default is 3.
\item {\bf [-s Nsigma]} \\
\item {\bf [-f]} \\
Suppress the noise, but not the glitches.
\end{itemize}

\begin{figure}[htb]
\centerline{
\vbox{
\psfig{figure=fig_deglitch2.ps,bbllx=2.5cm,bblly=13cm,bburx=19.5cm,bbury=25.5cm,width=17cm,height=12.5cm}
}}
\caption{Original data (top), deglitched data (middle), and both overplotted 
(bottom).}
\label{fig_deglitch2}
\end{figure}

Figure \ref{fig_deglitch2} shows the results after
a such treatment. Figure \ref{fig_deglitch2} (top) shows the values 
taken by a pixel of the camera as time elapses. The x-axis represents the frame 
number (time / integration time), and the y-axis gives the ADU per second. These
data were collected during a raster observation, and the satellite stayed at the 
same 
position during around 20 frames, and the integration time was equal 2.1 second. A 
source is at the limit of detection  (frames 130 to 150). All peaks 
are due to cosmic ray impacts. The intensity of a cosmic ray can take all
values between a few ADUs to more than one thousand ADUs. Figure 
\ref{fig_deglitch2} 
(middle) shows the same data after the glitch suppression.
The third plot (Figure \ref{fig_deglitch2} (bottom)) shows both data and 
deglitched data overplotted.
 We see that the noise
and the signal are not modified during this operation. 

The method is robust and works for non stabilized data. The only real limitation 
is that we 
cannot detect glitches which are longer than or equal to $n*tint$. That
means that the more frames we have per camera configuration, the 
better will be the deglitching. 

\subsection*{IDL routine}
{\em mr1d\_deglitch} IDL routine eliminates glitches in 
a cube $D$ calling the previous program. Each vector $D(s,y,*)$
at position $(x,y)$ is treated individually. 
\begin{center}
     USAGE: mr1d\_deglitch, Cube, filter=filter, Nscale=Nscale, Nsigma=Nsigma, mask=mask
\end{center}
where 
\begin{itemize}
\item {\em Cube}: 3D IDL array (input-ouput parameter). Cube to deglitch.
\item {\em Nscale}: number of scale for the multiresolution analysis.
\item {\em Nsigma}: glitch detection at Nsigma.
\item {\em filter}: if set, then an adaptive temporal filter is applied.
\item {\em mask}: output 3D IDL array: Mask where glitches have been detected.
\end{itemize}


\clearpage
\section{Dark Pattern removal in the Fourier space}
One has to subtract the dark from the image. However, the standard
procedure is not always  able to remove completely the visual dark
pattern. The dark pattern is visible due to signal variation between
odd and even lines in the image.
If the dark of the calibration library is applicable, then the operation
just consist of subtracting it from the data.
But in practice, due to small dfits in dark current, this dark is not always good 
enough, and visible 
artifacts can remain in the reduced image. For these reasons,
several methods have been developed \cite{iso:bure96,starck:tr_dark96}
 to accomplish good dark subtraction. 
The dark pattern can be suppressed in the Fourier space by the
following method:

\begin{enumerate}
\item Average together all deglitched frames. we obtain $I_a$.

\item Eliminate in $I_a$ the low frequencies. we obtain $I_h$.

\item Estimate the noise in $I_h$, and set to zero all structures 
higher than three times the noise standard deviation.

\item Compute the FFT $\hat{I_h}$ of $I_h$, and estimate the noise in the
real part $\hat{I_h}_r$, and imaginary part $\hat{I_h}_i$ of
$\hat{I_h}$.

\item Threshold all Fourier coefficients lower than the noise. 
We get $\hat{T_h}_r$, $\hat{T_h}_i$.

\item Compute the inverse FFT transform of 
$(\hat{T_h}_r$, $\hat{T_h}_i)$. Its real part gives the pattern
$P$.  The pattern $P$ can then be subtracted from the input image.
\end{enumerate}
As the program may also be used for other purpose, it is describes in
section~\ref{pat}.

\section{Calibration from pattern recognition and faint source detection}
The main difficulty in 
dealing with ISOCAM faint source detection is the combination of the cosmic 
ray impacts (glitches) and the transient behavior of the detectors. 
Indeed, for glitches producing a single fast increase and decrease of 
the signal, a simple median filtering allows a fairly good deglitching,
while for other glitches, memory effects can produce false 
detections. Consequently, the major source of errors here is not the 
detection limit of the instrument, which is quite low, but the large 
number of glitches which create false detection.

\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=fig_3glitch.ps,bbllx=2.cm,bblly=12.5cm,bburx=20cm,bbury=25.5cm,width=14cm,height=8cm}
}}
\caption{Examples of glitches. (a) this signal contains three 
glitches of 
the first type. (b) A glitch a long tail appears (named fader)  
around the position 80. The
glitch has been truncated, and its real amplitude is 2700 ADUs. (c) A 
glitch
with a negative tail (named deeper) appears around position 240.}
\label{fig_glitch3}
\end{figure}
Three types of glitches can be distinguished: (i) a positive strong and short feature (lasting one readout), 
(ii) a positive tail (called {\em fader}, lasting a few readouts),
and (iii), a negative tail (called {\em dipper}, lasting  several tens of readouts).  
Figure~\ref{fig_glitch3} is 
a plot of the camera units (ADU, for Analog to Digital Units) measured 
by a single pixel as a function of the number of readouts, i.e.  time, 
which shows the three types of glitches.  On top (a), three sharp type "1" 
glitches are clearly visible. On the middle plot (b), another pixel 
history shows a "fader" (at about 80 readouts and lasting about 20 
readouts). On the bottom plot (c), a "dipper" is present at  readout 
230, which lasts about 150 readouts.

Finally, the signal measured by a single pixel as a function of time 
is the combination of memory effects, cosmic ray impacts and real 
sources: memory effects begin with the first readouts, since the 
detector faces a flux variation from an offset position to the target 
position (stabilization), then appear with long-lasting glitches and 
following real sources.  One needs to clearly separate all these 
constituents of the signal in each pixel before building a final 
raster map and to keep the information of the associated noise before 
applying a source detection algorithm.  Indeed, since the glitches do 
not follow a gaussian statistic, it is clear that an analysis of the 
final raster map would lead to poor results, for the standard 
detection criteria (detection above N times the standard deviation of 
the noise) would no more be valid. \\

The concept of pattern recognition 
using a multiresolution algorithm leads to an efficient calibration 
procedure, free of the major problems described above.    
The idea developed here is to use the multiscale vision modeling for 
a decomposition of a signal into its principal components. A simple 
object reconstruction from the detected structured in the wavelet 
space, as proposed in \cite{wave:bijaoui95}, will produce poor 
results because of the strong confusion between the objects. 
Furthermore
we need to extract positive and negative components, which imply that
 we may detect the wing around a negative structure as a positive
structure. The wings are a normal effect of the wavelet transform, 
which 
always create negative features around a positive component, as 
well as
positive features around a negative component. Furthermore,  
 the quality of the object reconstruction is good only when additional
 constraints are introduced (positivity constraint for positive 
objects, and
negativity constraint for negative objects). An object is defined as 
positive
(negative) when the wavelet coefficient of the object 
which has the maximum absolute value is positive (negative). 

A solution for limiting the confusion
is to use the knowledge we have about the objects. The problem
of unknown object reconstruction is reduced to a pattern recognition 
problem. We search only for objects which verify given 
conditions. For example, finding glitches of the first type is 
equivalent to  finding 
objects which are positive, strong, and with a temporal size lower 
than that of the sources. The principal component decomposition 
 method of the signal $D(t_0..t_n)$ is:
\begin{enumerate}
\item Search for the glitches of the first type. We get a signal $C_1(t_0..t_n)$, and
we calculate the deglitched data by $D_1 = D - C_1$.
\item Search for the negative components due to glitches: the multiscale 
vision
model is applied to $D_1$, and negative objects are reconstructed: we 
get $C_2(t_0..t_n)$, and we calculate $D_2 = D_1 - C_2$.
\item Search for the positive components due to glitches: this step must 
be
done carefully, in order not to erase a source by mistake.
Positive object with a temporal size different from that of the
sources are automatically considered as glitches. Positive objects having
a negative slope cannot be an object either.
 We get $C_3(t_0..t_n)$, and we calculate $D_3 = D_2 - C_3$.
\item Search for sources components: the multiscale vision
model is applied to $D_3$, and positive objects with a correct 
temporal
size are reconstructed: we get $C_4(t_0..t_n)$, and we calculate $D_4 
= D_3 - C_4$.
\item Search for the baseline: the signal $D_4$ contains only noise and 
sources at the noise level. The baseline is easily obtained by 
convolving
$D_4$ by a low frequency pass band filter. We get $C_5(t_0..t_n)$.
\item The residual noise is obtained by $C_6 = D_4 - C_5$.
\end{enumerate}
The set $(C_1,C_2,C_3,C_4,C_5,C_6)$, represents the decomposition of 
the
signal into its principal components. Note also that the input signal 
$D$ is
equal to the sum of all components: $D = \sum_{i=1}^{6} C_i$. 
A complete deglitching (all types of glitches) is obtained by 
$  D_g = D - C_1 - C_2 - C_3 $, 
and the signal  $D_b =  C_4 + C_6$ is background, dark, and glitch 
free.
$D_b$ represents the set of data we need for the deep survey study. 
The
background has been subtracted, and glitches with their long duration 
effects 
have been suppressed. Applying the pattern recognition method to all
detector pixels, we obtain a cube $D_b(x,y,t)$. All other component 
signals $C_i$ are also cubes.  
The baseline suppression presents several advantages: first the 
final
raster map is dark-corrected without the need of a library dark. 
This is particularly important when the library dark is  not good 
enough,
and visual artifacts often remains \cite{starck:tr_idum96}. 
Second,
the effect of the flat-field uncertainty is less severe, because the error
introduced by the flat-field correction on the background does not exist 
anymore,
since the background has been removed.  
\begin{figure}[htb]
\centerline{
\vbox{
\psfig{figure=fig_iso_plot7.ps,bbllx=2.5cm,bblly=13cm,bburx=19.5cm,bbury=25.5cm,width=14cm,height=8cm}
}}
\caption{Top, original data, and bottom, calibrated data (background 
free).
The flux in ADU (Analogic Digital Unit) is plotted against time given by the number of exposures.
Note the gain variation of about 5 ADUs which appears after the 
second glitch.}
\label{fig_calib}
\end{figure}

Figure~\ref{fig_calib} (bottom) presents the result after applying 
such a  treatment. Original data are shown in Figure~\ref{fig_calib} 
(top).
Figure~\ref{fig_decomp} shows the decomposition of the
 original signal (see figure~\ref{fig_calib} top) into its principal 
components: (a), (b), and (d) are features (short glitch, glitch 
negative tail, and baseline) which present no direct interest for 
faint source detection, and
(c) and (e) (source and noise) must be considered. The noise must also
be kept because faint sources could be undetectable in a single 
temporal signal, but
detectable after co-addition of the data.
The simple sum of the fives components is exactly equal to the 
original data (see figure~\ref{fig_calib} top). The calibrated 
background free data 
(see figure~\ref{fig_calib} bottom) are then obtained by addition of 
(c) and (e).

\begin{figure}[htb]
\centerline{
\vbox{
\psfig{figure=fig_iso_plot6.ps,bbllx=2.cm,bblly=13cm,bburx=19.5cm,bbury=25.5cm,width=17cm,height=12.5cm}
}}
\caption{Decomposition of the signal into its principal components: 
(a) short glitch, (b) glitch negative tail, (c) source, (d) baseline, 
(e) noise. The
simple sum of the fives components is exactly equal to the original 
data (see
figure 2). The calibrated background free data are obtained by 
addition of signals (c) and (e).}
\label{fig_decomp}
\end{figure}

The {\em mr\_isocalib} applies the calibration from pattern recognition.
The first input (raw data + observation parameters) file should be created 
using the {\em mosaic2fits} routine from the CAM Interactive Analysis package.
\begin{center}
 USAGE: mr\_isocalib option cube\_in cube\_in\_or\_out
\end{center}
where options are:
\begin{itemize}
\item {\bf [-n number\_of\_scales]} \\
Number of scales used in the multiresolution transform for the short glitches
removal. 
Default is 3.
\item {\bf [-N number\_of\_scales]} \\
Nnumber of scales used for the suppresion of long glitches. 
Default is 8.
\item {\bf [-g sigma]} \\
sigma = noise standard deviation. By default, it is automatically
estimated for each temporal vector.
\item {\bf [-s Nsigma]} \\
Detection level at nsigma * SigmaNoise.
\item {\bf [-d]} \\
Apply a short  glitches removal.  Default is no.
\item {\bf [-D]} \\
Apply a long glitches removal. Default is no.
\item {\bf [-b]} \\
Suppress the base line. Default is no.
\item {\bf [-B number\_of\_scales]} \\
 Number of scales used for baseline suppression.
\item {\bf [-f]} \\
Flat field correction. Default is no.
\item {\bf [-t]} \\ 
 Transient correction. Default is no.
\item {\bf [-K BorderNumber]} \\
Do not take into account the border.
\item {\bf [-a]} \\
Average the frames belonging to the same sky position. Default is no.
\item {\bf [-r]} \\
Create a rasmap.
\item {\bf [-S NSigma\_Long\_Glitch]} \\
NSigma for long glitch detection. Default is 5. 
\item {\bf [-F]} \\ 
Kill detected objects containing more than 50 masked  pixels.
\item {\bf [-G]} \\
Kill detected objects if the first 3 pixels are masked .
\item {\bf [-M]} \\
Mask pixels where long glitches have been detected.
\item {\bf [-A]} \\
(for all) Apply a flat field correction, a short and long glitches removal,
a baseline suppression, average the frame, create the raster map. It is equivalent
to options "-d -D -f -b -a -r".
\item {\bf [-L]} \\
Use the slope of an object for source/glitch separation.
\item {\bf [-m]} \\
Creates a micro-scan map instead of a raster map.
\end{itemize}

There is two modes for using the {\em mr\_isocalib} program: \\
If option "-d" and/or "-D" is set then the second file of the command
line is an output file, which contains the deglitched data cube, without
the baseline (if "-b" is set), and hence contains only the 
noise and the sources. In this case  the program will also create
a set of other files:
\begin{itemize}
\item xx\_baddata.fits: data cube which contains the detected long glitches.
\item xx\_mask.fits: data cube which contains the mask. mask(x,y,z) equal
to 1 if a short glitch is found at position (x,y,z). If "-M" is set, 
positions were long glitches have been detected are set also to 1.
\item xx\_bgr.fits: data cube which contains the baseline.
\item xx\_sigmanoise.fits: image which contains the estimated noise for each
detector pixel.
\item xx\_source.fits: data cube which contains the detected sources.
\end{itemize}

If neither "-d" or "-D" is set (second mode), all the files described above are read 
by {\em mr\_isocalib}. This allows us to treat in several steps the data.

other created files are created:
\begin{itemize}
\item Results concerning the flat field (only if "-f" is set):
\begin{itemize}
\item "xx\_auto\_flat.fits": estimated flat field.
\item "xx\_rms\_flat.fits": RMS of the estimated flat field.
\end{itemize}
\item Results concerning the reduced data (frame at the same sky position
have been averaged). Only if "-r" or/and "-f", or/and "-m" is set.
\begin{itemize}
\item "xx\_reduce.fits": reduced and flat-fielded (if "-f") cube.
\item "xx\_rms.fits": RMS cube of the averaged cube.
\item "xx\_npix.fits": number of pixels used for pixel of the averaged cube.
\item "xx\_rms\_noise.fits": Estimated noise on the averaged cube.
\item "xx\_raster.fits": raster scan or micro scan final map.
\item "xx\_rmsraster.fits": RMS of the final map
\item "xx\_npixraster.fits": number of pixels used
 for the final map calculation.
\end{itemize}
\item Results concerning the baseline:
\begin{itemize}
\item "xx\_bgrreduce.fits"
\item "xx\_bgrrms.fits"
\item "xx\_bgrnpix.fits"
\item "xx\_bgrraster.fits"
\item "xx\_bgrrmsraster.fits"
\item "xx\_bgrnpixraster.fits"
\end{itemize}
\item Results concerning the bad data (long glitches):
\begin{itemize}
\item "xx\_badreduce.fits"
\item "xx\_badraster.fits"
\end{itemize}
\end{itemize}
 
\clearpage
\section{transient fit}

There are  different methods to achieve stabilization which have
been tested. 
The best  method try to fit the transients using a
model, and then suppress them. See \cite{iso:delattre96} for a description of each of them. A transient can be split into two parts:  
\begin{itemize}
\item a first part where data are quickly decreasing and they can 
be fitted by an downward exponential.
\item a second part where data are decreasing very slowly but which 
cannot be seen as the tail of the decreasing exponential of the first
part.
\end{itemize}
The best model takes into account this behaviour, and proposes a transient
function with two relaxation times:

\begin{itemize}
\item For downward transient
	\[ J_d(t)\,=\,J_{\infty} + (J_0 - J_{\infty}).\beta.exp(- {t \over \tau}) + \beta' . exp(- {t \over \tau'}) \] 
where $\tau' >> \tau$ ;

\item and for upward transient
	\[ J_u(t)\,=\, J_{\infty} - (J_{\infty} - J_0).\beta.exp(- {t \over \tau}) \]
\end{itemize}
where $J_{\infty}$ is the stabilized value (observed flux), and $J_0$ is
the starting value (observed flux at the previous satellite configuration). This model has six parameters $J_0$,$J_{\infty}$, $\beta$, $\beta'$, $\tau$, $\tau'$.
The low decrease of the transient is modeled by a larger time constant
$\tau'$.  This model has two advantages: it leads to a complete fit of
the data (and not only the beginning or the end of the transient), and
it also allows us to work with the first points to guess the
stabilized value $J_{\infty}$.

\begin{center}
 USAGE: transient\_fit option cube\_in cube\_out
\end{center}
where options are:
\begin{itemize}
\item {\bf [-d downward\_model]} \\
for fitting downward transients.
\item {\bf [-e ending\_scd]} \\
e = position of the ending scd to be considered  for fitting transients.
\item {\bf [-g]} \\
Global correction. upward \& downward transients are fitted over all the scds.
 \item {\bf [-m method]} \\
m = name of the method used for the minimization of the merit-function:
'cauchy','exponential','gaussian'.
\item {\bf [-n number\_of\_iterations]} \\
n = max number of iterations when fitting the model with the data.
\item {\bf [-o]} \\
overshoot upward model.
\item {\bf [-s starting\_scd]} \\
s = position of the starting scd to be considered  for fitting transients.
\item {\bf [-t down\_threshold]} \\
t = the greatest negative value of the slope of a downward transient above 
which   no fitting is undertaken.
\item {\bf [-T up\_Threshhold]} \\
T = the lowest positive value of the slope of a upward transient beneath
 which no fitting is undertaken.
\item {\bf [-u upward\_model]} \\
for fitting upward transients.
\end{itemize}

\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=fig_ex_transient_CEA.ps,bbllx=2.5cm,bblly=2cm,bburx=18.5cm,bbury=13.1cm,width=16cm,height=11cm}}}
\caption{Example of transient fit using the SACLAY model.}
\label{fig_trans_cea1}
\end{figure}

Figure \ref{fig_trans_cea1} shows the result of a fit. The detector pixel values  
  are represented in solid line. The pixel detector is observing
a flux of around three ADUs. We see that even after
eighty frames, the flux is not stabilized. Overplotted to the data, the 
model is plotted, and in the bottom of the figure, we see the data corrected
from the transient effect.
\clearpage

\section{Field of View Distortion Correction}
  Field distortion in ISOCAM is mostly due to the off-axis Fabry mirror 
that directs the light beam toward each detector. The field distortion 
was measured for the  LW channel 6 and 3 arcsec PFOV lens, using calibration field observations that contains many stars. No measurements are planned for the 1.5 arcsec PFOV 
because they are difficult to make due to the satellite jitter which is of 
the order of the quantities to be measured. Moreover, results at 6 
and 3 arcsec are in good agreement with the predicted (ray-tracing) 
and measured pre launch values. Since the distortion at 1.5 arcsec 
PFOV is predicted to be negligeable, 
no error should be made if it is not taken into account.

 ISOCAM suffers from lens jitter. In order to avoid any 
mechanical blocking, the gear wheel has been designed with small 
play.  Therefore, the position at which the lens stops is not fixed.  It has been 
shown by the CAM Instrument Dedicated Team (CIDT) and by us that there 
are only two positions that the lens wheel can take for a commanded 
position, and it is suspected that the wheel stops at either side of 
the play.  This can be very easily detected by a close inspection of 
the flat field derived from the data : the leftmost column of the 
detector receives very little light.  This is called the `left' position.  
This jitter results in an offset of about 1.2 pixels of the optical 
axis, thus $\approx$ 7" with the 6" PFOV lens. It modifies also the 
distortion pattern of ISOCAM that has been measured for both 
positions. The measurment method is discussed in \cite{starck:aussel98}. 

Following the work done on the HST WFPC by \cite{iso:holtzman95},  each 
measurment is fitted with a general polynomial of degree 3, that is :
\begin{equation}
x_{c} = a_{0}+ a_{1}x + a_{2} y + a_{3}x^{2}+ a_{4}x y + a_{5}y^{2} + 
a_{6}x^{3}+ a_{7}x^{2}y + a_{8}xy^{2}+ a_{9}y^{3} 
\end{equation}
\begin{equation}
y_{c} = b_{0}+ b_{1}x + b_{2} y + b_{3}x^{2}+ b_{4}x y + b_{5}y^{2} + 
b_{6}x^{3}+ b_{7}x^{2}y + b_{8}xy^{2}+ b_{9}y^{3} 
\end{equation}

where $x_{c}$ and $y_{c}$ are the positions on the ISOCAM LW array in 
pixels, corrected for distortion, while $x$ and $y$ are the non-corrected ones. Figure \ref{fig_disto} shows a map of the 
distortion of the LW channel of ISOCAM with the 6" PFOV, where each vector starts from 
where the center of a pixel should fall if they were no distortion and 
ends at its actual position.  The length of the vectors are at the 
scale of the plot. At the lower corners of the array (lines 0 to 5), 
the effect is greater than one pixel.  

Since the pixel size is not uniform on the sky, the pixels at the edges of 
the array cover a wider surface. Therefore, a new flat-field correction has 
to be applied in order to account for it. This flat-field is of the 
form :
\begin{equation}
F_{i,j} = \frac{S_{16,16}}{S_{i,j}}
\end{equation}
with $S_{i,j}$ , the surface on the sky of pixel i,j.  The pixel 
(16,16), being the center pixel of ISOCAM LW array and therefore the 
less distorted, has been taken as reference. 

Once corrected for this effect, each raster sub-image is projected on 
the raster map, using a flux-conservative shift and add algorithm. 
The intersecting surface $S_{(x,y,i,j)}$ of each sky pixel of the raster map with each 
ISOCAM pixel is computed. The flux in the pixel (x,y) 
of the raster map is therefore:
 
\begin{equation}
R_{x,y} = \frac{\sum_{pointings}S_{(x,y,i,j)}\sqrt{N_{i,j}}I_{i,j}}
{\sum_{pointings}S_{(x,y,i,j)}\sqrt{N_{i,j}}}    
\end{equation}
Assuming gaussian distributions for pixels, the noise 
map is:
\begin{equation}
\sigma_{x,y} = \sqrt{\frac{\sum_{pointings}S^{2}_{(x,y,i,j)}N_{i,j}\sigma^{2}_{i,j}}
{\sum_{pointings}S^{2}_{(x,y,i,j)}N_{i,j}}}    
\end{equation} 
Where $R_{x,y}$ is the value of the final raster map at (x,y), 
$S_{(x,y,i,j)}$ is the intercepted surface between ISOCAM pixel (i,j) 
and raster map pixel (x,y) and $N_{i,j}$is the number of readouts that 
where averaged together to produce $I_{i,j}$, the image of the raster 
pointing. The computation of $S_{(x,y,i,j)}$ is derived from the 
algorithm used by Fruchter et al. in their `drizzle' IRAF task.
The files containing the coefficients for the distortion 
correction are available from the authors under a format accepted by 
this task.
 
\begin{center}
 USAGE: projection  options input1 input2 ... output  
\end{center}
where options are:
\begin{itemize}
\item {\bf [-R CROTA2]} \\
Creates a map with given {\em CROTA2} (decimal degrees).
Default is 0 .
\item {\bf [-d CDELT1]} \\
Creates a map with a given resolution (in arcsec). \\
if {\em CDELT1} is set and not {\em CDELT2}, then  \\
                 CDELT1 = -{\em CDELT1} and CDELT2 = {\em CDELT1} \\
to ensure North top and West left astronomical convention  with CROTA2=0 images.
\item {\bf [-D CDELT2]} \\
 Creates a map with a given CDELT2 (in arcsec). CDELT1 must have been provided.
\item {\bf [-M map]} \\
 Will use the orientation of the map input number map for the result map.
\item {\bf [-C]} \\
Will produce as many outputs as inputs, with the same astrometry, 
but without coadding the maps. Fits files will be numbered from 1 to n 
after the given output filename.
\item {\bf [-o output file name]} \\
Output file name. Default is "result.fits". 
\item {\bf [-x line of pixel to be examined]} \\
Default is -1000.
\item {\bf [-y column of pixel to be examined]} \\
 Default is -1000.
\end{itemize}

\begin{figure}[htb]
\centerline{
\hbox{
\psfig{figure=velo.ps,bbllx=2.7cm,bblly=5.5cm,bburx=19cm,bbury=22.5cm,width=11cm,height=11cm}}}
\caption{ISOCAM field of view distortion.}
\label{fig_disto}
\end{figure}

 
